<?xml version="1.0" ?>
<?xml-stylesheet type="text/xsl" href="style.xsl"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>Amazon AI News</title>
    <link>https://www.aboutamazon.com/artificial-intelligence-ai-news</link>
    <description><![CDATA[Latest news about AI at Amazon]]></description>
    <language>en-US</language>
    <lastBuildDate>Thu, 08 Jan 2026 10:05:53 GMT</lastBuildDate>
    <generator>rfeed v1.1.1</generator>
    <docs>https://github.com/svpino/rfeed/blob/master/README.md</docs>
    <item>
      <title>5 things to know about Peter DeSantis, Amazon's new leader for AGI, chips, and quantum computing</title>
      <link>https://www.aboutamazon.com/news/innovation-at-amazon/peter-desantis-amazon-artificial-general-intelligence</link>
      <description><![CDATA[Key takeaways DeSantis has spent 27 years at Amazon, leading transformative technologies from EC2's launch to AWS Infrastructure. His new organization unites AI models, custom silicon, and quantum computing—technologies he sees as naturally reinforcing each other. Amazon's combination of world-class compute resources and real-world applications attracts scientists who want their work to ship at massive scale. When Peter DeSantis joined Amazon in 1998, the company was known primarily as an online bookstore. Over the next 27 years, he would help build some of the most transformative technologies in computing history—from leading Amazon EC2’s launch in 2006 to spearheading the 2015 acquisition of Annapurna Labs , which builds Amazon's custom silicon. Now, as Senior Vice President overseeing a new organization that spans the most expansive AI models, custom silicon, and quantum computing, DeSantis is bringing together some of the most compelling emerging technologies of today. His sweeping portfolio includes the teams building Amazon Nova foundation models, developing Graviton and Trainium chips , and advancing quantum computing solutions —technologies that, in his view, will increasingly reinforce and accelerate each other. The organization is so new that it doesn't have an official name yet (but DeSantis and his teams are working on it). With a track record of solving problems "at the edge of what's technically possible" while delivering technologies that operate reliably at massive scale, DeSantis combines unusual technical depth with a relentless focus on customer needs. As these foundational technologies mature and interweave, his leadership will help shape how Amazon—and the broader technology industry—approaches the next generation of computing. Here are 5 things to know about the leader guiding Amazon's most ambitious long-term technology bets. 1. DeSantis sees custom chips, AI models, and quantum computing as reinforcing technologies All three of them are big, long-term bets for the company, and addressing them requires a similar approach, which is to blend our short-term urgency for delivery and roadmap planning with a long-term vision of where these technologies need to go in order to best serve our business and our customers. There are also more tangible ways that these technologies will reinforce each other. I think the most obvious one is the foundational model. My belief—and largely the industry's belief—is that these AI models are going to get bigger and more capable and more profoundly impact what we can do with them and how they change our lives. But to do that, we have to invest a large amount of capital and compute to build these models. One of the ways that we can give ourselves an advantage in how we build these models is by using our deep investments in chips to deliver both performance and cost efficiency that will allow us to differentiate our model development. A city in the palm of your hand: Exploring the intricate world of an Amazon Web Services chip The science that's happening inside of our foundational model teams—knowing where those models are going to go because of where the science is going—is going to influence our chips roadmaps. And chips take many years to build. Getting these two groups correctly working with each other, which, in a very Amazon way, will be loosely coupled, not tightly coupled, so that they are helpful to each other but not slowing each other down—it has a lot of potential. Quantum is, of the three, the longest-term thing that we're working on. It's going to be many years before we see the impact of quantum computing on the world, but I have very high conviction we will see it in our not-so-distant future. Ultimately, we are building a quantum chip . And now there's a lot of science that's happening in terms of how we use that chip in very, very different ways to build a very, very different kind of computer. As we get closer and closer to the point where we're ready to build that, scale that chip up and bring it to customers' hands, the things we've learned in our Annapurna chips business are going to be very complementary to that investment. It'll help us move even faster, scale even faster, and hopefully get to the very significant societal and technology goodness that's going to come with having a quantum computer. 2. He's most excited about getting Graviton 5, Trainium3, and Nova Forge into customers' hands I'm excited about a ton of things in the chips business, which I'm most familiar with because I've been involved in it since we got started over a decade ago. We just released Graviton 5 at re:Invent , which is by far our highest-performing general purpose processor ever. It will deliver the things that our customers have been most excited about with Graviton, which is differentiated performance, differentiated cost, and it will deliver that to almost every imaginable workload. Whereas if you go back a couple generations with Graviton, there was a subset of workloads that couldn't take advantage of it. Graviton 5 has truly gotten Graviton to the point where any workload that you want to run in the cloud probably runs best on Graviton. And the customer enthusiasm for Graviton has been huge, and we just released it, so the excitement is there. Now we have to bring it in volume. That's been an exciting part of getting the year started. Frontier agents, Trainium chips, and Amazon Nova: key announcements from AWS re:Invent 2025 Similarly, Trainium3 was just released and is one of the most exciting AI accelerators in the market. We're talking to a large number of customers that are excited about trying it, and we're excited to get it into their hands, get feedback from them, and hopefully get them running in meaningful ways on it. I spent a bunch of time at re:Invent this year with our customers on how they're thinking about Nova and particularly some of the new capabilities we launched. I would personally say Nova Forge, which is our capability that allows you to take our Nova models and take your data and your business expertise and produce what we call a Novella—a variant of that Nova model that's been deeply customized for your use case—is resonating with customers. I just got done talking to that team, and it's important that we get that in customers' hands. 3. He plans to deepen Nova integration across retail, Alexa, ads, and operations Nova is such an important part of our strategy in all of our core businesses—whether it's retail, or Alexa , or ads , or even operations —and each of these businesses has fundamentally different needs. A model that works great for shopping doesn't automatically work for Alexa. A model optimized for ads has different requirements than one built for fulfillment centers. So the real challenge isn't just building a great foundation model. It's figuring out how to make one model flexible enough that each business can shape it to their specific problems without losing the core intelligence underneath. That's harder than it sounds. We're still early in understanding what that looks like at scale. We've seen promising signals with teams taking Nova and customizing it for their use cases, which led to the recent launch of Nova Forge —allowing any business to build its own frontier model. But it's still early days. We're learning that we need to think differently about what comes next. I'm very much looking forward to having deeper conversations with our teams—learning how it's going today and where it can be improved as we look ahead. The honest answer is we're figuring this out together. My job is to listen, learn, and make sure we're building the right capabilities to support them. I expect that will involve conversations with my peers, but also much deeper conversations with their teams. 4. DeSantis says Amazon attracts missionaries who want to build transformative technology that ships Amazon is the best place for missionaries who want to build for customers. We’re uniquely long-term focused as a company. If we are convicted about something, we will see it through to success. The best example I know is AWS itself. When I first joined AWS, there was a lot of skepticism across the company about our investment in this new business. There was concern it would distract us and a belief that it would never be meaningful for Amazon. That seems silly now, but that’s really what a lot of people thought—internally and externally. Our leadership and team stayed convicted, and we all see how that turned out. We have similar conviction in chips, AI foundational models, and quantum computing. We also have some really unique assets to build with at Amazon. Our scientists have direct access to world-class compute resources—including GPUs and custom Trainium chips—AWS's global infrastructure, and real-world applications spanning Alexa, retail, logistics, and enterprise services. It’s really hard to find any of these anywhere else, but here we’re blessed with all these tailwinds to our investments. Introducing Alexa.com, a completely new way to interact with Alexa+ That combination attracts missionaries who want to build transformative technology that actually ships and makes a real difference in customers' lives. It's not just about publishing papers or winning benchmarks—it's about seeing your work in the hands of customers at massive scale. 5. After 27 years, he says Amazon still operates like the startup he joined One of the things that keeps me here is that, in a lot of the most important ways, the company hasn't changed. We're still focused on customers. We're still focused on building cool things. We are still in many, many ways like the startup that I joined 27 years ago. We're obviously much bigger, and so there's a lot more going on, which is fun. We've always been a company where there's been a ton of ground-up innovation that happens all over the place. Even when we were much smaller, you were often surprised that somebody was working on something that you had never heard about. Even with my relatively broad vantage point on what's going on in the company, I stumble into all sorts of things every day that I didn't know we were doing—which is cool. Learn more about how Amazon is transforming customers' lives with generative AI and agentic AI innovations .]]></description>
      <pubDate>Tue, 06 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/innovation-at-amazon/peter-desantis-amazon-artificial-general-intelligence</guid>
    </item>
    <item>
      <title>CES 2026: Key announcements from Amazon</title>
      <link>https://www.aboutamazon.com/news/devices/amazon-ces-2026-fire-tv-ring-alexa-plus</link>
      <description><![CDATA[The Consumer Electronics Show (CES) 2026 has kicked off, and Amazon is showcasing a vision for AI that focuses on making customers’ lives easier. From a Ring camera that catches something you might have missed to Alexa+ surfacing information before you ask for it, Amazon's latest innovations demonstrate ambient AI: products and experiences that are there when you need them and disappear into the background, always ready, when you don’t. Expedia, Yelp, Angi, and Square to build new agentic experiences for Alexa+ At this year's event in Las Vegas, Amazon is introducing new products across entertainment, smart home, security, and more. A redesigned Fire TV user interface promises to get customers to what they want to watch faster. Alexa+ is expanding beyond voice to the web and extending its capabilities with integrations across more devices. Ring is rolling out sweeping new security solutions. And Bee, the newest addition to Amazon’s Devices & Services, is serving up wearable AI with features designed to understand daily habits and offer proactive assistance. Here's a look at what Amazon is announcing this year: Ring launches new AI-powered features and devices, including Fire Watch Ring is announcing new features and devices to help make your neighborhood safer and give you peace of mind, wherever you are. One of these features is Fire Watch, a powerful new feature in the Neighbors section of the Ring app that delivers earlier warnings and real-time information during fast-moving fire events, enabling Ring camera owners to share snapshots while cameras analyze video for visual signs of smoke or fire. The feature is made possible through Ring's work with Watch Duty. Ring is also introducing the Ring Appstore, a new experience inside the Ring app that gives customers more ways to use their existing Ring cameras through third-party apps built by trusted developers. Alexa+ can now answer your Ring doorbell and talk to visitors Additionally, with Ring Sensors, a new lineup of smart security devices built on Amazon Sidewalk, Ring is delivering always-on protection without Wi-Fi range limits, hubs, or base stations, with three seamless layers—Security, Safety, and Control—that work together to protect your home, prevent damage, and simplify everyday routines. Read more about Ring's announcements . Amazon debuts cleaner and faster Fire TV experience, new Amazon Ember Artline lifestyle TV, and redesigned mobile app Amazon is overhauling the Fire TV experience with a redesigned interface that's up to 30% faster in some cases and better organized around content types like movies, TV shows, and sports. The update includes dedicated homes for each category, letting customers browse titles across all their subscriptions in one place. We are also launching our first lifestyle TV, the Amazon Ember Artline, a beautiful 4K QLED TV with a matte display, access to over 2,000 pieces of free art, and AI-powered recommendations that match artwork to your room's décor. Ten easily adjustable frame colors let you customize the look. And a redesigned Fire TV mobile app now lets you browse content, manage watchlists, and pick what you’ll watch next. Read more about our Fire TV news . Alexa+ expands to the web with Alexa.com, bringing AI assistant capabilities across voice, mobile, and browser Amazon is rolling out Alexa.com to all Alexa+ Early Access customers, bringing the full power of its AI assistant directly to the browsers. Since launching nine months ago, Alexa+ has scaled to tens of millions of customers with users engaging twice as much in conversations across a wide breadth of topics and tasks, making three times more purchases, and requesting recipes five times more frequently. Alexa.com combines deep information with real-world actions—from managing calendars and controlling smart homes to planning meals and making reservations. The web experience offers seamless integration across devices with persistent context, allowing customers to access Alexa wherever they are. Combined with the redesigned Alexa mobile app, which features an agent-forward design, Alexa+ is now accessible across every surface—whether you're at your desk, on the go, or at home. We’re excited about the potential that new modalities will add to Alexa+, and there’s much more to come with the capabilities and experiences we have planned. Read more about Alexa.com . New Alexa+ integrations with BMW, Samsung, Bosch, Oura, and more We’re announcing exciting new Alexa+ integrations that add to the tens of thousands of devices and services Alexa+ already works with. Alexa+ is available in even more places across the devices and services customers use every day. In 2026, we are adding the next generation of Alexa Custom Assistant, powered by Alexa+, to select BMW models, including the latest BMW iX3. Samsung is adding Alexa+ to their smart televisions, marking the first time Alexa+ is buit-in on a third-party device. Bosch is enabling voice-directed commands in its Bosch 800 series of fully automatic coffee makers. HERE Technologies and TomTom integrated Alexa Custom Assistant (ACA) into their mapping and location services for intelligent in-vehicle navigation. And Oura is rolling out early access to its Alexa+ integration, enabling customers to keep track of and act on their health information. All these new integrations give customers even more ways to use Alexa+ both at home, and on the go. Read more about our latest Alexa+ integrations . Since joining Amazon, the Bee team is evolving the wearable into the personal AI companion they’ve always envisioned—building new features and devices that have the potential to reach customers everywhere The team has shipped several major updates since joining Amazon, each one bringing this vision closer to reality: Actions connect Bee to your email and calendar, turning conversations into outcomes. When you mention needing to send an email or schedule a meeting, Bee can draft the email, create the invite, and handle it for you. Daily Insights surface patterns you'd never catch yourself: trends in how you're feeling, shifts in your relationships, themes that recur across weeks, and recommended personalized goals to help you act on what matters. Voice Notes enable you to capture any thought in an instant. Press the button, speak your mind, and it's there waiting for you. Templates will deliver intelligent summaries tailored to your specific needs and the setting you’re in. Whether it’s organizing lecture content into study plans for students or a salesperson recapping a client meeting into actionable next steps, Bee automatically formats the summary in the structure that works best for that moment. Read more about Bee’s journey at Amazon . Interested in more Amazon innovations? Visit our Devices page to see what else is new in the world of Ring, Blink, Kindle, Alexa+, and more.]]></description>
      <pubDate>Mon, 05 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/amazon-ces-2026-fire-tv-ring-alexa-plus</guid>
    </item>
    <item>
      <title>Alexa+ expands to Samsung TVs, BMW cars, and more in 2026</title>
      <link>https://www.aboutamazon.com/news/devices/alexa-plus-samsung-bmw-bosch-oura-integrations</link>
      <description><![CDATA[Key takeaways At CES, we announced new Alexa+ capabilities to keep customers connected in and outside their homes. Samsung will be the first third-party manufacturer to build in Alexa+, bringing voice-controlled entertainment and smart home management to their smart TVs. Amazon is also partnering with BMW, Bosch, and others, adding to the tens of thousands of devices and services Alexa+ already works with today. Whether at home, in the car, or on the go, Alexa+ is there when and where customers need it—ready to help with the tasks they care about most. Check out the six new Alexa+ integrations coming in 2026. Alexa+ in TVs Samsung is adding Alexa+ to their smart televisions, marking the first time Alexa+ is built into a non-Amazon device. Starting later this month, Samsung TV owners can speak to Alexa on their TVs to get to the content they want fast or get things done around the home. Using natural voice conversations, our shared customers can discover new series and movies quickly, easily manage smart home devices, play music from their televisions, and more. For example, say: “Alexa, it's showtime. What's new?” to find new releases or “Alexa, it feels too cold” to automatically adjust the thermostat. Early access to Alexa+ will be available for select 2021 to 2025 Samsung TV models with Alexa built-in. Introducing Alexa.com, a completely new way to interact with Alexa+ Alexa+ in your smart home Bosch will launch new capabilities with Alexa+ in 2026 so customers can talk to Alexa to control their coffee machine. Starting with the Bosch 800 Series fully automatic espresso machine, making coffee at home will feel just like talking to a barista. Customers will be able to have a natural conversation with Alexa to make and personalize their favorite coffee, lattes, cortados, and more. Alexa+ in the car BMW is showcasing its new BMW iX3 model, a cutting-edge electric SUV with the latest technology, including the next generation of BMW Intelligent Personal Assistant, powered by Alexa+. At the core of this innovation is Alexa Custom Assistant (ACA), a comprehensive service that enables automakers to create their own intelligent AI assistants powered by Alexa+ agentic capabilities. The new in-vehicle technology offers intuitive and sophisticated interactions between passengers and the vehicle in a natural dialogue—including the operation of vehicle functions as well as access to information and knowledge beyond the vehicle. Customers can have actual conversations with their car using natural language—no memorizing commands, no rigid phrase structures. They can say "Hey BMW, I am feeling a bit chilly could you warm it up in here" and have the car heat up. Customers can connect to dozens of services like music streaming and navigation, all in one cohesive experience. Expedia, Yelp, Angi, and Square to build new agentic experiences for Alexa+ HERE Technologies and TomTom also integrated Alexa Custom Assistant into their mapping and location technology. The result is an AI-powered in-vehicle navigation experience that enables customers to speak naturally to plan a trip, add or remove stops, find upcoming electrical vehicle charging spots, and more. This next generation of ACA debuted for the first time with BMW Group in their new BMW car iX3, and it is now available to automakers and location technology providers. Alexa+ in your daily health and wellness routine Soon, Alexa+ will help customers proactively manage their health and wellness journey each day. For example: As you’re getting ready in the morning, Alexa can give you a rundown of your sleep and recovery, and ways to achieve your wellness goals. In the evening, Alexa can use your optimal sleep time to remind you that it’s time to wind down and adjust temperature, lights, music and more to get you ready for a good night's sleep. At CES, we are giving customers a sneak peek of the Early Access experience with Oura. Integrations with Withings, Wyze, and additional partners are coming soon. Learn more and sign up for Alexa+ Health & Wellness .]]></description>
      <pubDate>Mon, 05 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/alexa-plus-samsung-bmw-bosch-oura-integrations</guid>
    </item>
    <item>
      <title>Amazon’s new Fire TV user interface gets you to what you want to watch—even faster</title>
      <link>https://www.aboutamazon.com/news/devices/new-fire-tv-upgrades-features-2026</link>
      <description><![CDATA[Key takeaways Fire TV's new user interface is faster and more streamlined, with dedicated homes for each content type. Amazon Ember Artline is a lifestyle TV with a matte screen and access to more than 2,000 pieces of free art. Generative AI-powered Alexa+ offers personalized recommendations and lets you jump to specific scenes in movies. Our mission at Fire TV is getting customers to what they want to watch—fast. We know that can be hard with so much content to choose from. It would take 100 years just to stream the free content on Fire TV. So, last year, we launched Alexa+ , our world-class entertainment expert, on Fire TV, to help customers get smarter, more personalized recommendations through natural conversation. Because customers are talking to Alexa+ more than 2.5 times more often than they were with the original Alexa, we knew it was time to upgrade other key parts of the Fire TV experience. So, to kick off 2026, we’re upgrading how customers browse for content with a new, redesigned user interface (UI), launching a transformed Fire TV mobile app, and introducing our first-ever lifestyle TV, the Amazon Ember Artline. A new Fire TV design that’s clean and fast We've redesigned the Fire TV UI to be cleaner, faster, and better organized—helping customers spend less time searching and more time watching. We’ve seen recent research from Gracenote that customers in the U.S. spend 12 minutes on average searching for what to watch, up from 10.5 minutes in 2023. We designed the new Fire TV experience to help cut down on that time. Now it’s faster and easier to find movies, TV shows, sports, news, and live content across all your subscriptions. That means when you browse movies, for example, you’ll see titles from all the apps you use. The new UI has a more modern design with improved layouts, rounded corners, redesigned color gradients, updated typography, and more optimized spacing. The update isn’t just aesthetic: The team rebuilt the underlying code to make the experience faster. In some cases, we’re seeing up to 20–30% gains in speed when using the new UI. All of these improvements will be available to customers with a free software update. With the redesign, we’re also increasing the number of apps you can pin to your home screen from six to 20. But the Fire TV experience is much more than just an app launcher. Now you can press the Menu button on your remote to quickly get to Games, Art & Photos, and the Ambient Experience. And with Amazon Photos on Fire TV, it’s easy to connect your personal photos so they show up beautifully on the biggest screen in your home. Jump right to the movie scene you describe with the launch of Fire TV's new Alexa+ feature We’ve also added a shortcut panel you can access by long-pressing the Home button on your remote. It gives you quick access to the most-used controls on Fire TV, including audio and display settings, your connected Ring cameras, and smart home device management. Of course, Alexa+, our generative AI-powered agent, is available in every part of the Fire TV experience. Just tell Alexa what you’re in the mood to watch, who you’re with, or examples of actors or directors you like. Alexa will help you find something great to watch. You can also ask Alexa to add the title you see on screen to your watchlist, get stats from the game you’re watching, create an AI-generated background screensaver, see photos from your last family vacation, turn down the lights, or jump straight to an iconic movie scene. The Fire TV mobile app gets a glow up Millions of customers use our Fire TV mobile app as a backup remote, but we knew it could do more. The redesigned app adds the ability to browse content, manage your watchlist, and play titles on your TV—all with a look and feel that matches the new Fire TV design. Now you can use your phone as a second screen to discover what to watch next or add a friend's show recommendation to your watchlist when you’re away from home. The Fire TV mobile app will be available for free to download. Innovating on behalf of customers Customers around the world have purchased over 300 million Fire TV devices, including our streaming media players; TVs made by partners like Hisense, Panasonic, TCL, and Xiaomi; and Amazon TVs like the latest Fire TV 2-Series, 4-Series, and Omni QLED Series. With our Amazon smart TVs, our goal has always been to push the boundaries of what the biggest screen in our homes can do. Over the years, we’ve launched innovations like the Ambient Experience so our TVs could display your photos and art whenever someone walks into the room and then power down when you leave the room to save energy. Customers have loved these features, so it was naturally time to elevate our hardware and build a TV worthy of the Ambient Experience. We’ve also had so much momentum with our line of Amazon smart TVs that we decided now was the time to give them their own name: Amazon Ember. And it was only fitting to launch this new name with our first-ever lifestyle TV, the Amazon Ember Artline. The Amazon Ember Artline—a lifestyle TV designed for any room The all-new Amazon Ember Artline is a beautiful 4K QLED TV featuring support for Dolby Vision, HDR10+, Wi-Fi 6, and a thin 1.5-inch design. It has a matte screen designed to make your art and photos look great and to reduce glare in any lighting condition. The Artline is more than a stunning display—it brings AI innovation to the lifestyle TV category. The Amazon Ember Artline comes with far-field microphones so you can naturally talk with Alexa+, and Omnisense technology that automatically turns the Ambient Experience on and off when people enter or leave the room. It includes seamless integration with Amazon Photos, more than 2,000 pieces of free art, and the all-new Fire TV UI so you can get to what you want to watch—fast. We know that finding the right piece of art to fit in a specific room can be challenging. So, we’ve built an all-new, AI-powered feature that lets you take up to four photos of the room where you plan to hang the Amazon Ember Artline and quickly get personalized recommendations on the best works of art to display that match your style and décor. With Amazon Photos connected, you can also ask Alexa+ to help create slideshows of your photos by saying things like, “Alexa, create a slideshow of our family trip to Colorado” or “Alexa, show photos from our wedding.” And customers will have the choice to pick one of 10 easily adjustable, magnetic frames to best fit your style. Colors include Walnut, Ash, Teak, Black Oak, Matte White, Midnight Blue, Fig, Pale Gold, Graphite, and Silver. Availability The new Fire TV UI and mobile app will launch starting in February on the Fire TV Stick 4K Plus, Fire TV Stick 4K Max (2 nd Gen), and Fire TV Omni Mini-LED Series in the U.S. Later this spring, we’ll expand the new UI design to more countries and more devices, including the latest generation Fire TV 4K streaming media players and TVs like the Fire TV 2-Series, Fire TV 4-Series, Fire TV Omni QLED Series; TVs made by partners like Hisense, Insignia, Panasonic, and TCL; and at launch on the all-new Amazon Ember Artline. Starting today, customers can sign up to receive an email when the Amazon Ember Artline goes on sale later this spring in the U.S., Canada, Germany, and the UK. The Amazon Ember Artline will be available from 55”–65” starting at $899, including your choice of one of the 10 adjustable color frames. Find the Fire TV that’s right for you—from us or our partners . *Separate subscriptions required to access certain content featured in visuals]]></description>
      <pubDate>Sun, 04 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/new-fire-tv-upgrades-features-2026</guid>
    </item>
    <item>
      <title>Introducing Alexa.com, a completely new way to interact with Alexa+</title>
      <link>https://www.aboutamazon.com/news/devices/alexa-plus-web-ai-assistant</link>
      <description><![CDATA[Key takeaways Alexa.com rolls out to all Alexa+ Early Access customers, bringing the power of Alexa+ to your browser. Alexa.com combines information with real-world actions. It offers seamless integration across devices for cooking, shopping, home control, entertainment, and more. Alexa+ has evolved rapidly since it launched nine months ago . We've integrated with tens of thousands of services and devices, scaled to tens of millions of customers, and have seen people transform the way they use their AI assistant: twice the conversations, three times the purchases, five times the recipe requests. What we've learned is simple: customers want Alexa wherever they are. Today, we're expanding on that vision by rolling out Alexa.com to all Alexa+ Early Access customers. Expedia, Yelp, Angi, and Square to build new agentic experiences for Alexa+ With over 600 million Alexa-enabled devices purchased worldwide, Alexa is already deeply integrated into daily life. But people are finding incredible value in how AI can help in every aspect of their day, and to truly serve as a personal assistant, Alexa+ needs to be available wherever they are—at home, on their phone, and now on the web. Alexa.com brings the full power of Alexa+ right to your browser. You can use Alexa.com to get quick answers, explore complex topics, create content, plan trip itineraries, and get help with homework. But Alexa+ doesn't just provide information, it’s designed to take action. It can help you complete countless tasks: managing your to-do list, updating your family calendar, controlling your smart home, making reservations, and so much more. It also provides persistent context and continuity, allowing you to access Alexa on whichever device or interface best serves the task at hand, with all previous chats, preferences, and personalization seamlessly carrying over. Here are just a few examples of how this comes to life: Meal planning made effortless:Get help handling meal planning end-to-end. Ask Alexa for a full week’s menu and watch as Alexa instantly generates a week of breakfast, lunch, and dinner options with your preferences taken into account like focusing on protein, avoiding sugar or processed foods, and making sure lunches are packable for school. You can ask Alexa to add every item you need to your Amazon Fresh or Whole Foods cart, ready to order, turning hours of work into minutes. Help with life admin:Upload documents, emails, and images to Alexa.com to get help keeping everything organized. Alexa+ can extract the key details from documents, add appointments and information to your calendar, and recall specific details on demand, whether it's remembering when the dog was last vaccinated, tracking the kids' soccer schedules, or keeping tabs on upcoming social events. Easily glance at your Echo Show to see what's coming up today, or pull up your schedule on the go and easily make edits from anywhere. Seamless smart home access:Your smart home controls are in the same window, right next to your chat with Alexa. You can instantly switch from chatting to checking who’s at the front door, turning on the lights, adjusting your thermostat, unlocking the door for a family member, or checking your security cameras while you're away, all without touching a phone or saying a word. Recipe discovery to the dinner table:Alexa+ can remove much of the work that goes into getting dinner on the table. Stumble across a recipe you like? Simply drop the recipe link into Alexa.com, ask Alexa to customize it to your family’s dietary restrictions, and add it to your recipe library. Customers can convert the full recipe into ingredients and have them added to your shopping list with a single request. When you’re ready to cook, have Alexa pull up the recipe on your Echo Show, guide you through each step, and set timers, all while keeping your hands free. Entertainment discovery:Start your movie night planning on Alexa.com, explore themed movie marathons, discover hidden gems, or get personalized recommendations based on what you've loved before. Once you find the perfect pick, Alexa can recall the suggestions on your Fire TV so you can start streaming instantly, reducing the endless scrolling or family debates about what to watch. Quick access to favorite features:A navigation sidebar keeps your most-used Alexa features just one click away—no need to open a different window or switch to another app. Access recent chats to pick up where you left off, jump to smart home controls to adjust your thermostat, check your calendar for upcoming appointments, review your shopping lists, or browse files you've shared with Alexa. It's designed to let you seamlessly move between tasks without losing your place. This is a new interaction model and adds a powerful way to use and collaborate with Alexa+. Combined with the redesigned Alexa mobile app, which will feature an agent-forward design, Alexa+ will be accessible across every surface—whether you're at your desk, on the go, or at home. We’re excited about the potential that new modalities will add to Alexa+, and there’s much more to come with the capabilities and experiences we have planned. To get started, customers with Early Access to Alexa+ can visit alexa.com while logged into their Amazon account and start chatting.]]></description>
      <pubDate>Sun, 04 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/alexa-plus-web-ai-assistant</guid>
    </item>
    <item>
      <title>Building Bee at Amazon: How the wearable AI device is evolving</title>
      <link>https://www.aboutamazon.com/news/devices/bee-amazon-wearable-ai-device-new-features</link>
      <description><![CDATA[Key takeaways Bee learns from conversations, emails, and other information you choose to share to provide personalized insights and suggested actions. After joining Amazon last year, Bee shipped several major features, including Voice Notes, which lets you capture any thought in an instant. The wearable device processes conversations in real-time without storing audio for privacy, delivering ambient AI wherever customers are. Think about all the conversations that happen throughout the day. A meeting where you promised to follow up on an action item or an idea you had during your morning walk that you meant to explore. These are the small moments that make up our lives: our relationships, our intentions, who we are, what we care about. But they're easy to lose track of. They fade in the middle of busy days, forgotten before we can act on them. That's where Bee comes in. It works in the background of your everyday life—in conversations, on the go, in the moments that matter. Amazon’s next-gen AI assistant for shopping is now even smarter, more capable, and more helpful Bee is the wearable AI that understands you. As you wear it throughout the day, it captures your conversations, understands your commitments, and builds a picture of your life that grows richer over time. A single press of the button starts and stops capturing, with a green LED to indicate when the device is recording. There's no setup, no training, no manual input. Bee learns from your daily patterns continuously to provide personalized insights that can empower you throughout your daily life. What we’ve learned Many customers first discovered Bee as a tool to make work and school life easier, to record and manage meetings, lectures, and conversations without frantically taking notes or getting distracted. But we began seeing something unexpected: customers were relying on Bee outside their professional lives, and it unlocked something they didn't know they needed. They started asking questions they'd never been able to ask before. “How can I be a more effective communicator?”, “What commitments have I made that I've lost track of?”, “How am I actually spending my time?” Bee surfaces insights across months of conversations, emails, calendar data, and health metrics from HealthKit—things that would otherwise go unnoticed. It becomes a mirror, one that helps you see patterns you've been living. The way you tend to respond when you're stressed. The commitments you make on Mondays that disappear by Fridays. The gap between how you think you spend your time and how you actually do. Accelerating with Amazon The goal has always been bigger than a single device. We're building toward a future where AI understands and helps you everywhere: at home, on the go, across every surface throughout your day. When we started Bee, we never imagined we'd end up at Amazon. But the more we built, the clearer it became that achieving our wearable AI vision requires a partner with the right scale and deep expertise to bring our wearable AI vision to life. Now at Amazon, we are excited to evolve Bee into the personal AI companion we've always envisioned—building new features and devices that have the potential to reach customers everywhere. We're continuing to move fast. Since joining Amazon, we've shipped several major updates, each bringing this vision closer to reality: Actionsconnect Bee to your email and calendar, turning conversations into outcomes. When you mention needing to send an email or schedule a meeting, Bee can draft the email, create the invite, and handle it for you. Actions is AI that understands your life to make it easier. Daily Insightssurfaces patterns you'd never catch yourself: trends in how you're feeling, shifts in your relationships, themes that recur across weeks and recommends personalized goals to help you act on what matters. Customers tell us this is where Bee feels most personal, like a coach who actually knows their life. Voice Notesenables you to capture any thought in an instant. Press the button, speak your mind, and it's there waiting for you. The fleeting ideas that usually disappear, the reminders you scribble down, the sudden clarity that hits in the middle of a walk. They all become part of Bee's understanding of you, easily accessible whenever you need them. Templateswill deliver intelligent summaries tailored to your specific needs and the setting you’re in. Whether it’s organizing lecture content into study plans for students or a salesperson recapping a client meeting into actionable next steps. Bee automatically formats the summary in the structure that works best for that moment, so you get exactly what you need, when you need it. Getting started with Alexa+: How Alexa+ can keep you and your family organized Privacy has been part of our DNA since Day 1. Bee processes conversations in real-time and no audio is ever stored. Since joining Amazon we have introduced a new layer of privacy, ensuring only customers have access to their transcripts and summaries and no one else—not even Amazon or Bee—can access them unless customers choose to share their data. Customers can also delete their personal data, including transcripts and summaries of conversations, at any time. We’re excited to continue inventing in this space. Building ambient AI Our vision for Bee has always been to deliver AI that understands you, which means integrating into every part of your life: at home, on the go, in the moments that matter wherever they happen. What drew us to Amazon wasn't just the scale, it was the chance to reach customers through the experiences already woven into their lives. We believe that having a shared ambient AI vision made us the perfect fit, with Bee and Alexa serving as natural complements in delivering truly personal and proactive ambient experiences that can serve customers wherever they are. We're continuing to invent rapidly while maintaining our startup spirit, constantly pushing the frontier of personal AI. We couldn't be more excited about this next step in Bee's journey and can’t wait to share more.]]></description>
      <pubDate>Sun, 04 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/bee-amazon-wearable-ai-device-new-features</guid>
    </item>
    <item>
      <title>Amazon invests to bring AI education to 500,000 students nationwide</title>
      <link>https://www.aboutamazon.com/news/community/amazon-future-engineer-ai-education-students</link>
      <description><![CDATA[Key takeaways Amazon is supporting 18 educational partners across seven U.S. regions—including school districts, charter networks, and individual schools—reaching nearly 500,000 students with AI education. Educators will build custom AI tools to support classroom learning, while students design AI-powered solutions to real-world challenges in their communities. The program expanded from initial plans, with Amazon increasing investment to $800,000 through PlayLab AI partnership. When Amazon launched a fund to help schools participate in the White House Presidential AI Challenge , a national initiative to expand AI education, the initial goal was to support a small cohort of districts ready to take the next step in AI education. Future Ready 2030: Amazon expands skills training goal, invests $2.5 billion to prepare 50 million people for the future of work Interest from education partners quickly exceeded the scope of the pilot, demonstrating strong nationwide demand for expanding AI learning opportunities for students and educators. In response, Amazon more than doubled its initial investment to $800,000, expanding support to 18 educational partners. Through a partnership with education nonprofit, Playlab, districts will receive access to custom AI tools for both students and teachers, along with hands-on training to implement AI education that supports each partner’s unique approach to teaching and learning. "The strong response from school districts showed us how many educators are ready to bring AI into the classroom to help students build skills for the future," said Bettina Stix, Amazon's global director of community impact. "By expanding this program, we're helping nearly half a million students access AI education while supporting teachers as they integrate these tools into daily learning.” This initiative builds on Amazon's broader support for the White House's Pledge to America's Youth. Through this commitment, Amazon will support AI skills training for 4 million U.S. learners and enable AI curricula for 10,000 educators by 2028, including up to $30 million in AWS promotional credits and $1.5 million in cash prizes for student winners of the Presidential AI Challenge. STEM Education programs Amazon supports in the U.S. Meeting educators and students where they are The program gives students and educators hands-on experience using AI in ways that directly supports classroom learning and problem solving, building in the PlayLab environment built intentionally to support learning. Rather than taking a one-size-fits-all approach, the program is designed to adapt to each district’s goals and level of readiness. “Together with Amazon, we’re meeting districts where they are,” said Hilah Barbot, head of strategic partnerships at PlayLab. “It gives educators and students the space to experiment with AI in meaningful ways, building skills that are relevant today while preparing for what’s next.” In Fairfax County Public Schools, the district is scaling participation to reach all high school students. In Washington, DC, Amazon and PlayLab hosted a two-day immersive workshop with 60 middle and high school students from Friendship Charter Schools, where students built and tested AI-powered solutions to real challenges in their communities. Other partners are focusing on educator professional development, student innovation projects, or district-wide AI adoption strategies aligned to local priorities. Amazon to invest up to $50 billion to expand AI and supercomputing infrastructure for US government agencies Building AI skills across communities Through this initiative, Amazon Future Engineer is supporting 18 educational partners across seven U.S. regions, spanning large public school districts, charter networks, individual schools, and a state-level education service center. Participating partners include: Public school districts Fairfax County Public Schools (VA) Alexandria City Public Schools (VA) Bellevue School District (WA) Renton School District (WA) Metro Nashville Public Schools (TN) Evanston Township High School District (IL) District of Columbia Public Schools (DC) Charter networks and schools KIPP DC (DC) Friendship Charter Schools (DC) Distinctive Schools (IL) Intrinsic Schools (IL) KIPP Atlanta (GA) Kingsman Academy (DC) Center City Public Charter School (DC) Washington Leadership Academy (DC) Nashville Classical (TN) Charles R. Drew Charter School (GA) State-level education service center Learning Technology Center of Illinois (IL) Learn more about Amazon Future Engineer and Amazon's commitment to education and skills development.]]></description>
      <pubDate>Sun, 21 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/community/amazon-future-engineer-ai-education-students</guid>
    </item>
    <item>
      <title>Alexa+ can now answer your Ring doorbell and talk to visitors</title>
      <link>https://www.aboutamazon.com/news/devices/alexa-ring-doorbell-ai-greetings</link>
      <description><![CDATA[Key takeaways Alexa+ enables your Ring doorbell to chat naturally with anyone at your door. You can customize how Alexa greets delivery personnel and unexpected visitors. Alexa+ manages your front door and alerts you to events instantly, wherever you are. Amazon is launching Alexa+ Greetings—a feature that transforms your Ring doorbell into an intelligent assistant capable of determining who's at your door, understanding what they need, and responding conversationally, whether you're home, away, or simply don't want to be interrupted. What is Alexa+ Greetings? Alexa+ Greetings combines Ring Video Descriptions * with Alexa's conversational capabilities to create an experience that's intelligent and intuitive. When someone rings your doorbell, Ring's camera determines who’s there based on what they’re wearing, holding, or their actions. For example, it can distinguish a person in a delivery uniform dropping off a package from someone casually stopping by asking to speak with the resident. Alexa uses this visual context, any information the visitor shares, and the instructions it’s been given to help manage interactions on your behalf. Ring introduces its first-ever 4K cameras and AI feature that helps find lost pets How to personalize Alexa+ Greetings In the Ring app, tap “AI Features” from the menu tab and toggle on Alexa+ Greetings. Once enabled, set personalized instructions through any Alexa-enabled device like an Echo, Fire TV, or the Alexa app. Just tell Alexa what you want it to say, such as "If I get any deliveries during the weekend, tell them to leave it by the back door," and it will remember. Alexa+ Greetings also contains some pre-set greetings that handle common scenarios like delivery personnel being asked to place packages out of sight. You can also check your current settings anytime by asking, "What are my greetings instructions?" or "What will you tell my visitors at the door?" Ways to use Alexa+ Greetings Managing deliveries when you're occupied: Alexa can thank drivers, let them know you'll grab the order soon, or direct them to water or snacks you've left out. Tell Alexa beforehand where you want packages placed “through the side gate and on the back porch" or "put it on the bench by the door out of sight," and it will relay those instructions. Alexa can also handle follow-up questions naturally. If the delivery driver asks about a signature or needs clarification on backyard access, Alexa can respond in the moment and pass along important details. Handling interruptions gracefully: Alexa+ Greetings can help handle door-to-door sales interruptions. When someone selling a product or service arrives, Alexa can deliver a message on your behalf. Tell Alexa something like, "If someone comes to the door trying to sell something, politely let them know we're not interested." Alexa can courteously handle the interaction while you carry on with your day, whether you're working from home, in the middle of a call, or simply don't want to be disturbed. Helping Friends and Family When You're Not Available: When friends or family stop by unexpectedly while you're occupied, Alexa can make the interaction feel warm and intentional. Whether you're in the middle of a work call or helping kids with homework, Alexa can greet visitors and say, "I'll let them know you stopped by—would you like to leave a message?" They aren’t left wondering and you have the full context when you follow up. Stay in the know while away: Alexa can manage every visitor interaction and keeps you fully informed. When a neighbor stops by looking for a misdelivered package or a contractor arrives for an estimate, Alexa asks about the purpose of their visit and captures detailed messages. You can review these messages alongside the video footage in your Ring app for complete context about who came by, what they needed, and when to follow up. It's like having a trusted assistant at your front door 24/7. Getting started with Alexa+: How Alexa+ can keep you and your family organized Smarter home management Your doorbell is no longer just a way to know someone's at the door; it's now an intelligent assistant that helps you manage visitors. Alexa's responses are crafted to be helpful without revealing your home status, and doorbell interactions are separate from your smart home controls. You maintain complete control over when and how Alexa responds, ensuring your home stays both welcoming and secure. Alexa+ Greetings is rolling out to Alexa+ Early Access customers today in the U.S. and Canada (English only). It’s available on Ring Wired Doorbell Pro (3 rd Gen) and Ring Wired Doorbell Plus (2 nd Gen) with Ring Premium Plan and Video Descriptions enabled. *Compatible Ring subscription required (sold separately). For customers in Illinois: Smart Video Search is not available on Ring devices due to specific state legislation. Next, discover 50 things to try with Alexa+ .]]></description>
      <pubDate>Wed, 17 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/alexa-ring-doorbell-ai-greetings</guid>
    </item>
    <item>
      <title>Andy Jassy makes Amazon leadership announcement</title>
      <link>https://www.aboutamazon.com/news/company-news/andy-jassy-peter-desantis-amazon-leadership-update</link>
      <description><![CDATA[The message below was shared with Amazon employees earlier today. At Amazon, we often start new businesses in parts of the company where there’s an initial customer need, and as they grow and get momentum, we assess where they’re best situated to maximize potential for customers and Amazon over the long term. I believe we are at this inflection point with several of our new technologies that will power a significant amount of our future customer experiences. I’ve asked Peter DeSantis to lead a new organization that drives our most expansive AI models (e.g. Nova—and the team we’ve called “AGI”), silicon development (e.g. Graviton, Trainium, Nitro), and quantum computing. I cannot think of a better leader for this organization than Peter. Peter has been at Amazon for over 27 years, and led some of the most transformative technologies in computing history. Peter was the leader of Amazon EC2 when we launched this revolutionary service in 2006, and built out that excellent team over many years. Under his leadership, we launched Block Storage, File Storage, Load Balancing, Networking, and Monitoring services that AWS customers continue to rely on to run their infrastructure. In 2015, Peter spearheaded the acquisition of Annapurna Labs, our outstanding team that builds our custom silicon, and continues to manage that team. In 2016, we asked Peter to lead our AWS Infrastructure team, who’s responsible for all of our data centers, networking, hardware, and associated supply chain. To give you an idea of scale, our infrastructure stretches across 38 geographic regions and 120 Availability Zones around the world. In 2021, Peter moved to lead all of our AWS Utility Computing services (e.g., compute, storage, database, analytics, various AI services, messaging, etc.), the combination of which is widely recognized as the industry leader and standard-setter in the cloud. Peter combines unusual technical depth with a track record of solving problems at the edge of what’s technically possible—and delivering technologies that operate reliably at massive scale. Peter embodies our leadership principles. His ability to invent, think big but be neck-deep in the details, insist on the highest standards, learn and be curious, focus on what matters to customers, and be right much of the time are among the many traits that make him so effective. With our Nova 2 models just launched at re:Invent, our custom silicon growing rapidly, and the advantages of optimizing across models, chips, and cloud software and infrastructure, we wanted to free Peter up to focus his energy, invention cycles, and leadership on these new areas. Peter will report directly to me. As part of this organizational change, Pieter Abbeel will lead our frontier model research team (the team that builds the base model) in AGI. Pieter is one of the world's leading AI researchers, and co-founder of Covariant, which pioneered the first commercial foundation model for robotics. His deep expertise in generative AI and reinforcement learning makes him well-suited to advance Amazon's AI research as we push the boundaries of what's possible for customers. Pieter will also continue his ongoing work with our Robotics team. Peter will share the rest of the organizational design shortly. Peter’s very strong leaders in AWS Utility Computing will continue to lead what they’ve been leading, with a few additional responsibilities. Matt Garman will share the new AWS structure in a follow-up note. Finally, I want to recognize Rohit Prasad, who has decided to leave Amazon at the end of this year. Rohit joined Amazon in 2013, during the early days of Alexa, to help us build a conversational AI that could make customers' lives easier. Rohit helped Alexa grow from an ambitious idea into a service that now touches hundreds of millions of customers' lives every day. For the past two years, Rohit has led the creation of Amazon Nova and our AGI organization, building twelve state-of-the-art foundation models with industry-leading price-performance that are now being used by tens of thousands of companies across almost all industries and use cases. Rohit has built a strong team, differentiated technology, growing customer momentum, and a culture of ambitious invention. He’s been missionary, passionate, and selfless, and I'm grateful for his leadership, his technical vision, and everything he's built here. Thank you, Rohit. The path ahead is full of opportunity. With the foundation that's been built, the traction we’re seeing, and Peter's leadership bringing unified focus to these technologies, we're well-positioned to lead and deliver meaningful capabilities for our customers. I'm excited about what this team will build and how these foundational technologies will help shape Amazon's future. Andy]]></description>
      <pubDate>Tue, 16 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/company-news/andy-jassy-peter-desantis-amazon-leadership-update</guid>
    </item>
    <item>
      <title>New Kindle feature offers instant spoiler-free answers to questions about your books</title>
      <link>https://www.aboutamazon.com/news/books-and-authors/kindle-recaps-feature-ebook-series-refreshers</link>
      <description><![CDATA[Key takeaways Ask this Book lets you ask questions about the book you’re reading and receive spoiler-free answers. The feature answers questions about the plot, characters, and other relevant details. Ask this Book is available on the Kindle iOS app for U.S. customers and will come to Kindle devices and Android OS next year. Amazon is making it easier for you to stay immersed in your books with Ask this Book, a new feature available to U.S. customers on the Kindle iOS app. Highlight any passage in a book you’ve bought or borrowed, and Ask this Book allows you to ask questions about what you’re reading, right on the page. The feature is currently enabled for thousands of English-language best-selling Kindle books and only reveals information up to your current reading position. Kindle buying guide: Find out which device is right for you How can Ask this Book enhance your reading? This feature serves as your expert reading assistant, instantly answering questions about plot details, character relationships, and thematic elements without disrupting your reading flow. All responses provide immediate, contextual, spoiler-free information. Where is this feature available? Ask this Book is currently available for thousands of English-language books on the Kindle iOS app in the U.S. The feature will be enabled on Kindle devices and Android OS next year. How can I get started? Find Ask this Book in the in-book menu or simply highlight any passage as you read. From there, tap one of the suggested questions or type your own to get instant answers. You can also keep the conversation going with follow-up questions. What else launched recently for Kindle readers? For fans of book series, recalling plots and characters after a long reading break or a wait between new releases can be a challenge. Kindle’s “Recaps” feature works much like the “Previously on…” segment before a TV show. Available on both Kindle devices and the Kindle app for iOS in the U.S., Recaps makes it easier for you to dive into the next book in your favorite series by providing a quick refresher on storylines and character arcs in Kindle books you own or have borrowed. Amazon introduces Kindle Translate, an AI-powered translation service for authors to reach global readers To access a full book recap for supported Kindle books in series, look for the “View Recaps” button in the series page in your Kindle Library. On Kindle devices, you can select “View Recaps” from the three-dot menu within the series grouping, while on the Kindle iOS app, this same option appears when you press and hold the series grouping. Next, check out the redesigned Kindle Scribe lineup with first-ever color Scribe .]]></description>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/books-and-authors/kindle-recaps-feature-ebook-series-refreshers</guid>
    </item>
    <item>
      <title>Amazon unveils redesigned Kindle Scribe lineup with first-ever color Scribe</title>
      <link>https://www.aboutamazon.com/news/devices/new-amazon-kindle-scribe-color</link>
      <description><![CDATA[Key takeaways Amazon introduces an all-new Kindle Scribe lineup, completely reimagined from the ground up for productivity. Kindle Scribe Colorsoft offers a color writing experience that’s fast, fluid, and easy on the eyes. Kindle Scribe and Kindle Scribe Colorsoft are available now, with the Kindle Scribe without a front light coming in 2026. Today, we’re thrilled to reveal our new Kindle Scribe lineup, reimagined for productivity: Our next-generation Kindle Scribe with and without a front light, and the first-ever color Kindle Scribe. A new paper-like design that’s thinner, lighter, and faster The new Kindle Scribe has a beautiful new design that’s just like paper—it’s ultra-thin at 5.4mm, ultra-light at 400g, and 40% faster for writing and page turns. The larger 11-inch glare-free display mirrors the proportions of a sheet of paper and feels just like you’re writing on one—it’s the perfect size for reviewing full-sized documents, feels natural for notetaking, and is easy to take with you wherever you go. Our new lineup is packed with innovation: A new front light system with miniaturized LEDs that fit tightly against the display to create a narrower bezel and uniform lighting. A new texture-molded glass to improve the friction when the pen glides across the screen—unlike tablets that often feel slippery or glassy. A rearchitected display stack to shrink the parallax to virtually nothing, so it feels like writing directly on the page. A new quad-core chip, more memory, and our latest Oxide display technology to make everything feel snappier. Answers to all your questions about the Kindle Unlimited reading membership A color writing experience that’s easy on the eyes Kindle Scribe Colorsoft features the same new design and provides a fluid color writing experience. To create colors that are soft and don’t hurt your eyes like an LCD display, we used our custom-built Colorsoft display technology, which has a color filter and light guide with nitride LEDs to enhance color without washing out the details. To deliver an incredible color writing experience, we developed a new rendering engine, which enhances the color and ensures writing is fast, fluid, and totally natural. Plus, Kindle Scribe Colorsoft provides weeks of battery life and doesn’t have any distracting apps or notifications to pull you away from your thoughts. All-new productivity features including an AI-powered notebook Our new lineup offers a powerful AI-powered notebook and redesigned software and tools that help you be more productive. All-new Home: From our all-new Home, we’ve added Quick Notes so you can easily jot something down whenever inspiration strikes. You can also open recently opened and added books, documents, and notebooks. Access all your docs: With support for Google Drive and Microsoft OneDrive, it’s easy to import documents for mark-up and export annotated PDFs. AI-powered search: Search your notes naturally across your notebooks and you’ll get simple AI summaries. You can also dig deeper with follow-up questions. Send to Alexa+: Early next year, you’ll be able to send your notes and documents from Kindle Scribe to Alexa+ and have a conversation about them. Share notebooks with OneNote: Export your notes as converted text or as an embedded image to OneNote so you can keep them all in one place and keep editing from your laptop. Color pens and highlights: Write, draw, and annotate in one of 10 pen colors or highlight in one of 5 highlighter colors. Shading: Artists and creators can create smooth gradients and subtle tones with our new shader tool, giving you even more control over the depth and richness of your art. Workspace: Organize your documents, notebooks, books, and more in the same folder. New Kindle feature offers instant spoiler-free answers to questions about your books Everything our customers love about Kindle Kindle Scribe is a notebook and a Kindle all in one with access to the world's best e-book store. It includes a 3-month subscription to Kindle Unlimited, as well as our latest reading features. We’re adding new AI-powered reading features that preserve the magic of reading on Kindle. Story So Far lets you catch up on the book you’re reading—but only up to where you’ve read without any spoilers. For our endlessly curious readers, Ask this Book will let you highlight any passage of text while reading a book and get spoiler-free answers to questions about things like a character’s motive or the significance of a scene. These features will be available for thousands of Kindle books in the U.S. You’ll be able to access these features on books you’ve purchased or borrowed on the Kindle iOS app later this year and on Kindle devices early next year. How Amazon tests Kindle devices and more in this innovation lab Pricing and availability All of our devices come with a new pen that feels amazing in your hands, seamlessly attaches to Kindle Scribe so you never lose it, and still never needs to be charged. We're also introducing a range of new folio covers, crafted in plant-based and premium leather, and an all-new executive notebook-style folio. Kindle Scribe is available starting at $499.99 and Kindle Scribe Colorsoft is available starting at $629.99. Kindle Scribe without a front light will be available next year for $429.99. All three products will be available in the UK and Germany next year. Next, learn about Kindle Scribe’s Gen AI features that make organizing and sharing your notes a snap.]]></description>
      <pubDate>Tue, 09 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/new-amazon-kindle-scribe-color</guid>
    </item>
    <item>
      <title>Frontier agents, Trainium chips, and Amazon Nova: key announcements from AWS re:Invent 2025</title>
      <link>https://www.aboutamazon.com/news/aws/aws-re-invent-2025-ai-news-updates</link>
      <description><![CDATA[Last updated: December 4, 2025 AWS unveiled a wave of innovations at re:Invent 2025, including Graviton5 —the company's most powerful and efficient CPU. Other announcements include frontier agents that can work autonomously for days, an expansion of the Amazon Nova model family , the availability of Trainium3 UltraServers , and AWS AI Factories for implementing AI infrastructure in customers' existing data centers. re:Invent 2025 wrapped up with a special closing keynote by Amazon CTO Werner Vogels . See the key announcements from the event below and watch re:Invent 2025 keynotes . AWS introduces Graviton5—the company's most powerful and efficient CPU As cloud workloads grow in complexity, organizations face a persistent challenge: delivering faster performance, lower costs, and meeting sustainability commitments without trade-offs. AWS is introducing Graviton5 processors —the company's most advanced custom chip for a broad set of cloud workloads. New Graviton5-based Amazon EC2 M9g instances deliver up to 25% higher performance than the previous generation, with 192 cores per chip and 5x larger cache. For the third year in a row, more than half of new CPU capacity added to AWS is powered by Graviton, with 98% of the top 1,000 EC2 customers—including Adobe, Airbnb, Epic Games, Formula 1, Pinterest, SAP , and Siemens—already benefiting from Graviton's price performance advantages. Learn more . Amazon expands Nova family of models and pioneers “open training” with Nova Forge Amazon is expanding its Nova portfolio with four new models that deliver industry-leading price-performance across reasoning, multimodal processing, conversational AI, code generation, and agentic tasks. Nova Forge pioneers "open training," giving organizations access to pre-trained model checkpoints and the ability to blend proprietary data with Amazon Nova-curated datasets. Nova Act achieves breakthrough 90% reliability for browser-based UI automation workflows built by early customers. Companies like Reddit are using Nova Forge to replace multiple specialized models with a single solution, while Hertz accelerated development velocity by 5x with Nova Act. Learn more . AWS unveils 3 frontier agents, a new class of AI agents that work as an extension of your software development team Frontier agents represent a step-change in what agents can do. They’re autonomous, scalable, and can work for hours or days without intervention. AWS is announcing three frontier agents—Kiro autonomous agent, AWS Security Agent, and AWS DevOps Agent. Kiro autonomous agent acts as a virtual developer for your team, AWS Security Agent is your own security consultant, and AWS DevOps Agent is your on-call operational team. Companies including Commonwealth Bank of Australia, SmugMug, and Wester Governors University that have used one or more of these agents to transform the software development lifecycle. Learn more . Trainium3 UltraServers enable customers to train and deploy AI models faster at lower cost As AI models grow in size and complexity, training cutting-edge models requires infrastructure investments that only a handful of organizations can afford. Amazon EC2 Trn3 UltraServers , powered by AWS's first 3nm AI chip, pack up to 144 Trainium3 chips into a single integrated system, delivering up to 4.4x more compute performance and 4x greater energy efficiency than Trainium2 UltraServers. Customers achieve 3x higher throughput per chip while delivering 4x faster response times, reducing training times from months to weeks. Customers including Anthropic, Karakuri, Metagenomi, NetoAI, Ricoh, and Splash Music are reducing training and inference costs by up to 50% with Trainium, while Decart is achieving 4x faster inference for real-time generative video at half the cost of GPUs, and Amazon Bedrock is already serving production workloads on Trainium3. Learn more . AWS simplifies model customization to help customers build faster, more efficient AI agents Running AI applications at scale remains expensive and resource-intensive, particularly for AI agents that spend significant time on routine tasks that don't require advanced intelligence. AWS is announcing new Amazon Bedrock and Amazon SageMaker AI capabilities that make advanced model customization accessible to any developer. Reinforcement Fine Tuning (RFT) in Amazon Bedrock simplifies the model customization process, delivering 66% accuracy gains on average over base models, with customers like Salesforce demonstrating up to 73% improvement in accuracy over base models. Amazon SageMaker AI now supports serverless model customization capabilities that accelerate workflows from months to days, with customers like Collinear AI cutting experimentation cycles from weeks to days. AWS AI Factories transform customers' existing infrastructure into high-performance AI environments Building high-performance AI infrastructure requires massive capital investments in GPUs, data centers, and power, creating multi-year timelines that divert focus from core business goals. AWS AI Factories provides enterprises and government organizations with dedicated AWS AI infrastructure deployed in their own data centers, combining NVIDIA GPUs, Trainium chips, AWS networking, and AI services like Amazon Bedrock and SageMaker AI. This approach lets organizations leverage existing data center space and power while meeting data sovereignty and regulatory requirements. AWS and NVIDIA are expanding their 15-year collaboration to deliver this infrastructure and already support customers like HUMAIN in Saudi Arabia, which is building an "AI Zone" featuring up to 150,000 AI chips in a purpose-built data center. Learn more . AWS Transform now modernizes legacy code and applications up to 5x faster Most organizations spend 30% of their team's time on tech debt—manual modernization work that takes valuable resources away from innovation. AWS Transform is adding new agentic AI capabilities that help companies modernize any code and application , including custom programming languages and applications specific to their organization. The service can now handle full-stack Windows modernization across .NET apps, SQL Server, and user interface frameworks, and deployment layers, eliminating up to 70% of maintenance and licensing costs. Companies like Air Canada have already used the service to modernize thousands of Lambda functions in just days, achieving an 80% reduction in time and cost compared to manual migration. Learn more . Amazon Bedrock AgentCore helps developers build production-ready AI agents with new policy, evaluation, and memory capabilities Amazon Bedrock AgentCore is launching Policy in preview, allowing teams to set clear boundaries for agent actions using natural language. AgentCore Evaluations simplifies monitoring agent behavior with 13 pre-built evaluators for dimensions like correctness and safety, continuously sampling live interactions to trigger alerts when performance drops. Additionally, AgentCore Memory introduces new episodic functionality that helps agents learn from past experience. Learn more . Simplifying purpose-built AI infrastructure with Amazon Bedrock AgentCore Amazon Bedrock AgentCore is the most advanced platform for building and deploying agents securely at scale. To move agents from prototype to production, companies need infrastructure that is secure, reliable, scalable, and purpose-built for the non-deterministic nature of agents. Agents need a foundation that scales dynamically, supports long-running workloads, and allows them to store and retrieve context instantly and securely. Today, early adopters are diverting significant resources to build this infrastructure from scratch, a labor-intensive and time-consuming process that slows down development cycles. Amazon Bedrock AgentCore addresses these challenges by offering essential, fully managed services. AgentCore supports any framework (like CrewAI, LangGraph, LlamaIndex, Google ADK, OpenAI Agents SDK, and Strands Agents) or model while handling critical agentic AI infrastructure needs. In just five months since preview, organizations including Amazon Devices Operations & Supply Chain, Cohere Health, Cox Automotive, Heroku, Natera, MongoDB, PGA TOUR, Pulumi, Thomson Reuters, Workday, Snorkel, and Swisscom are already using AgentCore to build agents, and developers have downloaded it more than 2 million times. Bedrock AgentCore customer momentum PGA TOUR, a pioneer and innovation leader in sports, has built a multi-agent content generation system to create articles for its digital platforms. The new solution, built on AgentCore, enables the PGA TOUR to provide comprehensive coverage for every player in the field by increasing content writing speed by 1,000% while achieving a 95% reduction in costs. MongoDB, a database platform, leveraged AgentCore to reshape how it designed and operationalized AI within the company. Through AgentCore's implementation, the company eliminated weeks of evaluation cycles and consolidated multiple disparate tools into a single, production-ready solution. By seamlessly integrating MongoDB's AWS infrastructure and utilizing MongoDB Atlas as the embedded Knowledge Base for Amazon Bedrock, its development teams deployed an agent-based application in just eight weeks. This process previously took months of infrastructure work and continuous maintenance. This streamlined approach enabled MongoDB to scale its AI initiatives with greater accuracy, contextual awareness, and consistency, while significantly reducing manual overhead. Swisscom, Switzerland's leading telecoms provider, selected AgentCore to deploy containerized agents with AgentCore Runtime for scalable hosting, AgentCore Identity for seamless authentication across systems, and AgentCore Memory for tracking customer interactions. By standardizing how agents are built, deployed, and integrated, Swisscom now has an enterprise-grade foundation that lets teams focus on business problems instead of infrastructure. With AgentCore and Strands, the company launched their business-to-consumer agent solution in just four weeks, focusing on personalized sales assistance and automated technical support. Learn more . Kiro powers: Access specialized expertise to accelerate software development As developers increase their use of AI agents for a wider range of software development tasks, they want agents that have deep knowledge of the tools they use every day and that are specialized in their workflows, like user interface or application programming interface development. Kiro powers enable developers to give Kiro agents instant expertise in these tools and workflows in a single click. Powers can be comprised of a combination of MCP servers for specialized tool access, steering files with best practices, and hooks to trigger specific actions helping developers equip Kiro agents with workflow-specific knowledge spanning the application lifecycle: design, development, deployment, and observability. By loading only when needed, powers help developers work with efficient token usage, precision, and speed. Developers can build with expertise in their everyday tools using Kiro powers from Datadog, Dynatrace, Figma, Neon, Netlify, Postman, Stripe, Supabase, and AWS—with more to come. Developers can also create and share their own powers with the community. Learn more about Kiro powers and review this documentation . Checkpointless training on SageMaker HyperPod: recover from model training faults in minutes Amazon SageMaker HyperPod simplifies infrastructure management for model training and deployment, reducing costs by up to 40%. As training scales across hundreds or thousands of accelerators, faults like hardware or software failures can occur. Traditional checkpoint-based recovery can take up to an hour, which is expensive, consumes storage, and leaves multi-million-dollar compute clusters idle during recovery. AWS is announcing checkpointless training on SageMaker HyperPod—automatically recovering from infrastructure faults in minutes with zero manual intervention, enabling training cluster efficiency of up to 95% on clusters with thousands of AI accelerators. Checkpointless training continuously preserves model state across the training compute cluster. When faults occur, the system automatically swaps out faulty components and recovers training using a peer-to-peer transfer of model and optimizer states from nearby healthy accelerators—mitigating lengthy downtime so teams can focus on building the best AI model for their use case. Learn more about checkpointless training on SageMaker HyperPod . Strands Agents SDK now in Typescript (preview) AWS is bringing Strands Agents, the open source, model-driven, AI agent framework to TypeScript, one of the world’s most popular programming languages and communities. Developers love TypeScript because it catches errors early and provides powerful tooling while still letting them write familiar, flexible JavaScript. Strands provides full support for key TypeScript features, including type safety, async/await, and modern JavaScript/TypeScript patterns. Originally available in Python with over 3M downloads, AWS is extending Strands Agents to give developers the ability to build their entire agentic stack in TypeScript using the AWS CDK. Head to the Strands Agents Github to join the millions of developers who are building today. Strands adds support for edge devices AWS is announcing the general availability of Edge Device support for Strands Agents. With edge device support, customers can use the Strands Agents SDK to create autonomous AI agents that can run on small-scale devices, unlocking new agentic use cases in automotive, gaming, and robotics. Developers can also implement bi-directional streaming capabilities and run agents using local models like Ollama and Llama.cpp. Head to the Strands Agents Github to join the millions of developers who are building today. Amazon Bedrock’s largest expansion of new models to date AWS added 18 new open weight models to Amazon Bedrock, reinforcing its commitment to offering a broad selection of fully managed models from leading AI providers. With access to top models and the flexibility to swap them without rewriting code, Amazon Bedrock makes it fast and easy for customers to evaluate, test, and adopt new models, so they can find the best option for their use case—all without disrupting production systems. The news includes the launch of two new sets of models, available first in Amazon Bedrock, from Mistral AI. Mistral Large 3 is Mistral AI’s most advanced open weight model optimized for long-context, multimodal, and instruction reliability, and Ministral 3 is a series of models that set a new benchmark for compact, general-purpose, and multimodal AI. The launch also features other popular models, including Google’s Gemma 3, MiniMax’s M2, NVIDIA’s Nemotron, OpenAI’s GPT OSS Safeguard, and more. Additionally, Amazon announced the release of its Nova 2 family of models, providing industry-leading price-performance across reasoning, multimodal processing, and conversational AI. Read more for the latest on Amazon Nova . Learn more about the new models available in Amazon Bedrock . AWS launches new Amazon EC2 instance powered by NVIDIA GPUs AWS is expanding its accelerated computing portfolio with P6e-GB300 UltraServers, featuring NVIDIA GB300 NVL72, the most advanced NVIDIA GPU architecture in Amazon EC2. Offering the highest GPU memory and compute within an UltraServer on AWS, the P6e-GB300 is ideal for AI inference at scale, supporting trillion-parameter models with reasoning capabilities in production. The P6e-GB300 UltraServers are powered by the AWS Nitro System, making them highly performant, secure, and reliable, and can integrate seamlessly with AWS services such as Amazon Elastic Kubernetes Service (EKS). Get started with P6e-GB300 UltraServers, visit Amazon EC2 or contact your AWS sales representative. AWS Lambda Managed Instances: The benefits of serverless without constraints Customers rely on Lambda to build serverless applications because of its simplicity, automatic scaling, and intuitive operational model. But they also need consistent, massive compute and precise control of the infrastructure to use Lambda for use cases like analytics pipelines, financial risk modeling, and multiplayer games. AWS Lambda Managed Instances bridges the gap between serverless simplicity and infrastructure control, allowing customers to run their Lambda functions on the Amazon EC2 instance of their choice. Customers will now have access to the exact compute power they need and immediately benefit from the latest hardware and pricing of EC2. Whether processing video, running complex algorithms, or handling other demanding tasks, developers can set desired utilization levels, and AWS will automatically adjust the fleet size according to demand, while building with the familiar Lambda programming model they use today. With Lambda Managed Instances, developers have ultimate control of their Lambda’s performance characteristics, allowing them to provide the best experiences to their end users. Learn more about AWS Lambda Managed Instances . AWS Lambda durable functions enables reliable multi-step applications and AI workflows Each month, over 1.8 million customers use AWS Lambda to process more than 15 trillion requests. Developers rely on Lambda to quickly build functions to run code, but also want to build multi-step applications that execute reliably over extended periods, like payment processing, customer onboarding, or orchestrating AI workflows. AWS Lambda durable functions empowers customers to create Lambda functions that can preserve their progress despite interruptions and allow them to suspend execution for up to a year. Lambda tracks the progress of the function, ensuring reliable execution through pauses or interruptions, with built-in error handling and automatic failure recovery. Now developers can use Lambda to build reliable, long-running multi-step applications and AI workflows, opening it to an entirely new set of use cases. Learn more about AWS Lambda durable functions . Amazon GuardDuty Extended Threat Detection now supports EC2 and ECS environments Modern cloud environments are dynamic and distributed, often running virtual machine, container, and serverless workloads at scale. Building on existing support for detecting compromised IAM credentials, Amazon S3 buckets, and Amazon EKS, GuardDuty Extended Threat Detection now expands to Amazon EC2 and Amazon ECS, providing broader visibility into sophisticated attack sequences and enabling faster remediation across a customer’s AWS environment. GuardDuty Extended Threat Detection uses AI and machine learning models trained at AWS scale to correlate signals such as anomalous process creation, persistence attempts, reverse-shell activity, and crypto-mining into a single, critical-severity event instead of separate alerts that each trigger a siloed investigation. Each finding includes an incident summary and a timeline of events mapped to MITRE ATT&CK® tactics and remediation recommendations. This end-to-end view surfaces potential compromises along with the associated severity level to help teams accelerate incident response across AWS compute environments. Review the AWS News Blog , Services Page , and Documentation for more information. Amazon S3 Vectors scales to two billion vectors per index Amazon S3 Vectors is now generally available with significant scale and performance improvements, enabling AI systems to store and query vectors natively in Amazon S3 for semantic search and context understanding. Designed to provide the same elasticity, scale, and durability as Amazon S3, S3 Vectors scales up to two billion vectors per index (40x preview capacity), supports up to 20 trillion vectors per bucket, delivers 2-3x faster frequent-query performance, and reduces costs by up to 90% over alternatives—eliminating overhead for customers building AI applications. S3 Vectors brings these capabilities to customer data and integrates with Amazon Bedrock Knowledge Bases and Amazon OpenSearch Service, making it easy to build AI agents, RAG systems, inference pipelines, and semantic search applications that understand context and intent. Customers like BMW Group, MIXI, Precisely, Qlik, and Twilio are using S3 Vectors to accelerate AI search and power recommendation systems at scale—without the complexity or cost of managing a dedicated vector infrastructure. Learn more about S3 Vectors in the AWS News Blog , What’s New Post , PDP , documentation , and demo video . Increased maximum Amazon S3 object size Data volumes have surged in recent years, with Amazon S3 now storing more than 500 trillion objects and hundreds of exabytes of data. As individual objects also grow larger, AWS is increasing the maximum S3 object size 10x from 5TB to 50TB, so customers can store massive data files like high-resolution videos, seismic data, and AI training datasets as single objects in their original form—simplifying workflows while maintaining full access to all S3 storage classes and features. Learn more about increased S3 maximum object size in the What’s New post and documentation . Faster Amazon S3 Batch Operations AWS has accelerated Amazon S3 Batch Operations for large jobs to run up to 10x faster, delivering the speed that customers demand for large-scale data processing and time-sensitive data migrations. With S3 Batch Operations, customers can perform batch workloads such as replicating objects across AWS Regions for backup or disaster recovery, tagging objects for S3 Lifecycle management, and computing object checksums to verify the content of stored datasets, at a scale of up to 20 billion objects in a job. Learn more about S3 Batch Operations in the What’s New post , product overview page , and documentation . Amazon S3 Tables optimize storage costs and enable automatic replication Since launch, Amazon S3 Tables for Apache Iceberg workloads has quickly grown to more than 400,000 tables. S3 Tables has launched over 15 new features and capabilities in the last 12 months, rapidly innovating on S3 native Iceberg support for data lakes. Today, AWS is adding two major capabilities to S3 Tables: support for the Intelligent-Tiering storage class and automatic replication across AWS Regions and accounts. Intelligent-Tiering brings the same automatic cost optimization that has saved S3 customers more than $6 billion. It automatically optimizes table data across three access tiers (Frequent Access, Infrequent Access, and Archive Instant Access) based on access patterns—delivering up to 80% storage cost savings without performance impact or operational overhead. Automatic replication enables distributed teams to query local data for faster performance while maintaining consistency across Regions and accounts. Customers can now automatically replicate tables, eliminating manual updates and complex syncing—simplifying compliance and backup management while keeping complete table structures intact and ready to use. Learn more about these new S3 Tables capabilities in the AWS News Blog , product overview page , and explainer video . Learn more about Intelligent-Tiering for S3 Tables in the What’s New post and documentation and automatic replication for S3 Tables in the What’s New post and documentation . Amazon FSx for NetApp ONTAP data accessible from Amazon S3 AWS is expanding Amazon S3 Access Points to support Amazon FSx for NetApp ONTAP so that customers can access the files they store in FSx as if the data were in S3. Customers can now use the data they store in FSx for NetApp ONTAP with AWS's AI, ML, and analytics services that are built to work with S3 data—such as Amazon Bedrock Knowledge Bases, Amazon SageMaker, and Amazon Athena. With this integration, customers with NetApp ONTAP enterprise data on premises can easily migrate to FSx for NetApp ONTAP and start using that data with all S3 compatible tools and applications for analytics and AI. Learn more about S3 Access Points for FSx for NetApp ONTAP in the AWS News Blog , What’s New Post , PDP , documentation , and explainer video . AWS unifies security, operations, and compliance data in CloudWatch Logs are the lifeblood of any operations team, but with so many sitting across a number of disparate systems, it can be hard to derive accurate and actionable insights. Often, organizations face data duplication, complex ETL pipelines, and extended resolution times as a result. Starting today, Amazon CloudWatch is introducing a new unified data store for operational, security, and compliance data. CloudWatch now simplifies log data ingestion with automated collection from AWS and third-party sources like CrowdStrike, Microsoft Office 365, and SentinelOne, and stores it in S3 Tables, so it’s fast and easy to use logs to investigate issues, find root causes, flag anomalies, and unlock new insights from applications. Learn more about the updates at Amazon CloudWatch . AWS eliminates local storage provisioning for EMR Serverless AWS is introducing Amazon EMR Serverless, which eliminates local storage provisioning for Apache Spark workloads, reducing data processing costs by up to 20%. Customers will no longer need to configure local disk type and size for each application or manage storage capacity for jobs, as the service automatically scales to handle shuffle operations. By automatically managing storage resources, EMR Serverless dynamically adjusts based on workload requirements, helping prevent job failures and performance bottlenecks from disk constraints while ensuring more reliable execution of Apache Spark jobs for data-intensive applications. Learn more about Amazon EMR Serverless AWS announces Database Savings Plans Customers can now reduce their database costs by up to 35% with Database Savings Plans—a new flexible pricing model that applies when they commit to a consistent amount of usage over a one-year term. Customers can purchase Database Savings Plans through the AWS Cost Management Console with savings automatically applied to eligible database workloads. SmugMug and Vanguard are among the first customers using Database Savings Plans, benefiting from these cost savings. Learn more about Database Savings Plans on the AWS Database Blog . Keeping AWS the best place to run commercial databases AWS now supports 4x more storage for Amazon RDS for SQL Server and RDS for Oracle—increasing capacity from 64 TiB to 256 TiB with a 4x improvement in IOPS and I/O bandwidth. Both io2 and GP3 storage volumes can be used together to optimize price performance for larger workloads. With RDS for SQL Server Optimize CPUs, customers can reduce their costs by up to 55%. For high-performance computing applications, customers can boost performance, with organizations like iCIMS, UST Health Proof, and Ivy Mobility Solutions LTD eager to take advantage of the technology. AWS also offers RDS for SQL Server Developer Edition, giving development teams access to every feature in SQL Server Enterprise Edition without licensing fees. Learn more about Amazon RDS for SQL Server, RDS for Oracle, Optimize CPUs, and Developer Edition on the AWS Database Blog . Building apps at the speed of ideas with AWS databases, Vercel Marketplace, and v0 Coming soon, AWS databases, including Amazon Aurora and Amazon DynamoDB, will be available as native integrations on Vercel Marketplace and v0. Developers can connect to Aurora PostgreSQL, Aurora DSQL, or DynamoDB in seconds from their Vercel dashboard or in v0 prompts, accelerating the velocity in building new applications. From ideation to production, customers benefit from the security, reliability, scalability, and operational excellence of AWS database services. AWS Security Hub, now generally available, delivers near real-time threat correlation Organizations managing multiple security tools often need to correlate signals across different services, which can create operational complexity. To solve this, AWS Security Hub, now generally available, is providing near-real-time risk analytics that automatically correlate security signals from Amazon GuardDuty , Amazon Inspector , AWS Security Hub CSPM , and Amazon Macie to unify cloud security operations for customers. In addition, Security Hub now provides advanced trends and historical insights through enhanced visualizations, helping organizations understand changes in their security posture over time. These insights help organizations identify potential attack paths, understand how threats, vulnerabilities, and misconfigurations could chain together, and quickly surface and prioritize active risks in their cloud environment. Visit the Security Hub News Blog , Security Hub Page and Security Hub Documentation for more information. AWS debuts AI-powered support with 2x faster response times at entry tier to boost reliability and speed innovation Customers and partners can now access new and enhanced AWS Support offerings with three experience-driven tiers: Business Support+, Enterprise Support, and Unified Operations. Combining the speed of AI with AWS engineer expertise, AWS Support now provides faster response times compared to any previous offering. Additionally, customers previewing AWS DevOps Agent can engage with AWS Support with one-click when needed, giving AWS experts immediate context of the situation for a faster resolution. The result for AWS customers: less time spent fixing issues, giving them more time to innovate. Business Support+delivers AI-powered assistance that understands the context of customer operations, with 24/7 access to AWS experts. For critical production issues, support engineers engage within 30 minutes to accelerate recovery. Enterprise Supportprovides designated Technical Account Managers (TAMs) who blend generative AI insights with human judgment to provide strategic operational guidance to customers on resiliency, cost, and efficiency. It also includes AWS Security Incident Response at no additional cost, which customers can activate to automate security alert investigation and triage. Unified Operations, the premier support plan, is for customers with the largest and most complex workloads—offering a global team of designated experts who deliver architecture reviews, guided testing, proactive optimization, and personalized responses within five-minutes for critical incidents. Business Support+, Enterprise Support, and Unified Operations are available in all commercial AWS Regions. Read the AWS Support Blog or visit the AWS Support product page to learn more. Amazon Connect launches agentic AI capabilities for seamless customer experiences Amazon Connect delivers natural voice interactions with advanced speech models Amazon Connect has helped businesses deliver automated voice experiences using neural text-to-speech in more than 30 languages and automated speech recognition in more than 25 languages. Amazon Connect is introducing agentic self-service capabilities that enable AI agents to understand, reason, and act across voice and messaging channels—automating routine and complex tasks through a blend of deterministic and agentic experiences that companies can deploy reliably and safely at scale. With advanced speech models from Nova Sonic , these agents deliver natural, human-like conversations, responding with the right pace, tone, and understanding across multiple languages and accents. For customers who already use third-party automated speech recognition (ASR) and text-to-speech (TTS) solutions, Connect now supports Deepgram and ElevenLabs. Customers can now resolve complex issues through intuitive self-service, reducing wait times while enjoying natural, conversational experiences. Agentic assistance creates true collaboration between humans and AI For years, Amazon Connect has provided AI-powered assistance that analyzes customer interactions to proactively deliver customer service representatives the information and the tools they need in real-time. Amazon Connect is taking this further with agentic assistance that creates true collaboration between humans and AI. While customer service representatives talk with customers, Amazon Connect analyzes conversation context and customer sentiment—not only suggesting next steps, but also actively completing tasks such as preparing documentation and handling routine processes. Customer service representatives can now focus on building relationships and handling complex situations while AI manages the background complexity, enabling them to serve more customers effectively. AI-powered recommendations create deeper customer engagement Amazon Connect has helped businesses personalize customer interactions through unified customer profiles that sync data from disparate applications. Now, Amazon Connect is introducing AI-powered product recommendations that turn customer conversations into opportunities for deeper engagement. By combining real-time clickstream data with rich customer history, AI agents and customer service representatives can deliver interactions with highly personalized product suggestions at exactly the right moment. Instead of waiting for customers to ask, businesses can also anticipate needs based on real-time behavior, increasing satisfaction while creating new revenue opportunities. AI agent observability, testing, and performance evaluations As businesses deploy more AI agents, understanding how they make decisions has become critical for maintaining quality and compliance. Amazon Connect is introducing AI agent observability that provides complete transparency—showing you what the AI understood, which tools it used, and how it reached its decisions. This visibility helps you optimize performance, ensure compliance, and build confidence in your AI-powered experiences. Amazon Connect enables businesses to test workflows before going live and evaluate both AI and customer service representative performance with automated assessment, custom criteria, and aggregated insights. Businesses can now confidently deploy AI agents at scale, knowing they have full visibility and control over every customer interaction. Learn more about Amazon Connect and the new capabilities. Understand how customers are benefitting from Amazon Connect today. AWS Interconnect - multicloud preview begins with Google AWS Interconnect - multicloud is designed to remove the complexity of traditional multicloud networking by enabling customers to quickly configure connections with dedicated bandwidth between AWS and other service providers, beginning with Google Cloud. Together, AWS and Google Cloud are introducing a new open specification for network interoperability. This jointly engineered multicloud networking solution uses both AWS Interconnect - multicloud and Google Cloud’s Cross-Cloud Interconnect , enabling customers to establish private, high-bandwidth connectivity between the two providers with increased speed and simplicity. Previously, customers connecting different cloud workloads faced a choice: use public connectivity with no bandwidth guarantees or build complex private connectivity. AWS Interconnect - multicloud simplifies connectivity by providing a fully managed, cloud-to-cloud experience that is provisioned quickly through the AWS Management Console or API. To further accelerate adoption, an open API package has been published on GitHub , making it easy for other service providers to adopt this new open specification for connecting private networks. By using pre-built capacity pools, organizations can create connections and adjust their bandwidth as needed. Built-in resiliency, streamlined support, and infrastructure that is fully managed by the service providers enable customers to remove the overhead of managing physical devices or virtual routing objects from their multicloud networks. Learn more about what is available today . TwelveLabs launches world's most powerful video understanding model on Amazon Bedrock TwelveLabs has launched Marengo 3.0, a breakthrough video foundation model now available through Amazon Bedrock. Unlike traditional models that analyze video frame-by-frame, Marengo 3.0 understands video as a complete, dynamic system—connecting dialogue, gestures, movement, and emotion across time to deliver truly human-like comprehension at AI scale. Marengo 3.0 addresses a critical business challenge: 90% of digitized data is video, but most of it remains unusable because it's too time-consuming for humans to analyze and previous AI models couldn't grasp everything happening on screen. Marengo 3.0 changes that by compressing audio, text, movement, visuals, and context into something that can be searched, navigated, and understood at enterprise scale. The model delivers immediate business value with a 50% reduction in storage costs and 2x faster indexing performance. It offers industry-first capabilities including team and player tracking for sports, composed multimodal queries that combine image and text, and support for four-hour videos across 36 languages. "Video represents 90% of digitized data, but that data has been largely unusable," said Jae Lee, CEO of TwelveLabs. "Marengo 3.0 shatters the limits of what is possible." AWS is the first cloud provider to offer Marengo 3.0, making it easy for enterprises to deploy the model securely within their existing AWS environment through Amazon Bedrock's fully managed service. Learn more about Marengo 3.0, on TwelveLabs Amazon Bedrock . Trane Technologies and AWS accelerate building decarbonization for Amazon Grocery Trane Technologies and AWS are using advanced AI to dramatically improve energy efficiency across three pilot Amazon Grocery fulfillment sites in North America , achieving energy reductions of nearly 15%—more than double initial targets. Through BrainBox AI , a Trane Technologies company, the partnership is transforming how Amazon Grocery’s fulfillment facilities consume energy. The AI-powered technology autonomously optimizes heating, ventilation, and air conditioning systems, helping Amazon advance its commitment to reach net-zero carbon by 2040 under The Climate Pledge. "At Trane Technologies, sustainability is at the core of everything we do. This strategic collaboration demonstrates how sustainable solutions can drive strong returns while benefiting the planet," said Riaz Raihan, SVP and chief digital officer of Trane Technologies. "Together, we’re not only transforming these fulfillment centers but also driving meaningful progress towards Amazon’s business objectives and bold sustainability goals.” The results have exceeded expectations, with pilot sites achieving energy-use reductions of nearly 15%. Following the success of these initiatives, deployment is planned for the remaining Amazon Grocery fulfillment and distribution centers across more than 30 sites in the U.S. Furthermore, plans to pilot in grocery stores will begin in 2026. “At Amazon, we’re continually looking for data-driven, scalable solutions to reduce our carbon footprint while maintaining operational excellence,” said Christina Minardi, vice president of Worldwide Grocery Stores Real Estate and Store Development at Amazon. “By working with Trane Technologies and the BrainBox AI team, we’re turning our buildings into intelligent systems that learn and adapt, helping us meet both our sustainability and performance goals in real time.” AWS powers Sony's enterprise AI and engagement platforms Sony is leveraging AWS's AI services for two key initiatives: an internal enterprise platform that helps Sony employees work more efficiently, and the Sony Engagement Platform that aims to deepen connections between fans and creators. The Engagement Platform will connect Sony's diverse portfolio of businesses—from electronics to PlayStation games to music, movies, and anime—making it easier for fans to discover and enjoy content across all of Sony's offerings. Behind the scenes, Sony Data Ocean, running on AWS, helps Sony understand what fans enjoy and delivers more personalized experiences by processing up to 760 terabytes of data from more than 500 different sources across Sony's businesses. The platform will extend core functions of the PlayStation infrastructure such as accounts, payments, data capabilities, and security to create seamless experiences across Sony's entertainment services. Meanwhile, Sony's internal enterprise AI platform, powered by Amazon Bedrock AgentCore , helps 57,000 Sony employees worldwide work smarter. The system handles 150,000 AI requests every day—helping teams draft content, answer questions, spot trends, and brainstorm new ideas—and is expected to grow 300 times larger in the coming years. WRITER and AWS bring enterprise-grade security and flexibility to AI agents WRITER, a leader in enterprise AI, is making it easier for companies to build and manage AI agents securely at scale. Through a new integration with Amazon Bedrock, WRITER customers can now access a wide variety of leading AI models directly within WRITER's platform—alongside WRITER's own Palmyra family of models—all under unified governance and security controls. The integration gives enterprises the flexibility to choose the best models for their needs while maintaining the security and compliance standards they require. Companies like Vanguard, Mars, and AstraZeneca can now deploy Amazon Bedrock models within WRITER's prebuilt or custom agents, with Amazon Bedrock Guardrails and WRITER’s observability tools connecting seamlessly to WRITER's AI Studio. WRITER also unveiled a new agent supervision suite that acts as a control center for enterprise AI. The suite gives IT teams full visibility into how agents are being used, with capabilities including detailed monitoring of user and agent behaviors, centralized approval workflows before deployment, and integration with existing security platforms. These controls help organizations scale AI confidently without sacrificing oversight. "The biggest barrier to scaling agents in the enterprise isn't the technology—it's trust," said WRITER CEO May Habib. "By expanding our supervision capabilities and deepening our relationship with AWS, we're delivering the first true control center for enterprise AI." Learn more . Adobe and AWS team up to reshape creativity and marketing in the AI era Adobe and AWS are transforming how people create and connect with audiences through artificial intelligence. Announced onstage at AWS re:Invent by Adobe CEO Shantanu Narayen, this collaboration leverages AWS's cloud infrastructure and services—from generative AI model training to AI agent deployment—to help Adobe deliver cutting-edge AI tools to creators, marketers, and businesses worldwide. AWS is the engine behind Adobe's most innovative features. Adobe Express uses AWS AI capabilities for conversational editing that makes design intuitive. Adobe Acrobat Studio taps Amazon Bedrock to bring personalized AI assistants to PDFs. And Adobe Firefly—Adobe's commercially safe generative AI—trains its text-to-image and text-to-video models on AWS's advanced EC2 P5 and P6 instances, enabling creators to bring ideas to life instantly. For marketers, AWS enables Adobe to orchestrate personalized customer experiences at an unprecedented scale. Adobe Experience Platform allows brands to unify real-time data and deliver standout experiences across every channel. Adobe GenStudio for Performance Marketing now activates display ads directly with Amazon Ads, dramatically shortening campaign launch times. Adobe and Amazon are also collaborating on AI agent adoption and multi-agent collaboration, with Adobe exploring AWS's newest capabilities like Amazon Bedrock AgentCore to accelerate autonomous agentic capabilities. By combining Adobe's creative expertise with AWS's AI and cloud infrastructure, this partnership makes professional-grade AI tools accessible to everyone—helping individuals and businesses stand out in today's digital economy. Learn more . Dartmouth becomes the first Ivy League institution to deploy AI campuswide with AWS and Anthropic The partnership with AWS and Anthropic will give Dartmouth students, faculty, and staff secure and reliable access to a suite of advanced AI tools designed to support innovation in teaching, learning, and research. This includes access to Amazon Bedrock , AWS's cloud infrastructure, and Anthropic's Claude for Education AI model. "We look forward to empowering Dartmouth, in partnership with Anthropic, as they continue to approach AI ethically, strategically, and securely to provide transformational student experiences and operational excellence," said Kim Majerus, vice president of Global Education and U.S. State and Local Government at AWS. Dartmouth will use Amazon Bedrock to build custom AI applications for campus operations and student services, with AWS's Digital Innovation Team providing direct support using their working backwards methodology. Comprehensive training and support will ensure community members can take advantage of the tools that best meet their needs. “This is more than a collaboration,” said President Sian Leah Beilock. “It’s the next chapter in a story that began at Dartmouth 70 years ago. This collaboration will ensure that the institution where the term AI was first introduced to the world will also demonstrate how to use it wisely in pursuit of knowledge.” “Dartmouth has always understood that technology is most powerful when it's paired with human wisdom and critical thinking—and that's exactly how we built Claude," said Daniela Amodei, president and co-founder of Anthropic. Bonterra and AWS launch mobile-friendly giving hub to simplify nonprofit donations Bonterra has unveiled The Giving Hub —a mobile-friendly platform that combines cash and in-kind donations in one seamless experience. Built on AWS and powered by Amazon Business Donation Driver APIs, this innovative solution transforms how donors support their favorite causes. The Giving Hub addresses a critical challenge facing nonprofits: meeting donor expectations for simple, transparent giving while managing diverse donation types. By integrating Bonterra's GiveGab solution with Amazon Business technology and AWS cloud infrastructure, the platform enables donors to discover organizations, browse nonprofit wish lists, and make cash contributions—all through a single, branded interface. "Nonprofits are under tremendous pressure during the holidays, and donors increasingly expect giving to be simple, transparent, and meaningful," said Ben Cohen, chief revenue officer at Bonterra. "This partnership is removing long-standing barriers in the giving process and unlocking new ways for donors to make an impact." For nonprofits, the platform streamlines operations by enabling custom wish list creation, facilitating cash donations, tracking in-kind contributions, and simplifying fulfillment processes. This builds on Bonterra and AWS's partnership to develop AI-powered, cloud-native solutions for the social good sector, including Bonterra Que—the first fully agentic AI platform built specifically for nonprofits, foundations, and CSR teams. Lyft brings agentic AI to drivers Lyft is partnering with AWS to reimagine rideshare through customer-first AI. Working with the AWS Generative AI Innovation Center and Anthropic, the company built an “intent agent” to support its more than 1 million drivers. The agent, powered by Anthropic’s Claude and Amazon Bedrock, speaks in Spanish or English and uses contextual, backend data to take meaningful action for drivers. For example, if a driver messages, “My earnings aren't showing up," the agent already knows they just completed three rides, sees their payment history, and works to resolve the issue. Lyft has seen an 87% reduction in average resolution time for customer and driver support requests, with more than half resolved in less than three minutes. "The future of customer service has fundamentally shifted through AI," said Ameena Gill, vice president of Safety and Customer Care at Lyft. Nissan accelerates software-defined vehicle innovation with AWS Nissan Motor Co. is rolling out its new Nissan Scalable Open Software Platform, powered by AWS . This cloud-based foundation is completely transforming how Nissan develops its software-defined vehicles (SDVs). The platform brings together software creation, data management, and vehicle operations in one seamless system—running on AWS technology. The results speak for themselves: testing that's 75% faster than before and a unified environment where more than 5,000 developers across the globe can collaborate effortlessly. Teams can now update vehicle features more quickly and work together across international boundaries like never before. "Software development for SDVs is an extremely important strategy for Nissan," said Kazuma Sugimoto, general manager at Nissan. "The Nissan Scalable Open Software Platform is key technology that enables us to rapidly deliver innovative value to customers." Looking ahead, Nissan isn't slowing down. The company is planning to integrate more AI capabilities, including an advanced version of their ProPILOT system for complex driving environments by 2027. Visa collaborates with AWS to deliver secure agentic payments Visa and AWS have teamed up to enable AI agents to transact securely and autonomously on behalf of users. By combining Visa's global payment infrastructure with AWS's AI and cloud capabilities, the companies aim to simplify commerce and unlock faster innovation for developers while delivering seamless experiences for consumers and businesses worldwide. The companies will also publish open blueprints on the Amazon Bedrock AgentCore public repository to help developers create intelligent agentic workflows for retail shopping, travel booking, and payment reconciliation. These blueprints will enable AI agents to handle complex, multi-step transactions—from product discovery and price comparison to secure checkout and order tracking. "Visa Intelligent Commerce is designed to be the trust layer for the agent economy," said Rubail Birwadker, SVP and global head of Growth at Visa. "With AWS's scalable cloud capabilities and Visa's global payment network, Visa Intelligent Commerce enables AI agents to transact securely and contextually at scale." The collaboration brings together industry partners including Expedia Group, Intuit, lastminute.com, Eurostars Hotel Company, and others to review blueprint designs spanning travel, retail, and B2B payments. For example, users could instruct an AI agent to "Buy me basketball game tickets if the price drops below $150," and the agent would execute those tasks on behalf of the user. BlackRock teams with AWS to deliver Aladdin on secure, scalable, performant cloud infrastructure BlackRock is offering Aladdin—BlackRock's industry-recognized investment management technology platform—on AWS . Aladdin on AWS enables clients to leverage advanced risk modeling, enterprise-grade analytics, and smart investment decision-making capabilities while benefiting from AWS's proven track record running mission-critical financial services workloads for over 20 years. "By expanding Aladdin to AWS, we are giving clients more choice in where and how they deploy their technology ecosystem," said Sudhir Nair, senior managing director and global head of Aladdin at BlackRock. "With Aladdin running on AWS, clients gain access to secure, scalable, and resilient infrastructure for advanced risk modeling, enterprise-grade analytics, and smart investment decision-making while maintaining the highest security and resiliency standards," said Scott Mullins, managing director of Worldwide Financial Services at AWS. General availability for Aladdin Enterprise clients hosted in the United States is expected in the second half of 2026. Deepgram brings advanced speech AI capabilities to AWS Deepgram is delivering streaming speech-to-text, text-to-speech, and voice agent capabilities to Amazon SageMaker AI and integrating its enterprise-grade speech technology with Amazon Connect and Amazon Lex. Together, these integrations enable customers to build and deploy voice-powered applications with sub-second latency while maintaining the security and compliance benefits of their AWS environment. Deepgram clients now have the option to deploy real-time speech capabilities across AWS services—from contact centers to custom voice applications—providing choice in their technology environment without compromising the performance and reliability that make Deepgram a trusted solution for enterprise voice AI. "By bringing our streaming speech models directly into SageMaker, enterprises can deploy speech-to-text, text-to-speech, and voice agent capabilities with sub-second latency, all within their AWS environment," said Scott Stephenson, CEO at Deepgram. "Integrating Deepgram's advanced speech technology with Amazon Connect enables organizations to build voice interactions that understand context and respond with appropriate pace and tone, transforming automated interactions into opportunities for deeper customer relationships," said Pasquale DeMaio, VP of Amazon Connect at AWS. Deepgram is an AWS Generative AI Competency Partner with a multi-year Strategic Collaboration Agreement. Early adopters are already leveraging these integrations to power real-time speech processing for enterprise platforms. Learn more about Deepgram as an AWS Partner . Discover more news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Wed, 03 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-re-invent-2025-ai-news-updates</guid>
    </item>
    <item>
      <title>AWS introduces Graviton5: the company’s most powerful and efficient CPU</title>
      <link>https://www.aboutamazon.com/news/aws/aws-graviton-5-cpu-amazon-ec2</link>
      <description><![CDATA[Key takeaways New AWS Graviton5-based Amazon EC2 M9g instances deliver up to 25% higher performance than the previous generation. With 192 cores per chip and 5x larger cache, customers can scale up workloads and improve application performance while reducing infrastructure cost. For the third year in a row, more than half of new CPU capacity added to AWS is powered by Graviton, and 98% of the top 1,000 EC2 customers, including Adobe, Airbnb, Atlassian, Epic Games, Formula 1, Pinterest, SAP, Siemens, Snowflake, and Synopsys, have already benefited from Graviton's price performance advantages. As cloud workloads continue to grow in complexity and scale, organizations face a persistent challenge: how to simultaneously deliver faster performance, lower costs, and meet sustainability commitments. Traditional approaches often force trade-offs, leaving you to choose between speed and efficiency. To address this need, today we are introducing Graviton5 processors—AWS's most advanced custom chip to date for a broad set of cloud workloads. Graviton5 delivers up to 25% better compute performance than the previous generation while maintaining leading energy efficiency, enabling you to run applications faster, reduce costs, and meet sustainability goals. Graviton5 delivers measurable business impact Graviton5-based EC2 M9g instances enable you to process information more efficiently with the highest CPU core density available in Amazon EC2—192 cores in a single package. This efficient design reduces the distance data must travel between cores, cutting inter-core communication latency by up to 33% while increasing bandwidth. Demanding workloads like real-time gaming, high-performance databases, big data analytics, application servers, and Electronic Design Automation (EDA) can now scale up with faster data exchange between processing cores. The chip includes a 5x larger L3 cache—a high-speed memory buffer that keeps frequently accessed data close to the processor. Each Graviton5 core has access to 2.6x more L3 cache than Graviton4, which translates to fewer delays waiting for data and faster application response times. Memory performance has also improved, with Graviton5 providing faster memory speeds, enabling you to process larger datasets and run memory-intensive applications more efficiently. Network and storage bandwidth have also increased, with up to 15% higher network bandwidth and 20% higher Amazon Elastic Block Store (EBS) bandwidth on average across instance sizes, and up to twice the network bandwidth for the largest instances—resulting in faster data transfers, quicker backups, and improved performance for distributed applications. Graviton5 also delivers better performance while being more energy efficient, helping you meet sustainability targets without compromising capability. These innovations are possible because of end-to-end ownership from chip design through server architecture. Graviton5 adopts the latest 3nm technology, optimizes the design for AWS use cases, and allows for system-level optimizations such as bare-die cooling. Graviton5 advances security without compromise Built on the AWS Nitro System—the security and performance foundation trusted by the world's most privacy-conscious organizations across government, healthcare, and financial services—Graviton5 instances leverage sixth-generation Nitro Cards to offload virtualization, storage, and networking functions to dedicated hardware. This architecture delivers virtually all the server's compute and memory resources directly to your workloads while implementing a zero-operator access design that fundamentally prevents any other system or person from logging into EC2 servers, reading instance memory, or accessing customer data. Graviton5 introduces the Nitro Isolation Engine as an enhancement to the Nitro System, harnessing formal verification to provide mathematical certainty that your workloads are isolated from each other and AWS operators. Nitro Isolation Engine’s minimal, formally verified codebase uses mathematical proofs to ensure it behaves exactly as defined, pioneering a new standard for mathematically proven cloud security. We will engage with customers to provide access to the Nitro Isolation Engine implementation so they can evaluate it and the resulting proofs. Proven customer performance across industries Adobe is using Graviton to transform broadcasts into personalized viewing experiences for millions of users, leveraging the improved compute performance to process video streams in real-time. Epic Games relies on Graviton to bring competitive gaming experiences to millions of players daily, where the reduced latency and increased bandwidth ensure smooth gameplay even during peak demand. Formula 1 uses Graviton to help fans keep up with drivers traveling at 350 km/h, processing telemetry data and delivering real-time insights to viewers around the world. Pinterest hosts more than 500 million monthly active users on Graviton-based infrastructure, benefiting from the price performance advantages to serve personalized content at scale. Airbnb was born in 2007 when two hosts welcomed three guests to their San Francisco home and has since grown to over 5 million hosts who have welcomed over 2 billion guest arrivals in almost every country across the globe. “AWS Graviton5-based Amazon EC2 instances are some of the fastest EC2 instances we have ever tested,” said Denis Sheahan a principal performance engineer at Airbnb. “In our performance tests, conducted using Airbnb's production search workloads, we are seeing improvements of up to 25% over other system architectures of the same generation, and up to 20% compared to prior generation Graviton4 instances. We are especially impressed with P95 latency for our critical workloads, helping to provide a consistent experience for Airbnb guests and hosts.” A recognized leader in software development, work management, and enterprise service management software, Atlassian enables enterprises to connect their business and technology teams with an AI-powered system of work that unlocks productivity at scale. “Atlassian has migrated more than 3,000 EC2 instances for Jira and Confluence to AWS Graviton4-based EC2 instances,” said Paulo Almeida, principal site reliability engineer at Atlassian. “In our testing of Jira on AWS Graviton5-based M9g instances, we observed 30% higher performance and 20% lower latency compared to the prior generation, and we look forward to AWS Graviton5 general availability.” Siemens Digital Industries Software helps organizations of all sizes digitally transform using software, hardware, and services from the Siemens Xcelerator business platform. Siemens Calibre Design Solutions delivers a complete integrated circuit verification and design for manufacturing optimization EDA platform. “The future of semiconductor physical verification lies in cloud-enabled, high-performance computing,” said Juan Rey, senior vice president and general manager at Siemens Digital Industries Software. “Our collaboration with AWS positions Calibre at the forefront of this transformation. We're excited to announce support for Calibre on Arm-based AWS Graviton processors, which deliver 20% performance improvements and more than 30% compute cost reductions on AWS Graviton4 compared with other AWS instances. Early AWS Graviton5 testing shows an additional 30% performance boost, unlocking faster verification and time-to-market for our customers.” For over 50 years, organizations have trusted SAP to bring out their best by uniting business-critical operations spanning finance, procurement, HR, supply chain, and customer experience. “We've been working closely with AWS on running SAP HANA Cloud on AWS Graviton since 2023 and have seen significant performance improvements with each new Graviton generation,” said Stefan Bäuerle, senior vice president and head of SAP HANA & Persistency at SAP. “With AWS Graviton5-based Amazon EC2 M9g instances, we've observed a stunning 35% to 60% increase in the performance of our OLTP queries on SAP HANA Cloud—a phenomenal advancement in a single generation.” Synopsys is the leader in engineering solutions from silicon to systems, enabling customers to rapidly innovate AI-powered products. “For over a decade since the inception of Annapurna Labs, Synopsys and AWS have collaborated to enable Amazon's custom silicon development,” said Sanjay Bali, senior vice president in strategy and product management at Synopsys. “Synopsys EDA tools such as VCS, PrimeTime, Fusion Compiler, and IC Validator support on AWS Graviton have been critical to the design of Graviton as well as Nitro and Trainium chips. Today, Synopsys and AWS are expanding Graviton support to accelerate our customers' semiconductor innovation. Compared to Graviton4, early results on Graviton5 show up to 35% runtime improvements for Fusion Compiler and PrimeTime. In addition, our joint partner, Arm, is observing up to 40% faster runtimes for Synopsys VCS on Graviton5 relative to previous generations.” Graviton5-based M9g instances designed for general purpose workloads are available in preview now. C9g instances for compute-intensive workloads and R9g instances for memory-intensive workloads are planned for 2026. For more details on AWS Graviton5 and the new M9g instances, visit: AWS Graviton productpage Gravitondocumentation Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Wed, 03 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-graviton-5-cpu-amazon-ec2</guid>
    </item>
    <item>
      <title>AWS simplifies model customization to help customers build faster, more efficient AI agents</title>
      <link>https://www.aboutamazon.com/news/aws/amazon-sagemaker-ai-amazon-bedrock-aws-ai-agents</link>
      <description><![CDATA[Key takeaways New Amazon Bedrock and Amazon SageMaker AI capabilities give customers access to advanced techniques for model customization. Reinforcement Fine Tuning in Amazon Bedrock makes it easier to tailor models to unique cases and improve accuracy. Amazon SageMaker AI cuts advanced model customization workflows from months to days, accelerating AI development and bringing new solutions to market faster. Efficiency has emerged as a critical challenge for organizations deploying AI. While building AI applications has become easier, running them at scale remains expensive and resource-intensive. This challenge is particularly acute for AI agents , which can have higher inference demands as they reason through problems, leverage a variety of tools, and coordinate across multiple systems. Most companies opt for the largest, most capable models to power their agents, but a significant amount of an agent’s time is spent doing routine tasks, like checking calendars and searching documents, that don't require advanced intelligence. The result? Unnecessary costs, slower responses, and wasted resources. The solution lies in customization: tailoring smaller, specialized models to handle the work agents do most often to deliver faster, more accurate responses at lower costs. But until now, advanced customization techniques like reinforcement learning required deep machine learning expertise, extensive infrastructure, and months of development time. Today, we announced new Amazon Bedrock and Amazon SageMaker AI capabilities that make advanced model customization accessible to developers at any organization. Reinforcement Fine Tuning (RFT) in Amazon Bedrock and serverless model customization in Amazon SageMaker AI with reinforcement learning simplify the process of creating efficient AI that's fast, cost-effective, and more accurate compared to base models. By making these techniques more accessible for our customers’ developers, we’re making it easier for organizations of all sizes to build custom agents for any business need. RFT made easy for everyday developers with Amazon Bedrock Difficult customization techniques present a roadblock for building custom, efficient models. Reinforcement learning, for example, trains a model using feedback from either humans or another model. Good behavior gets reinforced, while bad behavior gets corrected. It’s particularly good for reasoning and complex workflows because it rewards good processes, not just good answers. However, reinforcement learning requires a complex training pipeline, massive compute, and access to expensive human feedback or a powerful AI model to evaluate every response. RFT on Amazon Bedrock simplifies the model customization process, opening the technique to any developer at any organization. Amazon Bedrock is a fully managed AI platform giving customers access to high-performing foundation models from leading AI companies, along with capabilities to build agents and generative AI applications with features for security, privacy, and responsible AI. RFT on Amazon Bedrock delivers 66% accuracy gains on average over base models, helping you get better results with smaller, faster, more cost-effective models instead of relying on larger, expensive ones. The process is simple. Developers select their base model, point it at their invocation logs (in other words, the AI’s history), or upload a dataset. Then, they choose a reward function—AI-based, rule-based, or a ready-to-use template. Automated workflows in Amazon Bedrock handle the fine-tuning process end-to-end. No PhD in machine learning required—only a clear sense of what good results look like for the business. At launch, RFT in Amazon Bedrock will support the Amazon Nova 2 Lite model. Compatibility with additional models is coming soon. Customers like Salesforce and Weni by VTEX have seen increased accuracy and efficiency using RFT in Amazon Bedrock. Phil Mui, SVP of Software Engineering, Agentforce at Salesforce, said, “AWS’s benchmarking with Amazon Bedrock’s Reinforcement Fine Tuning shows promising results, demonstrating up to 73% improvement over base model in accuracy for our specific business requirements. We anticipate leveraging RFT to enhance and extend what we already achieve with supervised fine-tuning, enabling us to deliver even more precise and customized AI solutions for our customers. This approach complements our existing AI development workflow while maintaining Salesforce’s high standards for quality and safety.” Amazon SageMaker AI accelerates model customization from months to days Teams that need more control over the AI workflow can turn to Amazon SageMaker AI. AI developers choose SageMaker AI for customization because it gives them full control to build, train, and deploy the most capable models at scale. Since launching in 2017, SageMaker AI has made the AI development workflow faster and more efficient. However, as organizations look to use more advanced customization techniques, they want more seamless experiences that remove roadblocks that take months of work—like infrastructure management and generating synthetic data—so they can focus on developing better outcomes for customers. That’s why SageMaker AI now supports new serverless model customization capabilities, making model customization possible in just days. There are two experiences to choose from: an agentic experience, launching in preview, that uses an agent to guide developers through the model customization process, or a self-guided approach for those who like to be in the driver's seat. With the agentic experience, developers describe what they need in natural language and then the agent walks through the entire customization process, from generating synthetic data to evaluation. Developers who want granular control and flexibility can choose the self-guided experience. This eliminates infrastructure management while providing the right tooling to select a customization technique and the ability to tweak the parameters. With either option, developers can access advanced customization techniques like Reinforcement Learning from AI feedback, Reinforcement Learning with Verifiable Rewards, Supervised Fine-Tuning, and Direct Preference Optimization. The new SageMaker AI capabilities will work with Amazon Nova and popular open weight models like Llama, Qwen, DeepSeek, and GPT-OSS, giving customers a wide range of options to match the right model to their use case. Collinear AI, Robin AI, Vody, and Eloquent AI are just a few of the customers that have started simplifying model customization with SageMaker AI’s new capabilities. For example, Collinear AI, an AI improvement platform built for enterprise genAI, saved weeks using SageMaker AI. Soumyadeep Bakshi, co-founder, Collinear AI, said, “Fine-tuning AI models is critical to creating high-fidelity simulations, and it used to require stitching together different systems for training, evaluation, and deployment. Now with Amazon SageMaker AI's new serverless model customization capability, we have a unified way that empowers us to cut our experimentation cycles from weeks to days. This end-to-end serverless tooling helps us focus on what matters: building better training data and simulations for our customers, not maintaining infrastructure or juggling disparate platforms.” For more details about these capabilities, visit: AWS News blog: RFT in Amazon Bedrock RFT in Amazon Bedrock product page AWS News blog: SageMaker AI serverless model customization SageMaker AI model customization product page Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Tue, 02 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/amazon-sagemaker-ai-amazon-bedrock-aws-ai-agents</guid>
    </item>
    <item>
      <title>Trainium3 UltraServers now available: Enabling customers to train and deploy AI models faster at lower cost</title>
      <link>https://www.aboutamazon.com/news/aws/trainium-3-ultraserver-faster-ai-training-lower-cost</link>
      <description><![CDATA[Key takeaways Trainium3 UltraServers deliver high performance for AI workloads with up to 4.4x more compute performance, 4x greater energy efficiency, and almost 4x more memory bandwidth than Trainium2 UltraServers—enabling faster AI development with lower operational costs. Trn3 UltraServers scale up to 144 Trainium3 chips, delivering up to 362 FP8 PFLOPs with 4x lower latency to train larger models faster and serve inference at scale. Customers including Anthropic, Karakuri, Metagenomi, NetoAI, Ricoh, and Splash Music are reducing training and inference costs by up to 50% withTrainium, while Decart is achieving 4x faster inference for real-time generative video at half the cost of GPUs, and Amazon Bedrock is already serving production workloads on Trainium3. As AI models grow in size and complexity, they are pushing the limits of compute and networking infrastructure, with customers seeking to reduce training times and inference latency—the time between when an AI system receives an input and generates the corresponding output. Training cutting-edge models now requires infrastructure investments that only a handful of organizations can afford, while serving AI applications at scale demands compute resources that can quickly spiral out of control. Even with the fastest accelerated instances available today, simply increasing cluster size fails to yield faster training time due to parallelization constraints, while real-time inference demands push single-instance architectures beyond their capabilities. To help customers overcome these constraints, today we announced the general availability of Amazon EC2 Trn3 UltraServers. Powered by the new Trainium3 chip built on 3nm technology, Trn3 UltraServers enable organizations of all sizes to train larger AI models faster and serve more users at lower cost—democratizing access to the compute power needed for tomorrow's most ambitious AI projects. Trainium3 UltraServers: Purpose-built for next-generation AI workloads Trn3 UltraServers pack up to 144 Trainium3 chips into a single integrated system, delivering up to 4.4x more compute performance than Trainium2 UltraServers. This allows you to tackle AI projects that were previously impractical or too expensive by training models faster, cutting time from months to weeks, serving more inference requests from users simultaneously, and reducing both time-to-market and operational costs. In testing Trn3 UltraServers using OpenAI's open weight model GPT-OSS, customers can achieve 3x higher throughput per chip while delivering 4x faster response times than Trn2 UltraServers. This means businesses can scale their AI applications to handle peak demand with less infrastructure footprint, directly improving user experience while reducing the cost per inference request. These improvements stem from Trainium3's purpose-built chip. The chip achieves breakthrough performance through advanced design innovations, optimized interconnects that accelerate data movement between chips, and enhanced memory systems that eliminate bottlenecks when processing large AI models. Beyond raw performance, Trainium3 delivers substantial energy savings—40% better energy efficiency compared to previous generations. This efficiency matters at scale, enabling us to offer more cost-effective AI infrastructure while reducing environmental impact across our data centers. Advanced networking infrastructure engineered for scale AWS engineered the Trn3 UltraServer as a vertically integrated system—from the chip architecture to the software stack. At the heart of this integration is networking infrastructure designed to eliminate the communication bottlenecks that typically limit distributed AI computing. The new NeuronSwitch-v1 delivers 2x more bandwidth within each UltraServer, while enhanced Neuron Fabric networking reduces communication delays between chips to just under 10 microseconds. Tomorrow's AI workloads—including agentic systems, mixture-of-experts (MoEs), and reinforcement learning applications—require massive amounts of data to flow seamlessly between processors. This AWS-engineered network enables you to build AI applications with near-instantaneous responses that were previously impossible, unlocking new use cases like real-time decision systems that process and act on data instantly, and fluid conversational AI that responds naturally without lag. For customers who need to scale, EC2 UltraClusters 3.0 can connect thousands of UltraServers containing up to 1 million Trainium chips—10x the previous generation—giving you the infrastructure to train the next generation of foundation models. This scale enables projects that simply weren't possible before, from training multimodal models on trillion-token datasets to running real-time inference for millions of concurrent users. Customers already seeing results at frontier scale Customers are already seeing significant value from Trainium, with companies like Anthropic, Karakuri, Metagenomi, NetoAI, Ricoh, and Splash Music reducing their training costs by up to 50% compared to alternatives. Amazon Bedrock, AWS's managed service for foundation models, is already serving production workloads on Trainium3, demonstrating the chip's readiness for enterprise-scale deployment. Pioneering AI companies including Decart, an AI lab specializing in efficient, optimized generative AI video and image models that power real-time interactive experiences, are leveraging Trainium3's capabilities for demanding workloads like real-time generative video, achieving 4x faster frame generation at half the cost of GPUs. This makes compute-intensive applications practical at scale—enabling entirely new categories of interactive content, from personalized live experiences to large-scale simulations. With Project Rainier , AWS collaborated with Anthropic to connect more than 500,000 Trainium2 chips into the world's largest AI compute cluster—five times larger than the infrastructure used to train Anthropic's previous generation of models. Trainium3 builds on this proven foundation, extending the UltraCluster architecture to deliver even greater performance for the next generation of large-scale AI compute clusters and frontier models. Looking ahead to the next generation of Trainium We are already working on Trainium4, which is being designed to bring significant performance improvements across all dimensions, including at least 6x the processing performance (FP4), 3x the FP8 performance, and 4x more memory bandwidth to support the next generation of frontier training and inference. Combined with continued hardware and software optimizations, you can expect performance gains that scale well beyond baseline improvements. The 3x FP8 performance improvement in Trainium4 represents a foundational leap—you can train AI models at least three times faster or run at least three times more inference requests, with additional gains realized through ongoing software enhancements and workload-specific optimizations. FP8 is the industry-standard precision format that balances model accuracy with computational efficiency for modern AI workloads. To deliver even greater scale-up performance, Trainium4 is being designed to support NVIDIA NVLink Fusion high-speed chip interconnect technology. This integration will enable Trainium4, Graviton, and Elastic Fabric Adapter (EFA) to work together seamlessly within common MGX racks, providing you with a cost-effective, rack-scale AI infrastructure that supports both GPU and Trainium servers. The result is a flexible, high-performance platform optimized for demanding AI model training and inference workloads. Amazon EC2 Trn3 UltraServers are now generally available. Learn more and get started today. Additional resources: AWS AI Blog Documentation See howcustomers are using Trainium Get startedwith Trainium Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/trainium-3-ultraserver-faster-ai-training-lower-cost</guid>
    </item>
    <item>
      <title>New Amazon Bedrock AgentCore capabilities power the next wave of agentic AI development</title>
      <link>https://www.aboutamazon.com/news/aws/aws-amazon-bedrock-agent-core-ai-agents</link>
      <description><![CDATA[Key takeaways Policy in Amazon Bedrock AgentCore actively blocks unauthorized agent actions through real-time, deterministic controls that operate outside of the agent code. AgentCore Evaluations helps developers continuously inspect the quality of an agent based on its behavior. AgentCore Memory introduces episodic functionality that helps agents learn from experiences, improving decision-making. Organizations of all sizes and regulatory requirements—including Amazon Devices Operations & Supply Chain, Archera.ai, Cohere Health, Cox Automotive, Druva, Heroku, Natera, NTT Data, MongoDB, PGA TOUR, Pulumi, Thomson Reuters, Workday, Snorkel.ai, Swisscom, and S&P Global Market Intelligence—trust AgentCore to accelerate their AI agents into production. Today, we announced new innovations in Amazon Bedrock AgentCore , the most advanced platform for building and deploying agents securely at scale. Policy in AgentCore allows teams to set boundaries on what agents can do with tools, and AgentCore Evaluations help teams understand how their agents will perform in the real world. Additionally, AWS launched an enhanced memory capability that enables agents to learn from experience and improve over time, providing more tailored insights to customers. Develop enterprise AI agents that know their power and their limits While the ability for agents to reason and act autonomously makes them powerful, organizations must establish robust controls to prevent unauthorized data access, inappropriate interactions, and system-level mistakes that could impact business operations. Even with careful prompting, agents make real-world mistakes that can have serious consequences. Today, we are launching Policy in Amazon Bedrock AgentCore, which helps organizations set clear boundaries for agent actions. Using natural language, teams can now give agents boundaries by defining which tools and data they can access, what actions they can perform, and under what conditions. These tools could be APIs, Lambda functions, MCP servers, or popular third-party services like Salesforce and Slack. To ensure agents stay fast and responsive, Policy is integrated into AgentCore Gateway to instantly check agent actions against policies in milliseconds. This ensures agents stay within defined boundaries while operating autonomously. The natural language-based policy authoring provides a more accessible and user-friendly way for customers to create fine-grained policies by allowing them to describe rules in natural language instead of writing formal policy code. For example, a simple policy like “Block all refunds from customers when the reimbursement amount is greater than $1,000” can be implemented and enforced consistently, following Amazon's “trust, but verify” principle. This will allow agents to operate autonomously while maintaining appropriate oversight. Druva is a leading provider of data security solutions. "Typically, customers can spend hours manually checking logs across dozens of systems when data backups fail,” said David Gildea, vice president of product AI at Druva. “However, with our AI agents , they can get instant analysis and step-by-step remediation for data recovery. We are excited to get started with Policy in AgentCore as it will help our customers set clear boundaries for agent access to internal tools and data like backup systems, security logs, and monitoring dashboards. With appropriate policies in place, our developers can innovate confidently, knowing agents will stay within defined compliance boundaries. This enables us to expand our agent platform while maintaining the strict security standards our enterprise customers expect." Gain complete visibility into AI agent behavior and results Unlike traditional software metrics, evaluating AI agent quality requires complex data science pipelines, subjective assessments, and continuous real-time monitoring, a challenge that compounds with each agent update or model change. AgentCore Evaluations simplifies complicated processes and eliminates complex infrastructure management with 13 pre-built evaluators for common quality dimensions such as correctness, helpfulness, tool selection accuracy, safety, goal success rate, and context relevance. Additionally, developers have the flexibility to write their own custom evaluators using their preferred LLMs and prompts. Previously, this required months of data science work to build just the evaluation systems. The new service continuously samples live agent interactions to analyze agent behavior for pre-identified criteria like correctness, helpfulness, and safety. Development teams can set up alerts for proactive quality monitoring, using evaluations both during testing and in production. For example, if a customer service agent's satisfaction scores drop by 10% over eight hours, the system triggers immediate alerts, enabling swift response before customer experience is impacted. Natera is a leader in genetic testing and diagnostics. “At Natera, we're transforming oncology patient care through AI agents,” said Mirko Buholzer, software engineering lead, Natera. “Our teams are currently undertaking a substantial effort to uphold consistent quality and performance across our AI agents while meeting strict health care compliance standards. AgentCore Evaluations will play a key role in this work by continuously monitoring our agents' performance by using essential metrics such as accuracy, helpfulness, and patient satisfaction. We expect this real-time quality intelligence to help us quickly identify and address issues preemptively. With AgentCore Evaluations, we aim to confidently deploy reliable agents that maintain our high standards and support the delivery of transformative patient care at scale.” Build agents that get smarter with every interaction Most AI agents today lack critical memory capabilities because "memory" is often limited to a short-term context window that is reset with each new interaction, preventing them from learning from past successes or failures in production environments. AgentCore Memory provides this critical feature, allowing an agent to build a coherent understanding of users over time. Today, AgentCore Memory is making a new episodic functionality generally available that allows agents to learn from past experiences and apply those insights to future interactions. Through structured episodes that capture context, reasoning, actions, and outcomes, another agent automatically analyzes patterns to improve decision-making. When agents encounter similar tasks, they can quickly access relevant historical data, reducing processing time and eliminating the need for extensive custom instructions. For example, an agent books airport transportation 45 minutes before the flight when you are traveling alone. Three months later, when you are traveling to the same destination—with kids this time—it automatically schedules pickup two hours early, remembering previous family trip challenges. This targeted learning approach helps agents make more consistent decisions based on actual performance data rather than relying on predetermined guidelines. S&P Global Market Intelligence provides insights and leading data and technology solutions to institutional investors, banks, and corporations. “We recently developed Astra, an internal general-purpose agentic workflow platform, but faced challenges orchestrating complex multi-agent workflows across our distributed organization,” said Helene Astier, head of Technology, MI Enterprise Technology and Sustainability, at S&P Global Market Intelligence. “As hundreds of specialized agents emerged, managing state and maintaining consistent context became increasingly difficult, highlighting the need for a unified memory layer. Amazon Bedrock AgentCore Memory provided the solution through seamless, centralized state checkpointing across our multi-agent orchestration stack. With the new episodic memory functionality, our agents will learn from prior analyses to generate more intelligent insights. Previously, deploying agents onto the Astra platform took weeks. Now, with AgentCore we can create and deploy an agent or MCP server within minutes.” Today’s innovations give you purpose-built agent infrastructure that lets you focus on innovation rather than building AI foundations. For more details on the new Amazon Bedrock AgentCore innovations, visit: AgentCore News Blog AgentCore webpage Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-amazon-bedrock-agent-core-ai-agents</guid>
    </item>
    <item>
      <title>AWS unveils frontier agents, a new class of AI agents that work as an extension of your software development team</title>
      <link>https://www.aboutamazon.com/news/aws/amazon-ai-frontier-agents-autonomous-kiro</link>
      <description><![CDATA[Key takeaways Frontier agents represent a new class of AI agents that are autonomous, scalable, and work for hours or days without constant intervention. Kiro autonomous agent is your virtual developer that maintains context and learns over time while working independently, so you can focus on your biggest priorities. AWS Security Agent is your virtual security engineer that helps build secure applications by being a security consultant for app design, code reviews, and penetration testing. AWS DevOps Agent is your virtual operations team member that helps resolve and proactively prevent incidents, while continuously improving your applications’ reliability and performance. AI agents have transformed how development teams work, and as the technology evolves, teams are learning how to maximize agents’ value. To understand how to push agents further, we looked to our own development teams building services at Amazon scale and uncovered three critical insights to dramatically increase value. First, by learning what the agents were and weren’t good at, the team could switch from babysitting every small task to directing agents toward broad, goal-driven outcomes. Second, the velocity of our teams was tied to how many agentic tasks they could run simultaneously. Third, the longer the agents could operate on their own, the better. While these insights came from software development, the team quickly realized they needed the same capabilities across every aspect of the software development lifecycle—like security and operations—or risk creating new bottlenecks. These insights led AWS to frontier agents—a new, more sophisticated class of AI agents with three defining characteristics. First, they're autonomous. Direct them toward a goal, and the agents figure out how to achieve it. Second, they're scalable. They can perform multiple tasks at the same time and distribute work across multiple agents. Third, they work independently. They can operate for hours or days without requiring intervention. That’s why we are announcing three new frontier agents—Kiro autonomous agent, AWS Security Agent, and AWS DevOps Agent—focused on transforming the software development lifecycle. These agents represent a step-function change in what you can do with agents today, moving from assisting with individual tasks to completing complex projects autonomously like a member of your team. These agents take advantage of our decades of experience building software, industry-leading security practices, and extensive operational expertise to help you build faster, secure applications from the start, and operate with greater confidence. Clariant, Commonwealth Bank of Australia, SmugMug, Western Governors University, and Presidio are among the customers already using one or more of these new agents to dramatically accelerate the software development lifecycle. Kiro autonomous agent: The frontier agent for software development AI coding tools have accelerated individual tasks, but many of them have also introduced new friction. Using these tools, you can find yourself acting as the human "thread" that holds work together—rebuilding context when switching tasks, manually coordinating cross-repository changes, and restitching information scattered across tickets, pull requests, and chat threads. This slows them down and pulls focus away from real priorities. What would it take for a tool to cut this friction, so you can stay focused and ship code faster? The Kiro autonomous agent keeps work moving independently while you focus on priority tasks. You now get more uninterrupted time for high-priority work instead of juggling background busy work, shortening the path from idea to meaningful contributions. Kiro autonomous agent maintains persistent context across sessions and continuously learns your pull requests and feedback. It can handle a range of tasks—from triaging bugs to improving code coverage—with a single change spanning multiple repositories. You can ask it questions, describe a task, and assign tasks in your backlog directly from GitHub. The agent will then independently figure out how to get the work done, sharing changes as proposed edits and pull requests, so you stay in control of what gets incorporated. For teams, the Kiro autonomous agent is a shared resource that works alongside the entire team, building a collective understanding of your codebase, products, and standards. It connects to your team’s repos, pipelines, and tools, like Jira, GitHub, and Slack, to maintain context as work progresses, adapting to changes or updates. Every code review, ticket, and architectural decision informs the agent’s understanding, making it even more useful for the team over time. AWS Security Agent: The frontier agent for more secure apps Security teams face a dual challenge: they need to proactively identify risks throughout development, while also reacting quickly when issues emerge. Current tools often provide generic recommendations, and penetration testing takes so much time and resources that it can’t keep up with fast-moving development teams. What if security could deliver tailored guidance throughout the lifecycle and make comprehensive testing available on demand? AWS Security Agent helps you build applications that are secure from the start across AWS, multicloud, and hybrid environments. The agent embeds deep security expertise throughout the development lifecycle, proactively reviewing design documents and scanning pull requests against organizational security requirements and common vulnerabilities. You define your organization's security standards once, and AWS Security Agent automatically validates them across your applications during its review—helping teams address the risks that matter to their business, not generic checklists. The agent also transforms penetration testing from a slow, manual process into an on-demand capability, matching your team’s development velocity. Now you can expand penetration testing across your entire application portfolio. The agent returns validated findings with remediation code to fix the issues it finds, saving you invaluable time and resources. If you have multiple apps deploying at once, you can easily scale the number of AWS Security Agents to meet demand, so you never have to compromise between moving fast and maintaining security. By continually validating security from design to deployment, the agent helps prevent vulnerabilities early, so you can focus on what matters most. SmugMug is a Software-as-a-Service platform for photographers to store, host, and share their images and videos. The company added AWS Security Agent to its automated security portfolio to help transform its security testing approach, enabling penetration test assessments that complete in hours rather than days at a fraction of manual testing costs. "AWS Security Agent helped catch a business logic bug that no existing tools would have caught, exposing information improperly," said Andres Ruiz, staff software engineer at SmugMug. "To any other tool, this would have been invisible. But the ability for Security Agent to contextualize the information, parse the API response, and find the unexpected information there represents a leap forward in automated security testing. Existing tools today lack this capability, and likely only a human tester would have been able to catch this." AWS DevOps Agent: The frontier agent for operational excellence When an application goes down, everything stops. Customers lose access, teams lose time, and trust takes a hit. Modern distributed applications—with microservices, cloud dependencies, and telemetry spread across multiple tools—make it increasingly difficult to isolate issues and understand system behavior. Meanwhile, as services scale, operations can continue to eat up more of your time, reducing your ability to spend innovating and improving your application to provide the best experience for customers. What if operations could break this cycle and move from constant firefighting to continuous improvement? AWS DevOps Agent delivers fewer alerts and more sleep for your team through always-on incident triage, guided resolution, and recommendations for how to continuously improve the reliability and performance of your applications across AWS, multicloud, and hybrid environments. AWS DevOps Agent is on call when incidents happen, instantly responding to issues and using its knowledge of your application and the relationship between components to find the root cause of the problem. It learns your resources and their relationships spanning everything from observability tools, like Amazon CloudWatch, Dynatrace, Datadog, New Relic, and Splunk, to runbooks, code repositories, and continuous integration and continuous delivery (CI/CD) pipelines. It maps your application resources and correlates telemetry, code, and deployment data to precisely pinpoint root causes and reduce mean time to resolution. Within Amazon, AWS DevOps Agent has handled thousands of escalations, with an estimated root cause identification rate of over 86%. You can also move from reactive firefighting to proactive operational improvement by analyzing patterns across historical incidents with AWS DevOps Agent. It uses those learnings to provide targeted recommendations that strengthen four key areas: observability, infrastructure optimization, deployment pipeline enhancement, and application resilience. This approach accesses the untapped insights in your operational data and tools, helping teams improve recovery times and drive operational excellence across applications. Commonwealth Bank of Australia is one of Australia's leading providers of integrated financial services serving over 17 million customers. The bank's Cloud Foundations group manages over 1,700 AWS accounts and provides centralized cloud operation services for thousands of engineers. While prototyping their next-generation internal cloud platform, the team replicated a complex network and identity management issue to test AWS DevOps Agent. These types of issues can take a seasoned DevOps engineer hours to identify, and the agent found the root cause in under 15 minutes. "AWS DevOps Agent thinks and acts like a seasoned DevOps engineer, helping our engineers build a banking infrastructure that’s faster, more resilient, and designed to deliver better experiences for our customers," said Jason Sandery, head of cloud services at Commonwealth Bank of Australia. "This isn't just about faster resolution times—it's about maintaining the trust our customers put in us.” Driving toward an agentic future Together, Kiro autonomous agent, AWS Security Agent, and AWS DevOps Agent mark the beginning of a new era in software development. These frontier agents don't just make teams faster—they fundamentally redefine what's possible when AI works as an extension of your team, delivering outcomes autonomously across the software development lifecycle. All of these agents are available today in preview. For more details about these agents, visit the following product pages and blogs: Frontier agents product page The Kiro blog about the Kiro autonomous agent Kiro autonomous agent product page The AWS News blog on the AWS Security Agent AWS Security Agent product page The AWS News blog on the AWS DevOps Agent AWS DevOps Agent product page Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/amazon-ai-frontier-agents-autonomous-kiro</guid>
    </item>
    <item>
      <title>Amazon introduces new frontier Nova models, a pioneering Nova Forge service for organizations to build their own models, and Nova Act for building agents</title>
      <link>https://www.aboutamazon.com/news/aws/aws-agentic-ai-amazon-bedrock-nova-models</link>
      <description><![CDATA[Key takeaways Nova 2 models deliver industry-leading price-performance across reasoning, multimodal processing, conversational AI, code generation, and agentic tasks. Nova Forge enables companies to build their own optimized variants of Nova by infusing their proprietary data early in the training process through Forge’s unique "open training" approach. Nova Act achieves breakthrough 90% reliability for browser-based UI automation workflows built by early customers. Amazon announces a comprehensive expansion of its Nova portfolio with four new models, a pioneering "open training" service that empowers organizations to build their custom model variants with Nova , and a service for creating highly reliable AI agents. Tens of thousands of companies are using Nova for diverse applications, such as producing high-quality content, automating multi-step tasks, and accelerating development of AI agents. Amazon's new Nova 2 model family balances speed, cost, and intelligence across multiple AI domains: Nova 2 Lite Nova 2 Lite is a fast, cost-effective reasoning model for everyday workloads that can process text, images, and videos to generate text. Customers can adjust how much step-by-step "thinking" the model performs before responding, balancing intelligence depth with speed and cost—ideal for customer service chatbots, document processing, and business automation. Nova 2 Lite delivers industry-leading price performance in its intelligence class. It is equal or better on 13 out of 15 benchmarks compared to Claude Haiku 4.5, equal or better on 11 out of 17 benchmarks compared to GPT-5 Mini, and equal or better on 14 out of 18 benchmarks compared to Gemini Flash 2.5. Nova 2 Lite demonstrates standout capabilities in processing documents, extracting information from videos, generating code, providing accurate grounded answers, and automating multi-step agentic workflows. Nova 2 Pro Nova 2 Pro is Amazon's most intelligent reasoning model that can process text, images, video, and speech to generate text. It’s ideal for highly complex tasks like agentic coding, long-range planning, and sophisticated problem-solving—where the highest accuracy is essential. The model can also serve as a "teacher" for knowledge distillation—transferring its capabilities into smaller, more efficient "student" models for specific domains and use cases. Nova 2 Pro is equal or better on 10 out of 16 benchmarks compared to Claude Sonnet 4.5, equal or better on 8 out of 16 benchmarks compared to GPT-5.1, equal or better on 15 out of 19 benchmarks compared to Gemini 2.5 Pro, and equal or better on 8 out of 18 benchmarks compared to Gemini 3 Pro Preview. Nova 2 Pro demonstrates strengths in multi-document analysis, video reasoning, following complex instructions, solving advanced math, and executing agentic and software engineering tasks. Both Nova 2 Lite and Nova 2 Pro have built-in web grounding and code execution capabilities, meaning they can search the web for current information and run code directly—ensuring responses stay anchored in up-to-date facts rather than relying solely on training data. Nova 2 Sonic Nova 2 Sonic is Amazon's speech-to-speech model that unifies text and speech understanding and generation for real-time, human-like conversational AI. It features expanded multilingual support with expressive voices, higher accuracy, and a one-million token context window for sustained interactions, while enabling seamless switching between voice and text. The model handles tasks asynchronously, letting users continue natural conversations—even switching topics—while actions like booking flights complete in the background. It also seamlessly integrates with Amazon Connect, telephony providers (Vonage, Twilio, AudioCodes), and conversational AI frameworks (LiveKit, Pipecat), making it ideal for customer service applications, AI assistants, and interactive voice experiences. Nova 2 Sonic offers industry-leading price performance and quality compared to OpenAI’s gpt-realtime and Gemini 2.5 Flash models available through their realtime APIs. Nova 2 Omni Nova 2 Omni is a unified multimodal reasoning and generation model that can process text, images, video, and speech inputs while generating both text and images—an industry first. It handles up to 750,000 words, hours of audio, long videos, and hundred-page documents, simultaneously analyzing entire product catalogs, testimonials, brand guidelines, and video libraries at once. This eliminates the cost and complexity of connecting multiple specialized models. For example, marketing teams can analyze product details across all formats to instantly generate complete campaigns including headlines, copy, social posts, and visuals in one workflow. While there are no comparable models in the industry to Nova 2 Omni, it demonstrates strengths in public benchmarks of multimodal reasoning on documents, images, videos, and audio, and can generate high-quality images similar to other leading image-generation models. Organizations like Cisco, Siemens, Sumo Logic, and Trellix are using Nova 2 models for applications ranging from agentic threat detection to video understanding and voice AI assistants. Nova Forge: First-of-its-kind service for building your own frontier AI models Organizations embedding proprietary knowledge into AI applications currently face three compromises: customizing proprietary models in ways that only scratch the surface for integrating an organization’s expertise, continuing to train open-weights models without access to the original training data, which risks the model regressing on foundational capabilities like instruction following, or building from scratch at enormous expense. What organizations need is access to both frontier model capabilities and the ability to deeply integrate their expertise. Nova Forge empowers organizations to build their own optimized variants of Nova—we call them “Novellas”—by blending their proprietary data with Nova’s frontier capabilities. The service pioneers "open training"—giving exclusive access to pre-trained, mid-trained, and post-trained Nova model checkpoints so customers can mix their proprietary data with Amazon Nova-curated datasets at every stage of model training. The result is a customized model that combines Nova's full knowledge and reasoning power with deep understanding of each organization's specific business. Customers can start building their own Novellas with Nova 2 Lite today. In addition, Nova Forge customers get early access to Nova 2 Pro and Nova 2 Omni, which gives them a head start in building applications and their Novellas with even more capable Nova models. Beyond model checkpoints and data-mixing capabilities, Nova Forge offers three additional powerful capabilities: First, the ability to train AI using your own environments, which are referred to as reinforcement learning “gyms.” These gyms are synthetic environments where the models learn from simulated scenarios that reflect their real-world use cases. Second, option to create smaller, faster models that maintain their intelligence at a lower cost—trained on AI-generated examples from larger models through a process called synthetic data-based distillation. Third, access to a responsible AI toolkit that allows them to implement safety controls. Organizations like Booking.com, Cosine AI, Nimbus Therapeutics, Nomura Research Institute, OpenBabylon, Reddit, and Sony are building their own models with Nova Forge to better serve their unique requirements. “Working with Nova Forge is allowing us to improve content moderation on Reddit with a more unified system that's already delivering impressive results,” said Chris Slowe, CTO, Reddit. “We're replacing a number of different models with a single, more accurate solution that makes moderation more efficient. The ability to replace multiple specialized ML workflows with one cohesive approach marks a shift in how we implement and scale AI across Reddit. After seeing these early successes in our safety efforts, we're eager to explore how Nova Forge might help in other areas of our business.” Once customers create their own frontier model with Nova Forge, they can deploy it on Amazon Bedrock with the same enterprise-grade security, scalability, and data privacy as all other Bedrock models. This complete solution—from building their own frontier model to production deployment—ensures organizations achieve optimal AI performance tailored to their specific business needs, with exclusive use of their model securely hosted on AWS. Nova Act: New AWS service for building and managing reliable AI agents for UI-based workflows Nova Act is now available as a service on AWS for building and deploying highly reliable AI agents that can take actions in web browsers. Powered by a custom Nova 2 Lite model, Nova Act provides the fastest and easiest path to build and manage fleets of agents that automate browser-based tasks. Nova Act delivers 90% reliability on early customer workflows and outperforms competing models on relevant benchmarks. Nova Act achieves breakthrough reliability by training a custom Nova 2 Lite model through reinforcement learning, running thousands of tasks on hundreds of simulated web environments. This style of training allows Nova Act to excel on UI-based workflows like updating data in a customer relationship management (CRM) system, testing website functionality, or submitting health insurance claims. With Nova Act, developers can start prototyping an agent in minutes with a no-code playground using natural language prompts, refine that Nova Act agent in familiar IDEs like VS Code, and then deploy to AWS. What customers build and test locally scales in production, with comprehensive management tools and monitoring through the Nova Act AWS console. Organizations across sectors are already seeing results with Nova Act: Startup Sola Systems integrated Nova Act to automate hundreds of thousands of workflows per month for their clients across business-critical tasks like reconciling payments, coordinating shipments, and updating medical records. 1Password used Nova Act to enable users to access their logins with fewer manual steps, and works automatically with a single simple prompt that works across hundreds of different websites. Hertz accelerated its software delivery by 5x and eliminated its Quality Assurance (QA) bottleneck by using Nova Act to automate end-to-end testing across its rental platform—which processes millions in daily bookings—transforming what used to take weeks into hours. Amazon Leo eliminated its QA constraint ahead of its satellite internet launch by using Nova Act to write test scenarios in natural language that automatically execute and adapt across thousands of web and mobile test cases, reducing what previously took weeks of engineering effort to minutes while running three times faster with zero AI costs after initial runs. Getting started with Amazon Nova To learn more about Amazon Nova, visit aws.amazon.com/bedrock/nova . Start building for free at nova.amazon.com/dev . Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-agentic-ai-amazon-bedrock-nova-models</guid>
    </item>
    <item>
      <title>New AWS AI Factories transform customers’ existing infrastructure into high-performance AI environments</title>
      <link>https://www.aboutamazon.com/news/aws/aws-data-centers-ai-factories</link>
      <description><![CDATA[Key takeaways AWS AI Factories deliver dedicated infrastructure combining the latest NVIDIA accelerated computing platform, Trainium chips, AWS AI services, and AWS high-speed, low-latency networking. Customers can leverage their existing data center space, network connectivity, and power while AWS handles the complexity of deployment and management of the integrated infrastructure. AWS AI Factories help enterprises and public sector organizations meet their data sovereignty and regulatory requirements, with accelerated deployment timelines. As governments and large organizations seek to scale AI projects, some are turning to the concept of an “AI factory” to address their unique sovereignty and compliance needs. But building a high-performance AI factory requires a comprehensive set of management, database, storage, and security services—complexity that few customers want to take on themselves. To address this need, today we announced AWS AI Factories, a new offering that provides enterprises and governments with dedicated AWS AI infrastructure deployed in their own data centers. AWS AI Factories combine the latest AI accelerators, including cutting-edge NVIDIA AI computing and Trainium chips , AWS high-speed, low-latency networking, high-performance storage and databases, security, and energy-efficient infrastructure, together with comprehensive AI services like Amazon Bedrock and SageMaker AI so customers can rapidly develop and deploy AI applications at scale. Organizations in regulated industries and the public sector face a critical AI infrastructure challenge in getting their large-scale AI projects deployed. Building their own AI capabilities requires massive capital investments in GPUs, data centers , and power, plus navigating complex procurement cycles, selecting the right AI model for their use case, and licensing models from different AI providers. This creates multi-year timelines and operational complexity that diverts focus from their core business goals. AWS AI Factories address this challenge by deploying dedicated AWS AI infrastructure in customers’ own data centers, operated exclusively for them. AWS AI Factories operate like a private AWS Region that gives secure, low-latency access to compute, storage, database, and AI services. This approach lets you leverage existing data center space and power capacity you’ve already acquired and gives access to AWS AI infrastructure and services—from the latest AI chips for training and inference to tools for building, training, and deploying AI models. It also provides managed services that offer access to leading foundation models without having to negotiate separate contracts with model providers—all while helping you meet security, data sovereignty, and regulatory requirements for where data is processed and stored. Leveraging nearly two decades of cloud leadership and unmatched experience in architecting large-scale AI systems, we are able to deploy secure, reliable AI infrastructure faster than most organizations can on their own, saving years of buildout effort and managing operational complexity. AWS and NVIDIA expand collaboration to accelerate customer AI infrastructure deployments The relationship between AWS and NVIDIA goes back 15 years, to when we launched the world’s first GPU cloud instance, and today we offer the widest range of GPU solutions for customers. Building on our longstanding collaboration to deliver advanced AI infrastructure, AWS and NVIDIA make it possible for customers to build and run large language models faster, at scale, and more securely than anywhere else—now in your own data centers. With the NVIDIA-AWS AI Factories integration, AWS customers have seamless access to the NVIDIA accelerated computing platform, full-stack NVIDIA AI software, and thousands of GPU-accelerated applications to deliver high performance, efficiency, and scalability for building next-generation AI solutions. We continue to bring the best of our technologies together. The AWS Nitro System, Elastic Fabric Adapter (EFA) petabit-scale networking, and Amazon EC2 UltraClusters support the latest NVIDIA Grace Blackwell and the next-generation NVIDIA Vera Rubin platforms. In the future, AWS will support NVIDIA NVLink Fusion high-speed chip interconnect technology in next-generation Trainium4 and Graviton chips, and in the Nitro System. This integration makes it possible for customers to accelerate time to market and achieve better performance. “Large-scale AI requires a full-stack approach—from advanced GPUs and networking to software and services that optimize every layer of the data center. Together with AWS, we’re delivering all of this directly into customers’ environments,” said Ian Buck, vice president and general manager of Hyperscale and HPC at NVIDIA. “By combining NVIDIA’s latest Grace Blackwell and Vera Rubin architectures with AWS’s secure, high-performance infrastructure and AI software stack, AWS AI Factories allow organizations to stand up powerful AI capabilities in a fraction of the time and focus entirely on innovation instead of integration.” Helping the public sector accelerate AI adoption AWS AI Factories are built to meet AWS's rigorous security standards of providing governments with the confidence to run their most sensitive workloads across all classification levels: Unclassified, Sensitive, Secret, and Top Secret. AWS AI Factories will also provide governments around the world with the availability, reliability, security, and control they need to help their own economies advance and take advantage of the benefits of AI technologies. AWS and NVIDIA are collaborating on a strategic partnership with HUMAIN, the global company based in Saudi Arabia building full-stack AI capabilities, with AWS building a first-of-its-kind "AI Zone" in Saudi Arabia featuring up to 150,000 AI chips, including GB300 GPUs, dedicated AWS AI infrastructure, and AWS AI services, all within a HUMAIN purpose-built data center. “The AI factory AWS is building in our new AI Zone represents the beginning of a multi-gigawatt journey for HUMAIN and AWS. From inception, this infrastructure has been engineered to serve both the accelerating local and global demand for AI compute,” said Tareq Amin, CEO of HUMAIN. “What truly sets this partnership apart is the scale of our ambition and the innovation in how we work together. We chose AWS because of their experience building infrastructure at scale, enterprise-grade reliability, breadth of AI capabilities, and depth of commitment to the region. Through a shared commitment to global market expansion, we are creating an ecosystem that will shape the future of how AI ideas can be built, deployed, and scaled for the whole world.” For more details on AWS AI Factories, visit the product page . Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-data-centers-ai-factories</guid>
    </item>
    <item>
      <title>New agentic capabilities in AWS Transform enable rapid modernization of any code or application</title>
      <link>https://www.aboutamazon.com/news/aws/aws-transform-ai-agents-windows-modern</link>
      <description><![CDATA[Key takeaways AWS Transform custom capability makes rapid, large-scale modernizations possible for all legacy systems across any software, code, library, and framework. AWS Transform accelerates full-stack Windows modernization by up to 5x across all layers, eliminating up to 70% of customers’ maintenance and licensing costs. Air Canada, Experian, QAD, Teamfront, Thomson Reuters, and Verisk are using AWS Transform to help eliminate their tech debt. A typical organization spends 30% of its teams' time on manual modernization work, otherwise known as tech debt. This work is necessary, but takes valuable resources away from innovations that create new business value. AWS Transform , the first agentic AI service for transforming Windows .NET applications, VMware systems, and mainframes, has already helped customers modernize 4x faster with existing transformation capabilities. Customers have used AWS Transform to analyze an estimated 1.1 billion lines of code and save more than 810,000 hours of manual effort. However, customers told us they have even more systems they need to modernize, so today we’re announcing enhancements that broaden customers’ ability to rapidly modernize legacy applications and code at scale—to realize the full value of AI . AWS Transform custom capability modernizes any system, even custom to your organization We are introducing new agentic capabilities in AWS Transform to accelerate organization-wide code and application modernization across any code, API, framework, runtime, architecture, language, and even company-specific programming languages and frameworks. With pre-built transformations for common patterns (e.g., Java, Node.js, and Python upgrades) and custom transformations for organization-specific tasks, a specialized agent executes consistent, repeatable, and high-quality transformations. For a typical organization, AWS Transform custom can scale modernization across hundreds or thousands of applications, achieving transformation up to 5x faster than when done manually. The transformation agent automatically captures feedback and continues to improve over time, so each subsequent transformation becomes more reliable and efficient. Air Canada, the largest airline in Canada, needed to modernize outdated software that jeopardized the company’s rhythm of business. In only a few days, Air Canada was able to deploy AWS Transform to coordinate and execute the modernization across thousands of Lambda functions (i.e., small tasks in response to events or triggers), realizing an 80% reduction in expected time and cost for the project compared to performing the migration manually. QAD is a software company at the forefront of cloud-based solutions for global manufacturers. “For many of our customers, upgrading from older, highly customized versions to our modern cloud Adaptive ERP with Champion AI has been a real challenge. AWS Transform has completely changed that,” said Sanjay Brahmawar, chief executive officer of QAD|Redzone. “Modernizations that used to take two weeks now take just three days, driving 60%-70% productivity gains and saving more than 7,500 developer hours a year. We’ve already processed more than 180,000 lines of legacy code with exceptional accuracy—and the agent improves with each project. This means faster upgrades, fewer disruptions, and a dramatically easier path to the latest QAD Adaptive ERP platform. For our customers, this isn’t just modernization—it’s acceleration.” AWS Transform speeds up Windows modernization Customers need to modernize their complete Windows environments to reduce expensive licensing costs and improve security and performance. Starting today, AWS Transform provides an up to 5x acceleration of full-stack Windows modernization including .NET apps, SQL Server, user interface (UI) frameworks, and deployment layers into open source, cloud-native solutions. The AWS Transform agents start by analyzing the complete Windows stack and proposing coordinated modernization plans across all layers. Once approved, the agent transforms the application, UI framework, database, and operating system, while providing updates and comprehensive transformation summaries. The new capabilities enable the rapid modernization of full-stack Windows and SQL Server systems to open source alternatives, freeing customers from expensive licensing agreements and reducing operating costs by up to 70%. Teamfront is a strategic partner for market-leading software companies. "Our initial success with AWS Transform—modernizing 800,000 lines of code in just two weeks—demonstrated that we could transform massive codebases in weeks instead of months,” said Bobby Land, chief product and technology officer, Teamfront. “This breakthrough showed us a clear path to retiring technical debt and gave us the confidence to expand our modernization efforts. We're now moving from SQL Server to PostgreSQL while simultaneously transforming our applications, accelerating our modernization journey and enabling us to better serve our portfolio of field service software companies." Thomson Reuters, a global AI and technology leader powering legal, tax, government, risk, and compliance industries, used AWS Transform to move from Windows to open source alternatives to achieve better performance and lower costs. Using agentic AI-powered automation, they now boost velocity by migrating 1.5 million lines of code per month, achieving 30% lower costs, and reducing technical debt by 50%. Enhancements to AWS Transform for mainframe and VMware Drawing on nearly two decades of experience helping organizations modernize, we continue to enhance AWS Transform, today adding: New capabilities in AWS Transform for mainframe modernizationthat save time, reduce risk, and simplify migration. Three new agents build on the code analysis, business rule extraction, and technical documentation capabilities already available in AWS Transform. The agents help produce activity analysis to aid modernization and retirement decisions, blueprints for reimagining legacy code into clear business functions, capabilities, flows, and data usage, as well as simplified domain decomposition. Additionally, new task agents speed up test planning and validation by automatically generating test plans, test data collection scripts, and automation scripts, which traditionally take up to half of project timelines. New capabilities in AWS Transform for VMwarethat simplify and accelerate large-scale discovery, planning, and network migration. This includes an agentic experience for iteration and migration flexibility, which customizes and orchestrates the entire process from assessment to deployment, as well as a new on-premises discovery tool with support for security reviews and inventory discovery. A new migration planning agent applies business context using unstructured inputs (e.g., documents, files, chats, and business rules). Lastly, enhanced network migration agentic capabilities support advanced configurations and security technologies from Cisco ACI, Fortigate, and Palo Alto Networks. New AWS Transform composability initiativethat empowers our AWS Partners to integrate their proprietary tools, agents, and knowledge bases to build customized workflows for customers within the AWS Transform product experience. Accenture, Capgemini, and Pegasystems are the first AWS Partners to build new agents for AWS Transform that deliver more effective and contextually relevant transformations for customers in industries such as financial services and healthcare. For more details on AWS Transform, visit: AWS Transformproduct page AWS News Blog:Introducing AWS Transform custom: Crush tech debt with AI-powered code modernization AWS News Blog:AWS Transform announces full-stack Windows modernization capabilities AWS News Blog:AWS Transform for mainframe introduces reimagine capabilities and automated testing functionality What’s New at AWS:AWS Transform adds new agentic AI capabilities for enterprise VMware migrations See the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Sun, 30 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-transform-ai-agents-windows-modern</guid>
    </item>
    <item>
      <title>Getting started with Alexa+: How Alexa+ can keep you and your family organized</title>
      <link>https://www.aboutamazon.com/news/devices/new-alexa-plus-amazon-devices</link>
      <description><![CDATA[Key takeaways Alexa+ simplifies family life by managing calendars, digitizing recipes, and delivering personalized reminders. Alexa+ is your personal AI shopping assistant that understands your needs and simplifies every step of your shopping journey. Get proactive deal notifications, automated purchasing, and smart delivery add-ons to save time and money on every purchase. Manage all your shopping needs in one place with a new Echo Show widget that combines voice, touch, and personalized recommendations. Millions of customers with Early Access to Alexa+ are having naturally flowing conversations, discovering new features, and getting more done than ever before. They’re controlling multiple smart home devices simultaneously with a single sentence, planning their days, exploring trending topics, getting personalized recommendations, and so much more. How Amazon rebuilt Alexa with generative AI Ready to explore what Alexa+ can do for you? Whether you're new to Alexa or a longtime customer, this guide will help you get started and make the most of your Alexa+ experience. 50 things to try with Alexa+ Say “Alexa” just once 50 things to try with Alexa+ Explore Alexa+’s vast knowledge Get to know Alexa+'s personality Calendar widget:Simplify your schedule with daily, weekly, or monthly views. Just ask Alexa to show your schedule and you'll see a full-screen view of your calendar—including upcoming events like social engagements or after-school activities. You can then naturally follow up with questions about the upcoming month, for example, and Alexa will adjust the display accordingly. Smart home widget:Control your Alexa-compatible devices, access them by category or customizable groups, check device status, accessMap View, and even view recent Ring camera events. Plus, if you’re a Ring Home Premium subscriber, you can also integrate Alexa+ with Ring’sSmart Video Searchto easily search through your camera event history and view specific moments. For You widget:This new panel combines personalized notifications with tailored suggestions as you interact more with Alexa+, keeping you updated on things you've asked about and providing relevant prompts based on your interests—from conversation topics and movie recommendations to outdoor activities and more. Create personalized experiences for each family member 3 of the newest Prime benefits you need to check out, including Alexa+ Sign up for Early Access Track down any song with just a few detailslike partial lyrics, the artist’s name, where and when you heard it, or even movie soundtrack mentions. Simply describe what you remember, and Alexa+ will find the song you're looking for, making those frustrating "tip of your tongue" moments a thing of the past. Have natural conversationsfor music recommendations. Start with a broad request and refine just by asking for a specific era, mood, tempo, and even exclude specific artists or styles. Create custom soundtracksbased on activities, emotions, or unique scenarios like "music for driving along the Pacific Coast Highway at sunset." Playlists are fully dynamic—save them to your library, rename them, or ask Alexa to add specific tracks anytime. Access deep music knowledgeabout artists, albums, music history, and cultural context. Alexa+ is like having a responsive music encyclopedia that connects the dots to deliver the insights you're curious about. 50 things to try with Alexa+ Never miss a deal: Alexa+ monitors items in your cart and wish list, or you can tell Alexa specifically what items to track, like “Let me know if the Dyson cordless vacuum drops below $300.” This automated deal tracking eliminates constant price checking and ensures you get the best value on purchases. Alexa completes purchases automatically: Set your desired price for specific products, and Alexa handles the rest, using your default Amazon shipping address and payment option to complete the purchase when it falls below your target price. Imagine tracking a $200 air purifier. Tell Alexa your target price of under $100, and she'll complete the purchase the moment it drops—even at 3 a.m. when you're sleeping. Your shopping command center: The new Shopping Essentials experience transforms your Echo Show 15 and 21 into a shopping command center with real-time delivery tracking, recent orders, household essentials you may need to reorder, your shopping list, and saved items. You can easily tap to see more product details, add items directly to your cart, or checkout. Simply say “Alexa, where's my stuff?” or “Open Shopping Essentials” to get started. Soon you’ll be able to add a shopping widget to your Echo home screen. No more last-minute store runs—just add to your next delivery: Tack on last-minute needs and items you might have forgotten to incoming deliveries, so you get them faster. When Alexa knows you have a delivery coming, she'll suggest items that can be added to that shipment, right up until it leaves the fulfillment center. Forgot batteries for that new toy? Add them to tomorrow's delivery. This feature is starting to roll out now and helps consolidate orders to ensure you get everything you need faster. Personalized gift recommendations made simple: Finding the perfect gift is as simple as having a conversation with Alexa+. Share details about who you’re shopping for or the occasion, and Alexa+ will generate personalized product recommendations, visually organized into different categories for easy browsing. How Amazon is using generative and agentic AI to transform the shopping experience Amazon unveils redesigned Kindle Scribe lineup with first-ever color Scribe Your personal recipe library Amazon's next-generation Alexa Custom Assistant will power BMW's in-car voice assistant Personalized reminders for family members Managing your family calendar]]></description>
      <pubDate>Tue, 25 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/new-alexa-plus-amazon-devices</guid>
    </item>
    <item>
      <title>Amazon’s custom AI-powered Prime Insights take fans inside the game</title>
      <link>https://www.aboutamazon.com/stories/prime-video-ai-live-sports-viewers-tv</link>
      <description><![CDATA[Real-time analytics powered by custom Amazon AI models bring expert-level insights to Thursday Night Football, NASCAR, and NBA viewers.]]></description>
      <pubDate>Mon, 24 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/stories/prime-video-ai-live-sports-viewers-tv</guid>
    </item>
    <item>
      <title>5 tech predictions for 2026 and beyond, according to Amazon CTO Dr. Werner Vogels</title>
      <link>https://www.aboutamazon.com/news/aws/werner-vogels-amazon-cto-predictions-2026</link>
      <description><![CDATA[Key takeaways Technology is rapidly evolving to address fundamental human needs rather than just technical challenges, from loneliness to education to security. Developers will evolve into "renaissance" professionals who combine AI tools with uniquely human judgment and domain expertise. Organizations face urgent pressure to implement quantum-safe security as timeline projections for quantum computing breakthroughs accelerate. We have entered an era where technology increasingly addresses profound human challenges. From AI companions to quantum computing advancements, we are witnessing technology augment human capabilities in meaningful ways. In the coming years, using technology for positive impact will redefine the way we think about success—and ourselves. Amazon's chief technology officer, Dr. Werner Vogels , weighs in on what lies ahead. 1. Companionship is redefined for those who need it most Loneliness has reached epidemic proportions, affecting one in six people worldwide and designated as a public health crisis by the World Health Organization. Social isolation increases death risk by 32%, comparable to smoking, while loneliness increases dementia risk by 31%. As MIT researcher Kate Darling discovered, we're biologically hardwired to project intent and life onto autonomous movement, which is why people tend to treat robots more like animals than devices. At Amazon, our Astro team has documented people building genuine relationships with companion robots. Rather than replacing human caregivers, these robots create a collaborative model where technology and people work together to combat the loneliness epidemic. Amazon introduces new frontier Nova models, a pioneering Nova Forge service for organizations to build their own models, and Nova Act for building agents 2. The dawn of the renaissance developer As generative AI reshapes how we build software, a familiar trope has reemerged—that developers will become obsolete. But this is not the end of the developer; it's the dawn of the renaissance developer. Generative AI lets us generate code in seconds, but it doesn't sit in budget meetings where leadership debates cost versus performance. The core attributes of great developers remain constant. Creativity, curiosity, and systems thinking have continued to define the craft throughout every technological revolution. Developers who thrive in this AI-augmented world must become modern polymaths who understand that systems are living, dynamic environments. AWS unveils frontier agents, a new class of AI agents that work as an extension of your software development team 3. Quantum-safe becomes the only safe Personal data, financial records, and state secrets are already being harvested by adversaries betting on quantum's arrival to decrypt later. Advances in error correction have compressed timelines, and the window for proactive defense is closing. Organizations need to act on three fronts: deploying post-quantum cryptography now, planning to update physical infrastructure, and developing quantum-ready talent. New Amazon Bedrock AgentCore capabilities power the next wave of agentic AI development 4. Defense technology changes the world Military investment in technology is surging, both by governments and the private sector. Innovation has accelerated and software updates for autonomous systems happen weekly, not annually. Algorithms learn from real-world data and improve overnight. Civilian organizations will be able to take advantage of these advances in defense technology and apply them to solving critical problems: from disaster response and food security to health care access in remote regions. 5. Personalized learning meets infinite curiosity Every student deserves an educator who engages their curiosity and nurtures creativity. But for most of human history only the wealthy could afford a personal tutor. That's about to change. AI-powered personalized tutoring changes education fundamentally. Khan Academy's Khanmigo reached 1.4 million students in its first year. According to a UK survey, the proportion of students using any AI tool jumped from 66% last year to 92% this year. Teachers are NOT going away. What's changing is what teachers do. AI is freeing them from administrative tasks while enabling more creative and individualized education. Read the full predictions on Vogels' blog on All Things Distributed . Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Mon, 24 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/werner-vogels-amazon-cto-predictions-2026</guid>
    </item>
    <item>
      <title>5 things you need to know about re:Invent, AWS’s biggest AI and cloud event of the year</title>
      <link>https://www.aboutamazon.com/news/aws/what-is-aws-reinvent</link>
      <description><![CDATA[Key Takeaways AWS re:Invent 2025 returns December 1-5 with agentic AI as the central theme across 600+ technical sessions. Five keynotes from AWS leaders, including AWS CEO Matt Garman, will show how the company is reinventing what's possible in the agentic AI era. Industry leaders from Sony, Adobe, Blue Origin, and more will join AWS experts to share real-world applications of agentic AI. Tens of thousands of cloud computing experts, builders, customers, partners, and technology enthusiasts will once again gather in Las Vegas for Amazon Web Services’ re:Invent . The 14th annual event takes place December 1-5, 2025, featuring keynotes, innovation talks, hands-on labs, workshops, demos, service announcements, and much more. Here are five things to expect at AWS re:Invent 2025: Agentic AI takes center stage Agentic AI—systems that can operate autonomously to accomplish tasks—will be a major theme throughout the week. With more than 600 technical sessions exploring how AI agents are transforming applications, workplaces, and business processes, attendees will discover the latest advancements in this rapidly evolving field. New Amazon Bedrock AgentCore capabilities power the next wave of agentic AI development Five keynotes from AWS leadership AWS leaders will deliver five keynotes showcasing technological breakthroughs in agentic AI, cloud infrastructure, and foundation models: Tuesday, Dec 2, 8:00 a.m. PST – 10:30 a.m. PST:AWS CEO Matt Garmanopens the week with insights on reinventing foundational building blocks and new experiences to empower customers. Garman will be joined by John Kodera, chief digital officer of Sony Group, Shantanu Narayen, CEO of Adobe, and May Habib, CEO and co-founder of Writer to discuss AI transformation strategies. Wednesday, Dec 3, 8:30 a.m. PST – 10:30 a.m. PST:Dr. Swami Sivasubramanian, vice president for agentic AI at AWS, presents "The Future of Agentic AI is Here" with Colleen Aubrey, SVP of AWS Applied AI Solutions, and Byron Cook, vice president, distinguished scientist, Automated Reasoning Group of AWS. You’ll hear about how to build, deploy, and run agents on AWS, and the engineering behind them. Wednesday, Dec 3, 3:00 p.m. PST – 4:30 p.m. PST:VP of Global Specialists and Partners Dr. Ruba Borno delivers "The Partnership Advantage", including a fireside chat with AWS CEO Matt Garman, discussing customer transformations empowered through AWS solutions. Featured guest Sanjay Bhakta, chief product and technology officer at Condé Nast, will discuss leveraging AWS services to build scalable, resilient technology ecosystems. Thursday, Dec 4, 9:00 a.m. PST – 10:30 a.m. PST:SVP of Utility Computing Peter DeSantis and VP of Compute and Machine Learning Services Dave Brown dive deep into infrastructure innovations with Jae Lee, CEO and co-founder of TwelveLabs, whose multimodal AI foundation models are powering next-generation video understanding on Amazon Bedrock. Thursday, Dec 4, 3:30 p.m. PST – 4:30 p.m. PST:Amazon CTO Dr. Werner Vogels concludes with his "definitive developer keynote." Vogels will explore how software development is evolving in an AI-driven world. View the full agenda , and get keynote details . Innovation talks dive into technical frontiers Beyond the keynotes, 15 innovation talks will provide deeper exploration of cutting-edge technologies. These sessions, led by AWS thought leaders, offer attendees the chance to understand complex topics in greater detail, including analytics and data, security and identity, storage innovations, financial services, and public sector applications. Immersive Expo experiences and sessions The re:Invent Expo will bring AWS technology to life with demos, prototypes, and partner solutions. Attendees can explore interactive exhibits showcasing agentic AI, autonomous robotics, and sustainability innovations. Beyond the main Expo floor, re:Invent offers diverse learning opportunities across multiple venues. Attendees can participate in hands-on workshops, interactive builders' sessions with AWS experts, code-focused talks featuring live demonstrations, and collaborative chalk talks that address real-world architecture challenges. Werner Vogels' keynote and T-shirt reveal One of the most anticipated moments of re:Invent is Amazon CTO Dr. Werner Vogels' closing keynote on Thursday, December 4. Known for his insightful technical presentations and movie-style video intros—delivered in a themed T-shirt—Vogels will share his vision for how AI is transforming software development. Catch up on his 2026 tech predictions before the keynote begins. 5 tech predictions for 2026 and beyond, according to Amazon CTO Dr. Werner Vogels Whether attending in person or participating virtually, re:Invent 2025 offers a unique opportunity to connect, learn, and be inspired by the latest in cloud technology. With its expanded focus on agentic AI, the event promises to deliver insights into how advanced cloud services are shaping the future of business and technology. To learn more about AWS re:Invent 2025, including registration information and the complete session catalog, visit aws.amazon.com/reinvent .]]></description>
      <pubDate>Mon, 24 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/what-is-aws-reinvent</guid>
    </item>
    <item>
      <title>Amazon plans to invest $15 billion in Northern Indiana to build new data center campuses and advance AI innovation</title>
      <link>https://www.aboutamazon.com/news/company-news/amazon-15-billion-indiana-data-centers</link>
      <description><![CDATA[Key takeaways Amazon plans to invest an additional $15 billion in Northern Indiana to build data center campuses, creating 1,100 new high-skilled jobs and supporting thousands more in the data center supply chain. The new project will add 2.4 gigawatts of data center capacity in the region. Energy agreement with NIPSCO will improve local citizen services and is expected to provide approximately $1 billion in cost savings to current Indiana residents and businesses over 15 years. Since 2010, Amazon has invested more than $31.3 billion in Indiana, contributing more than $29.9 billion to the state's GDP and supporting 24,500 full and part-time jobs, plus 27,500 indirect jobs, across various facilities. Amazon will bring training and education programs, including data center technician programs, fiber optic fusion splicing workshops, and STEM awareness and learning opportunities for K-12 schools, to local communities. Today, Amazon announced plans to invest an estimated $15 billion in Northern Indiana to build new data center campuses to support artificial intelligence (AI) and cloud computing technologies. Generative AI is driving increased demand for advanced cloud infrastructure and compute power, and Amazon’s investment will support the future of AI innovation from new data center campuses in the Hoosier State. This investment is additional to the $11 billion investment announced last year in St. Joseph County and will expand our infrastructure to new sites across Indiana. This new project, which will add 2.4 gigawatts of data center capacity in the region, builds on AWS’s strong track record of innovation, scale, and engineering excellence—bringing the same advanced infrastructure that powers Project Rainier , the world’s largest AI supercomputer. By designing our own chips , servers, and network architecture, AWS delivers unmatched performance, security, reliability, and efficiency for customers running the world’s most demanding compute workloads. These facilities are purpose-built for scale—optimized for AI, machine learning, and next-generation cloud applications—while maintaining industry-leading standards in energy efficiency and sustainability. Together, our existing and future data center campuses represent the next step in our mission to provide the most advanced, secure, and sustainable cloud infrastructure anywhere in the world. An AWS technician gives us a tour of a data center—see what it's like inside This landmark investment is expected to create more than 1,100 new high-skilled jobs while supporting thousands of other jobs in the data center supply chain. New high-skilled jobs will range from data center engineers and network specialists, to engineering operations managers, security specialists, and many more technical roles. In addition to these direct positions, this planned investment is expected to support thousands of local electricians, construction workers, and fiber-optic technicians, and other jobs within the local community. “This is a massive win for Hoosier ratepayers. This agreement will ensure a surplus in new energy development that will deliver real savings to Hoosier ratepayers,” said Indiana Governor Mike Braun. “Amazon’s historic investment shows that Indiana’s business-friendly climate continues to attract world-class employers and drive growth in our state. This project will create more than a thousand jobs while supporting thousands more across the region, further strengthening Indiana’s position in energy dominance and economic leadership.” “Indiana has long been an important partner for Amazon, and today we are proud to reaffirm our commitment to long-term investment and growth, underscoring our dedication to fueling AI innovation while generating meaningful economic impact throughout the state," said David Zapolsky, Amazon's chief global affairs and legal officer. "By expanding our advanced cloud infrastructure in Indiana, we are investing in Indiana's technological future through job creation, skills training initiatives, and community engagement programs. We're excited to help power the next wave of technological advancement while delivering tangible benefits that will enhance the lives of Indiana residents for years to come." How Amazon helps data center communities thrive Powering Indiana’s future: A partnership that benefits everyone Amazon’s energy strategy is part of our customer obsession, and that includes the communities where we operate. That’s why Amazon and NIPSCO have established a first-of its kind framework specifically developed with local residents and small businesses in mind, to power Amazon data centers—helping to bring more connectivity, faster speeds, and innovative AI tools locally and across the U.S.—while delivering substantial benefits to existing customers. Through its newly created subsidiary, NIPSCO Generation LLC (GenCo), Amazon will pay fees to use existing power lines and cover the costs for any new power plants, power lines, or equipment needed to serve the data center project—without additional cost to local residents and businesses. This is just one way Amazon is structuring new energy deals to ensure communities aren't impacted. “This agreement structure with Amazon represents approximately $1 billion in cost savings over 15 years to our existing NIPSCO electric customers while strengthening our regional grid and economic future,” said Vince Parisi, NIPSCO president and chief operating officer. “By structuring this agreement thoughtfully, we're ensuring our current customers are protected, without increasing their rates, while we expand our capacity to meet growing demands. This project isn't just about powering data centers, it's about powering possibilities for our communities through thousands of new jobs, an expanded tax base, and building a skilled workforce in Northern Indiana for long-term growth and prosperity.” In total, the new project will add up to 3 gigawatts of new capacity, which goes beyond serving only Amazon's needs of 2.4 gigawatts. This additional generation helps to enhance grid reliability for all of NIPSCO's customers, while also adding greater assurance that the grid remains reliable during periods of peak stress, such as hot summer days and cold winter nights. Amazon is committed to building, growing, and investing in Indiana's energy infrastructure for the long-term. How Amazon is harnessing solar energy, batteries, and AI to help decarbonize the grid The agreement with NIPSCO represents a win for all stakeholders. For local residents and businesses, it means an estimated $1 billion in cost-savings over the life of the contract without bearing any project risks. And, for the communities in Northwest Indiana, it’s an opportunity to benefit from major economic development opportunities and skills training enabled by Amazon's investment. “This project will create good-paying jobs for Hoosiers, expand our tax base, and strengthen the economic foundation for communities across the state,” said U.S. Representative Rudy Yakym. “It also positions Indiana at the forefront of America’s next generation of innovation. As our country races to lead in artificial intelligence and advanced computing, investments like this ensure we are building that future here at home and delivering new opportunities for hardworking Hoosier families.” Supporting education, skills training, and more As part of today’s announcement, we are also reinforcing the following commitments to Indiana communities: Support for Indiana community colleges, technical schools, universities, and workforce development organizations to design, develop, and grow training programs and work-based learning opportunities that prepare job seekers for high-demand career pathways in the growing field of data center construction and operations, as well as the broadband industry. This training and support will include facilities and equipment donations to empower hands-on learning; faculty training from industry subject matter experts; and curricular content to link programs of study to industry standards and best practices. This builds on existing partnerships and programs such as: Amazon Community Workforce Accelerator (CWA):training centers that support careers in cloud computing infrastructure with AWS and our network of contractors, vendors and partners. With cutting edge facilities and a network of training providers—community colleges, universities, school districts, industry training organizations, and AWS itself—CWAhouses a variety of skilled technical trades training programs to prepare the workforce of tomorrow to build, connect, power and operate, and maintain AWS's data centers in this region. Data Center Operations and Fiber Optic Technician Programs: bringing industry experts and state-of-the-art equipment to local education institutions to train the next generation of Indiana data center operators. Ivy Tech integrated these programs into its curriculum in 2025. Fiber Optic Fusion Splicing Workshops:two-day certificate courses implemented at local community colleges, technical schools, and universities that train individuals in fusion splicing (the welding together of fiber optical cables) techniques and equipment, then connect these learners to fiber-broadband employers. Information Infrastructure Workshops for Educators:a one-day workshop to help education and workforce leaders better understand the physical layer of cloud computing and our information economy, and the many different careers that are available. AWS Information Infrastructure Pre-Apprenticeship:a paid pre-apprenticeship designed for students and job-seekers to prepare for entry into any one of several careers that build, connect, power, and operate the infrastructure of the information economy. Those who successfully complete the program will earn industry-recognized credentials and a guaranteed interview with AWS or one of our contractors. The program launched at Ivy Tech in April and the first class graduated the program in May. Watch: What it’s like having data centers in your community Support for STEM awareness and learning opportunities for K-12 school systems, including: We Build it Better: a set of industry-designed curricular experiences and resources that engage middle school and older students in a work-like STEM environment stocked with industry-grade tools. We Will Build it Better: a career awareness program for elementary classrooms to engage students in a work-like STEAM environment, complete with an array of industry-grade hand tools and technology. Think Big Experiences: aninnovative initiativeempowering students in technology, programming, and robotics, inspiring young people to pursue careers in technology. Support for education institutions and independent learners with free, ready-to-learn cloud computing curriculum that works backward from employer demand for specific skills and roles in cloud support, software development, and data integration, among other in-demand cloud computing skills. As of 2024, AWS has helped more than 31 million learners across 200 countries and territories build their cloud skills through free training initiatives. Support for local partners to implement high-impact programs aimed at fostering the sustained growth and prosperity of the region. As part of our long-term community investment, we will launch the Amazon Community Fund in the communities where we will build and operate. This grant program is aimed at supporting initiatives focused on key themes, including STEM education, sustainability and environment, digital skills, culture and heritage, health, and well-being. In collaboration with community partners and stakeholders, we will identify opportunities to enhance community infrastructure, revitalize public areas, create new green spaces, promote sustainability and invest in what matters to the local community. By focusing on hyperlocal needs, these investments will strengthen communities and create lasting positive impact, ensuring resources are directed to the projects and programs that matter most to the communities it serves. Amazon’s ongoing commitment to Indiana These cloud computing and AI innovation campuses join a growing Amazon operations footprint across the state that now includes 15 fulfillment and sortation centers, 11 delivery stations, and data centers in New Carlisle, Indiana. Inside the delivery station putting dozens of sustainability strategies to the test Since 2010, Amazon has invested more than $31.3 billion in Indiana, including infrastructure and compensation to employees, and has created more than 24,500 direct jobs across the state. These investments support an additional 27,500 indirect jobs, in fields like construction and professional services, and have contributed more than $29.9 billion to the Indiana GDP, in addition to Amazon’s investments. We have also made significant investments in renewable energy projects, including four solar farms and a wind farm. We choose locations for our data center campuses that provide robust utility infrastructure, a skilled workforce, and opportunities to support public services through increased tax revenue. Our goal is to create a positive impact across the state of Indiana, and drive increased job creation , educational partnerships , sustainability initiatives , and community reinvestment . We are proud to expand our operations in Indiana to help drive AI innovation and are grateful for the state and local leaders who have partnered with us. We look forward to keeping the state of Indiana at the leading edge of the digital age. Learn more about the ways in which Amazon data centers benefit local communities .]]></description>
      <pubDate>Sun, 23 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/company-news/amazon-15-billion-indiana-data-centers</guid>
    </item>
    <item>
      <title>Claude 4.5 models from Anthropic available in Amazon Bedrock</title>
      <link>https://www.aboutamazon.com/news/aws/anthropic-claude-4-opus-sonnet-amazon-bedrock</link>
      <description><![CDATA[November 24, 2025: This article has been updated to reflect the availability of Claude Opus 4.5. October 15, 2025: This article has been updated to reflect the availability of Claude Haiku 4.5. September 29, 2025: This article has been updated to reflect the availability of Claude Sonnet 4.5. August 5, 2025: This article has been updated to reflect the availability of Claude Opus 4.1. Key takeaways Hybrid reasoning Claude 4.5 models let customers choose between near-instant responses and deeper reasoning. These models transform how businesses deploy AI for both complex tasks and everyday high-volume operations. Claude 4.5 models are designed to power more capable, autonomous AI agents for multi-step workflows across thousands of steps. Claude Haiku 4.5 delivers fast and cost-effective near-frontier intelligence to power scaled sub-agents and free products. Claude Opus 4.5 is Anthropic’s most advanced model, setting a new standard for coding, agents, and computer use, and office tasks. Amazon Web Services (AWS) has announced the availability of Claude Opus 4.5 in Amazon Bedrock , which joins the existing Claude models available to customers, including the recently launched Claude Haiku 4.5 and Claude Sonnet 4.5. These hybrid reasoning models (meaning they can toggle between near-instant responses and extended thinking) have set new standards across coding, advanced reasoning, and multi-step workflows. This generation of Claude models spans the development lifecycle, with Claude Opus 4.5 setting new standards for sophisticated coding and agentic workflows, Claude Sonnet 4.5 sitting at the sweet spot for rapid iteration and scaled use cases, and Claude Haiku 4.5 offering the best combination of performance, price, and speed for scaled sub-agent and free tier products. The expansion of Claude models available in Amazon Bedrock enhances customers’ AI choices with increasingly advanced models, simplifying how customers build better, more transformative applications with enterprise-grade security and responsible AI controls. Why you should care The latest Claude models fundamentally change how teams approach both complex and latency-sensitive projects. Claude Opus 4.5is Anthropic’s most capable model and best vision model to date. Claude Opus 4.5 sets a new standard across coding, agentic workflows, and computer use, enabling sustained performance on complex, long-running tasks and powering AI agents capable of doing hours of work in minutes. Claude Opus 4.5 also excels at office tasks, powering agents that produce professional documents, spreadsheets, and presentations with consistency for industries that require precision such as finance. Customers should use Claude Opus 4.5 for their production level use cases and for use cases that warrant frontier performance. Claude Haiku 4.5is Anthropic’s most efficient model, delivering near-frontier performance quickly and cost effectively. Specifically, Claude Haiku 4.5 matches Claude Sonnet 4 performance on coding, computer use, and agentic tasks, making it well suited to power scaled sub-agent deployments, budget-constrained applications, and free products. In addition, the speed of Claude Haiku 4.5 makes agents using computers faster and more responsive, and is advantageous for use cases where response time is critical, like customer service agents and chatbots. Claude Sonnet 4.5is Anthropic’s powerful, mid-sized model, combining strong reasoning with efficient performance. It is ideal for simpler coding workflows, agents with fewer tools, and fast prototyping development cycles. It demonstrates enhanced knowledge across finance, research, and cybersecurity, supporting use cases like financial forecasting, vulnerability detection and patching, and content generation. All models include an optional “extended thinking” mode, which allows Claude to perform deep reasoning before taking action. Meet the AI Claude Opus 4.5 is a meaningful step forward in what AI systems can do. Opus 4.5 raises the bar for AI performance, bringing exceptional capabilities in coding, document creation, and tool use, while making professional-grade AI more accessible and scalable than ever before. Think of Claude Sonnet 4.5 as an everyday collaborator that can work independently for hours without missing a beat, expertly juggling multiple complex tasks across coding, financial analysis, and research while consistently delivering polished, actionable results that make everyone's job easier. Like an energetic and efficient collaborator, Claude Haiku 4.5 can handle a variety of tasks with remarkable speed and performance—whether it’s enabling customer chatbots or powering free-tier experiences and sub-agents. Straight from the source: Anthropic on Claude "Claude models consistently set new standards in coding, advanced reasoning, and multi-step workflows while understanding full business contexts and delivering precise results," Kate Jensen, head of Growth and Revenue of Anthropic, said. "The real breakthrough is freeing your talent for strategic work while Claude handles the heavy lifting." Crunching the numbers Claude Opus 4.5 is Anthropic’s best model for production code and sophisticated agents, achieving a new state-of-the-art 80.9% on SWE-bench Verified. Claude Opus 4.5 also outperforms Anthropic’s prior models on vision, achieving 80.7% on MMMU (validation). According to Anthropic, Claude Sonnet 4.5 advances its state-of-the-art coding performance to 77.2% onSWE-benchand to 82% when evaluating multiple answers simultaneously (i.e., parallel test-time compute), showing stronger judgment on refactoring and generating production-ready code more effectively for frontier coding agents and critical coding tasks. Meanwhile, Claude Haiku 4.5 scores 73.3% on SWE-bench, indicating its usefulness for parallelized execution, coding and sub-agents. Beyond coding, Sonnet 4.5 offers new memory capabilities (ability to save, maintain, and reference information over time) and improves Claude’s agentic capabilities with enhanced ability to coordinate with sub-agents. The model also is more consistent, follows directions better, and is more creative in problem solving, making it well suited for enterprise customers. The models can switch between providing a quick, direct answer and step-by-step thinking—improving performance for multi-step workflows by substantial margins on key industry benchmarks. The bigger story This next generation of Claude models represents a significant leap forward in agentic AI capabilities, transforming how businesses can deploy AI for both specialized complex tasks and everyday high-volume operations. Rather than simply generating content, Claude 4.5 models function more like expert virtual collaborators—maintaining focus across complex tasks, preserving relevant context, and delivering complete solutions without constant guidance. This capability transforms how organizations can tackle challenges from developing software systems to creating comprehensive marketing strategies. For everyday users, it means working with AI that better understands their needs and can take on more significant portions of projects independently. What's around the corner? According to Anthropic, the latest generation of Claude models points toward a future where AI systems become increasingly capable partners in both creative and knowledge work. For example: taking on more specialized roles in organizations like handling routine analysis, coordinating across departments, and even managing complete workflows with minimal oversight. Dive deeper Visit Anthropic’s Claude in Amazon Bedrock product page. for more detailed information on Claude Opus 4.5, Claude Haiku 4.5, Claude Sonnet 4.5, Claude Opus 4.1, and Claude Sonnet 4.]]></description>
      <pubDate>Sun, 23 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/anthropic-claude-4-opus-sonnet-amazon-bedrock</guid>
    </item>
    <item>
      <title>Amazon to invest up to $50 billion to expand AI and supercomputing infrastructure for US government agencies</title>
      <link>https://www.aboutamazon.com/news/company-news/amazon-ai-investment-us-federal-agencies</link>
      <description><![CDATA[Key takeaways Amazon Web Services (AWS) will build and deploy the first-ever AI and high-performance computing (HPC) purpose-built infrastructure for the U.S. government. New investment will add nearly 1.3 gigawatts of compute capacity across AWS Top Secret, AWS Secret, and AWS GovCloud (US) Regions across all classification levels. Expands access to AWS's trusted infrastructure and comprehensive AI services to help government agencies advance America’s AI leadership. Today, Amazon announced an investment of up to $50 billion to expand AI and supercomputing capabilities for Amazon Web Services (AWS) U.S. government customers. This investment, set to break ground in 2026, will add nearly 1.3 gigawatts of AI and supercomputing capacity across AWS Top Secret, AWS Secret, and AWS GovCloud (US) Regions by building data centers with advanced compute and networking technologies. Federal agencies will gain expanded access to AWS 's comprehensive AI services, including Amazon SageMaker AI for model training and customization, Amazon Bedrock for model and agent deployment, Amazon Nova , Anthropic Claude , and leading open-weights foundation models, and AWS Trainium AI chips, as well as NVIDIA AI infrastructure, equipping agencies to develop custom AI solutions, optimize massive datasets, and enhance workforce productivity. These new capabilities will be available to existing and future U.S. government customers across AWS Top Secret, AWS Secret, and GovCloud (US) Regions, strengthening America's AI leadership and giving federal agencies the secure, scalable infrastructure they need for the next era of innovation. This investment will enable government agencies to accelerate discovery and decision-making across government missions. By integrating simulation and modeling data with AI, agencies can achieve in hours what once took weeks or months through autonomous experimental steering and real-time feedback loops. Research teams can process decades of global security data across hundreds of variables in real-time, transforming complex pattern analysis into instantly actionable insights while dramatically reducing massive datasets. Advanced computing can turn formerly fragmented supply chain, infrastructure, and environmental data into a unified picture. Defense and intelligence workflows that once required weeks of manual analysis can automatically detect threats and generate response plans by processing satellite imagery, sensor data, and historical patterns at unprecedented scale. This integration of AI with modeling and simulation positions America to tackle its most complex challenges with unprecedented speed and precision. The investment will transform critical U.S. government and industrial base missions ranging from national security to scientific research and innovation—including autonomous systems development, cybersecurity, energy innovation, and healthcare research—positioning America to lead in the next generation of computational discovery. Amazon's investment directly supports the priorities outlined in the Administration's AI Action Plan , as well as other advanced computing initiatives deployed on secure, U.S.-based AI and cloud infrastructure. "Our investment in purpose-built government AI and cloud infrastructure will fundamentally transform how federal agencies leverage supercomputing,” said AWS CEO Matt Garman. “We're giving agencies expanded access to advanced AI capabilities that will enable them to accelerate critical missions from cybersecurity to drug discovery. This investment removes the technology barriers that have held government back and further positions America to lead in the AI era." Amazon’s investment underscores the strategic importance of AI and supercomputing in maintaining technological superiority, safeguarding critical infrastructure, and driving industrial innovation. Federal customers and the supporting industrial base share a vision of AI and HPC convergence. This includes orchestrating expert AI models, agents, and natural language interfaces to enable researchers and engineers to explore complex problems through conversational interaction. This represents a fundamental shift from traditional HPC workflows to AI-accelerated discovery, where scientists can specify challenges and receive AI-driven recommendations backed by high-fidelity simulations and analysis. Building on a foundation of government innovation Today's announcement highlights AWS's position as the leader in government cloud computing, supporting more than 11,000 government agencies. AWS's proven commitment to large-scale government innovation spans over a decade, marked by several industry-first achievements: 2011: Launched AWS GovCloud (US-West) , becoming the first cloud provider to build infrastructure specifically for government security and compliance requirements; 2014: Introduced AWS Top Secret-East, the first air-gapped commercial cloud accredited to support classified workloads; 2017: Launched AWS Secret Region , becoming the first cloud provider accredited across all US government data classifications—Unclassified, Secret, and Top Secret; and 2018-2025: Expanded government cloud infrastructure with AWS GovCloud (US-East) , AWS Top Secret-West , and AWS Secret-West Regions . AWS's experience building infrastructure at all scales and providing comprehensive security, compliance, and governance tools for controlled unclassified and classified data allows federal agencies to focus on mission outcomes rather than managing complex, on-premises systems. For more information about how AWS enables American AI leadership, visit https://aws.amazon.com/federal/america-ai]]></description>
      <pubDate>Sun, 23 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/company-news/amazon-ai-investment-us-federal-agencies</guid>
    </item>
    <item>
      <title>Small space, super bass: How Amazon's audio engineers packed premium sound into our new Echo devices</title>
      <link>https://www.aboutamazon.com/news/devices/amazon-echo-dot-max-echo-studio-sound-quality-bass</link>
      <description><![CDATA[Key takeaways Amazon's new Echo Studio is 40% smaller while Echo Dot Max delivers triple the bass of standard models. Both Echo speakers automatically adapt to any room's acoustics, no manual calibration required. Amazon engineers pushed to the point of "breaking physics" to maximize sound quality. When Amazon's audio hardware team began work on a new lineup of Echo speakers , they knew two things for sure. First, customers were eager to see Amazon’s premium audio capabilities expand to more devices in the Echo lineup . Second, customers would appreciate devices that fit in more places across their shelves, furniture, and countertops. Combined, those factors have driven the team's work to deliver two groundbreaking new devices: an all-new Echo Studio that packs powerful, immersive, and spatial sound into a 40% smaller package and the first-ever Echo Dot Max, which elevates Amazon's entry-level speaker line with premium audio capabilities and that delivers nearly three times as much bass as the Echo Dot . Alexa+ launches in Canada, the first country to get the next generation of Alexa outside the US "This was very much a ground-up effort to develop something that would delight our customers," says Richard Little, senior manager for audio hardware technology. "We designed these devices to really push the limits of what is physically possible." The result is Amazon's most advanced Echo speakers yet. The all-new Echo Dot Max and Echo Studio feature next-gen AI processing and an Omnisense sensor fusion platform that powers more proactive and personalized Alexa+ experiences. And they deliver deep bass and premium sound quality in packages that are smaller and more stylish than ever—while also enabling a completely revamped Alexa Home Theater experience that makes high-quality surround sound accessible to any customer. The big squeeze The audio team began its development journey by working with Amazon's industrial design team to settle on speaker shapes and sizes that would win over customers. "We tried cylinders and boxes and spheres—all these basic shapes—and the sphere was the favorite," says Philip Hilmes, director of audio technology. "So then we asked, 'How big of a sphere should we do?' Nobody wants a watermelon-sized thing in their living room." For the new Echo Studio , they settled on a diameter of just about 6 inches, the size of a large grapefruit—40% smaller than the original Studio. This is where physics became a challenge, especially when it came to delivering the bass that customers expected. Bass output is a function of how much air the speaker can move, and a smaller package means less air to work with. Moreover, the woofers that push that air have to leave room for other components doing different jobs. For the new Echo Studio, the team had to completely reimagine how to deliver the same powerful spatial audio experience in a much smaller package. "We custom designed the full range drivers and extended bandwidth to optimize for spatial audio in its form factor," Little explains. The team also optimized the precise locations and orientations of the three full-range drivers in the Echo Studio, to achieve the best possible spatial coverage. Amazon's Echo Dot Max and Echo Studio, built for Alexa+, now available The Echo Dot Max presented its own engineering challenges. Unlike some current and previous generation Echo Dot models with a single speaker, the team made a bold decision to introduce a two-way speaker system to this entry-level device for the first time. The team also completely reimagined the internal architecture of the Echo Dot Max. Previous Echo Dot designs housed the speaker components in an internal module within the device's shell. With the Echo Dot Max, the team eliminated this inner module altogether through innovative engineering, instead sealing the speaker components directly to the device housing. Though slightly more challenging to test, this design choice roughly doubled the available airspace behind the speaker. The additional space allowed the team to incorporate a larger driver with fewer space restrictions and optimize power efficiency, dramatically boosting the bass output. Super bass Over the course of more than 30 prototypes across both devices, the team worked through challenges around power management, thermal limits, and ventilation. They solved each not just by playing with different arrangements inside the spheres, but by custom designing most of the devices' components in-house. "We shrunk the size of our components to fit within a smaller, more appealing industrial design, but pushed their physical limits to output more sound and maximize performance," Little says. Had they used off-the-shelf components, a much larger product footprint would have been needed, compromising what customers wanted—a beautiful design that sounds amazing. And where they did hit physical limitations, custom software came to the rescue. With the woofers, for example, the hardware team didn't have to rely solely on hardware to limit distortion because they developed proprietary software algorithms to correct any imperfections in sound. "No matter what you’re playing, we have an algorithm that maximizes the bass and delivers it as cleanly as possible while minimizing distortion," Little says. Acoustic transparency Another challenge came from the exteriors of both speakers, with a new design for the 3D knit fabric that surrounds the devices. "Think about a sail," Little says. "If the wind is fluttering, you'll hear the sound of it flapping." Even though the speaker fabric is porous, the pressure of the air moving through it can create a similar effect. The goal of fabric with "acoustic transparency" creates a delicate balancing act for engineers. If the fabric is too loose and starts to move in response to the air pushed by the speakers—particularly the powerful bass from the woofers—it creates its own unwanted sound. If the fabric is too dense, sound can't pass through effectively. The solution required both sophisticated materials science, advanced acoustic modeling and measurement methods, and clever engineering. The team developed a hidden tensioning system housed within the power port that keeps the fabric perfectly taut. They also meticulously tuned the audio output to compensate for the frequencies most affected by the fabric covering. Amazon announces new Fire TV lineup with Alexa+ to get you to what you want to watch, fast Spatial awareness Even the best-designed speaker can sound mediocre if it's placed in an acoustically challenging environment. A speaker that sounds perfect in a basement bedroom will perform quite differently in a spacious living room with vaulted ceilings. Rather than leave this challenge for customers to solve with tedious manual calibration, the team designed the Echo Dot Max and Echo Studio to listen to what they’re playing, understand how the environment is changing what customers hear, and re-balance their sound accordingly. "You have to train algorithms to make that decision for you,” Hilmes says. “We gain insights from many real-world living rooms, including both simulated living rooms we have here in our audio labs, and a lot of computer-simulated rooms with different dimensions, materials, and furniture configurations.” This room adaptation technology means customers don't need to be audio experts to get optimal sound. The speakers do the work, continuously monitoring and adjusting their output to match their environment. Your new home theater All these audio innovations—now widely available—come together in the completely reimagined Alexa Home Theater system, which lets customers easily create high-quality surround sound in their homes. With the new Alexa Home Theater experience, Amazon expanded the configuration from supporting just a pair of Echo speakers and a sub, to now up to five of either Echo Dot Max or Echo Studio devices and a subwoofer that will enable surround sound customers can hear from every angle. And thanks to that spatial awareness, customers don’t have to run extension cords around the room in search of the ideal setup spot. “You can just put your speakers anywhere they blend in best with your home,” Hilmes says. “We do the rest. That’s the power of Alexa Home Theater.” The sound of success The result of this development journey is a family of devices that embody Amazon's approach to innovation—start with what customers want, then find creative ways to deliver it even when the laws of physics seem to be working against you. "We've really pushed the envelope in terms of trying to get more out of products that are really small," Little says. "I mean we literally pushed it to the point where we were going to be breaking physics." It's an achievement that required rethinking not just how speakers are built, but how they interact with their environments and the people who use them—a harmony of industrial design, acoustic engineering, and artificial intelligence creating something that truly transforms how customers experience sound. Next, learn more about how Amazon's next-generation Alexa Custom Assistant will power BMW's in-car voice assistant .]]></description>
      <pubDate>Sun, 23 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/amazon-echo-dot-max-echo-studio-sound-quality-bass</guid>
    </item>
  </channel>
</rss>