<?xml version="1.0" ?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>NVIDIA Generative AI News</title>
    <link>https://blogs.nvidia.com/blog/category/generative-ai/</link>
    <description><![CDATA[Latest news from NVIDIA Generative AI Blog]]></description>
    <language>en-US</language>
    <lastBuildDate>Thu, 18 Dec 2025 10:04:39 GMT</lastBuildDate>
    <generator>rfeed v1.1.1</generator>
    <docs>https://github.com/svpino/rfeed/blob/master/README.md</docs>
    <item>
      <title>Into the Omniverse: OpenUSD and NVIDIA Halos Accelerate Safety for Robotaxis, Physical AI Systems</title>
      <link>https://blogs.nvidia.com/blog/openusd-halos-safety-robotaxi-physical-ai/</link>
      <description><![CDATA[Editorâ€™s note: This post is part of Into the Omniverse , a series focused on how developers, 3D practitioners and enterprises can transform their workflows using the latest advancements in OpenUSD and NVIDIA Omniverse . Physical AI is moving from research labs into the real world, powering intelligent robots and autonomous vehicles (AVs) â€” such as robotaxis â€” that must reliably sense, reason and act amid unpredictable conditions. To safely scale these systems, developers need workflows that connect real-world data, high-fidelity simulation and robust AI models atop the common foundation provided by the OpenUSD framework. The recently published OpenUSD Core Specification 1.0 , OpenUSD â€” aka Universal Scene Description â€” now defines standard data types, file formats and composition behaviors, giving developers predictable, interoperable USD pipelines as they scale autonomous systems. Powered by OpenUSD, NVIDIA Omniverse libraries combine NVIDIA RTX rendering, physics simulation and efficient runtimes to create digital twins and simulation-ready ( SimReady ) assets that accurately reflect real-world environments for synthetic data generation and testing. NVIDIA Cosmos world foundation models can run on top of these simulations to amplify data variation, generating new weather, lighting and terrain conditions from the same scenes so teams can safely cover rare and challenging edge cases. Learn more by watching the OpenUSD livestream today at 11 a.m. PT or in replay, part of the NVIDIA Omniverse OpenUSD Insiders series: In addition, advancements in synthetic data generation , multimodal datasets and SimReady workflows are now converging with the NVIDIA Halos framework for AV safety, creating a standards-based path to safer, faster, more cost-effective deployment of next-generation autonomous machines. Building the Foundation for Safe Physical AI Open Standards and SimReady Assets The OpenUSD Core Specification 1.0 establishes the standard data models and behaviors that underpin SimReady assets, enabling developers to build interoperable simulation pipelines for AI factories and robotics on OpenUSD . Built on this foundation, SimReady 3D assets can be reused across tools and teams and loaded directly into NVIDIA Isaac Sim , where USDPhysics colliders, rigid body dynamics and composition-arcâ€“based variants let teams test robots in virtual facilities that closely mirror real operations. Open-Source Learning The Learn OpenUSD curriculum is now open source and available on GitHub, enabling contributors to localize and adapt templates, exercises and content for different audiences, languages and use cases. This gives educators a ready-made foundation to onboard new teams into OpenUSD-centric simulation workflows.â€‹ Generative Worlds as Safety Multiplier Gaussian splatting â€” a technique that uses editable 3D elements to render environments quickly and with high fidelity â€” and world models are accelerating simulation pipelines for safe robotics testing and validation. At SIGGRAPH Asia, the NVIDIA Research team introduced Play4D , a streaming pipeline that enables 4D Gaussian splatting to accurately render dynamic scenes and improve realism. Spatial intelligence company World Labs is using its Marble generative world model with NVIDIA Isaac Sim and Omniverse NuRec so researchers can turn text prompts and sample images into photorealistic, Gaussian-based physics-ready 3D environments in hours instead of weeks. Those worlds can then be used for physical AI training, testing and sim-to-real transfer. This high-fidelity simulation workflow expands the range of scenarios robots can practice in while keeping experimentation safely in simulation. Lightwheel Helps Teams Scale Robot Training With SimReady Assets Powered by OpenUSD, Lightwheel â€™s SimReady asset library includes a common scene description layer, making it easy to assemble high-fidelity digital twins for robots. The SimReady assets are embedded with precise geometry, materials and validated physical properties, which can be loaded directly into NVIDIA Isaac Sim and Isaac Lab for robot training. This allows robots to experience realistic contacts, dynamics and sensor feedback as they learn. End-to-End Autonomous Vehicle Safety End-to-end autonomous vehicle safety advancements are accelerating with new research, open frameworks and inspection services that make validation more rigorous and scalable. NVIDIA researchers, with collaborators at Harvard University and Stanford University, recently introduced the Sim2Val framework to statistically combine real-world and simulated test results, reducing AV developersâ€™ need for costly physical mileage while demonstrating how robotaxis and AVs can behave safely across rare and safety-critical scenarios. Learn more by watching NVIDIAâ€™s â€œSafety in the Loopâ€ livestream: These innovations are complemented by a new, open-source NVIDIA Omniverse NuRec Fixer, a Cosmos-based model trained on AV data that removes artifacts in neural reconstructions to produce higher-quality SimReady assets. To align these advances with rigorous global standards, the NVIDIA Halos AI Systems Inspection Lab â€” accredited by ANAB â€” provides impartial inspection and certification of Halos elements across robotaxi fleets, AV stacks, sensors and manufacturer platforms through the Halos Certification Program . AV Ecosystem Leaders Putting Physical AI Safety to Work Bosch , Nuro and Wayve are among the first participants in the NVIDIA Halos AI Systems Inspection Lab, which aims to accelerate the safe, large-scale deployment of robotaxi fleets. Onsemi, which makes sensor systems for AVs, industrial automation and medical applications, has recently become the first company to pass inspection for the NVIDIA Halos AI Systems Inspection Lab. The open-source CARLA simulator integrates NVIDIA NuRec and Cosmos Transfer to generate reconstructed drives and diverse scenario variations, while Voxel51 â€™s FiftyOne engine, linked to Cosmos Dataset Search, NuRec and Cosmos Transfer, helps teams curate, annotate and evaluate multimodal datasets across the AV pipeline.â€‹ Mcity at the University of Michigan is enhancing the digital twin of its 32-acre AV test facility using Omniverse libraries and technologies. The team is integrating the NVIDIA Blueprint for AV simulation and Omniverse Sensor RTX application programming interfaces to create physics-based models of camera, lidar, radar and ultrasonic sensors. By aligning real sensor recordings with high-fidelity simulated data and sharing assets openly, Mcity enables safe, repeatable testing of rare and hazardous driving scenarios before vehicles operate on public roads. Get Plugged Into the World of OpenUSD and Physical AI Safety Learn more about OpenUSD, NVIDIA Halos and physical AI safety by exploring these resources: Watch the on-demand NVIDIA GTC session, â€œ Reconstructing Reality: Simulating Indoor and Outdoor Environments for Physical AI .â€ Visit the NVIDIA Halos AI Systems Inspection Lab webpage. Follow the NVIDIA DRIVE LinkedIn newsletter: â€œ NVIDIA Safety in the Loop .â€ Read the corporate blog explainer: How AI Is Unlocking Level 4 Autonomy . Get started with the Learn OpenUSD curriculum , now open source. Stay up to date by subscribing to NVIDIA news , joining the community and following NVIDIA Omniverse on Instagram , LinkedIn , Medium and X . Categories: Driving | Pro Graphics | Robotics Tags: Cosmos | Into the Omniverse | NVIDIA Blueprints | NVIDIA Isaac Sim | NVIDIA Omniverse | Physical AI | Synthetic Data Generation]]></description>
      <author>NVIDIA</author>
      <pubDate>Wed, 17 Dec 2025 17:00:49 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/openusd-halos-safety-robotaxi-physical-ai/</guid>
    </item>
    <item>
      <title>UC San Diego Lab Advances Generative AI Research With NVIDIA DGX B200 System</title>
      <link>https://blogs.nvidia.com/blog/ucsd-generative-ai-research-dgx-b200/</link>
      <description><![CDATA[The Hao AI Lab research team at the University of California San Diego â€” at the forefront of pioneering AI model innovation â€” recently received an NVIDIA DGX B200 system to elevate their critical work in large language model inference . Many LLM inference platforms in production today, such as NVIDIA Dynamo , use research concepts that originated in the Hao AI Lab, including DistServe . How Is Hao AI Lab Using the DGX B200? Members of the Hao AI Lab standing with the NVIDIA DGX B200 system. With the DGX B200 now fully accessible to the Hao AI Lab and broader UC San Diego community at the School of Computing, Information and Data Sciencesâ€™ San Diego Supercomputer Center , the research opportunities are boundless. â€œDGX B200 is one of the most powerful AI systems from NVIDIA to date, which means that its performance is among the best in the world,â€ said Hao Zhang, assistant professor in the HalÄ±cÄ±oÄŸlu Data Science Institute and department of computer science and engineering at UC San Diego. â€œIt enables us to prototype and experiment much faster than using previous-generation hardware.â€ Two Hao AI Lab projects the DGX B200 is accelerating are FastVideo and the Lmgame benchmark. FastVideo focuses on training a family of video generation models to produce a five-second video based on a given text prompt â€” in just five seconds. The research phase of FastVideo taps into NVIDIA H200 GPUs in addition to the DGX B200 system. Lmgame-bench is a benchmarking suite that puts LLMs to the test using popular online games including Tetris and Super Mario Bros . Users can test one model at a time or put two models up against each other to measure their performance. The illustrated workflow of Hao AI Labâ€™s Lmgame-Bench project. Other ongoing projects at Hao AI Labs explore new ways to achieve low-latency LLM serving, pushing large language models toward real-time responsiveness. â€œOur current research uses the DGX B200 to explore the next frontier of low-latency LLM-serving on the awesome hardware specs the system gives us,â€ said Junda Chen, a doctoral candidate in computer science at UC San Diego. How DistServe Influenced Disaggregated Serving Disaggregated inference is a way to ensure large-scale LLM-serving engines can achieve the optimal aggregate system throughput while maintaining acceptably low latency for user requests. The benefit of disaggregated inference lies in optimizing what DistServe calls â€œgoodputâ€ instead of â€œthroughputâ€ in the LLM-serving engine. Hereâ€™s the difference: Throughput is measured by the number of tokens per second that the entire system can generate. Higher throughput means lower cost to generate each token to serve the user. For a long time, throughput was the only metric used by LLM-serving engines to measure their performance against one another. While throughput measures the aggregate performance of the system, it doesnâ€™t directly correlate to the latency that a user perceives. If a user demands lower latency to generate the tokens, the system has to sacrifice throughput. This natural trade-off between throughput and latency is what led the DistServe team to propose a new metric, â€œgoodputâ€: the measure of throughput while satisfying the user-specified latency objectives, usually called service-level objectives. In other words, goodput represents the overall health of a system while satisfying user experience. DistServe shows that goodput is a much better metric for LLM-serving systems, as it factors in both cost and service quality. Goodput leads to optimal efficiency and ideal output from a model. How Can Developers Achieve Optimal Goodput? When a user makes a request in an LLM system, the system takes the user input and generates the first token, known as prefill. Then, the system creates numerous output tokens, one after another, predicting each tokenâ€™s future behavior based on past requestsâ€™ outcomes. This process is known as decode. https://blogs.nvidia.com/wp-content/uploads/2025/12/distserve.mp4 Prefill and decode have historically run on the same GPU, but the researchers behind DistServe found that splitting them onto different GPUs maximizes goodput. â€œPreviously, if you put these two jobs on a GPU, they would compete with each other for resources, which could make it slow from a user perspective,â€ Chen said. â€œNow, if I split the jobs onto two different sets of GPUs â€” one doing prefill, which is compute intensive, and the other doing decode, which is more memory intensive â€” we can fundamentally eliminate the interference between the two jobs, making both jobs run faster. This process is called prefill/decode disaggregation, or separating the prefill from decode to get greater goodput. Increasing goodput and using the disaggregated inference method enables the continuous scaling of workloads without compromising on low-latency or high-quality model responses. NVIDIA Dynamo â€” an open-source framework designed to accelerate and scale generative AI models at the highest efficiency levels with the lowest cost â€” enables scaling disaggregated inference. In addition to these projects, cross-departmental collaborations, such as in healthcare and biology, are underway at UC San Diego to further optimize an array of research projects using the NVIDIA DGX B200, as researchers continue exploring how AI platforms can accelerate innovation. Learn more about the NVIDIA DGX B200 system. Categories: Data Center | Generative AI | Research | Supercomputing Tags: Artificial Intelligence | Education | Inference | NVIDIA DGX | Open Source]]></description>
      <author>NVIDIA</author>
      <pubDate>Wed, 17 Dec 2025 16:00:15 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/ucsd-generative-ai-research-dgx-b200/</guid>
    </item>
    <item>
      <title>NVIDIA Acquires Open-Source Workload Management Provider SchedMD</title>
      <link>https://blogs.nvidia.com/blog/nvidia-acquires-schedmd/</link>
      <description><![CDATA[NVIDIA today announced it has acquired SchedMD â€” the leading developer of Slurm, an open-source workload management system for high-performance computing (HPC) and AI â€” to help strengthen the open-source software ecosystem and drive AI innovation for researchers, developers and enterprises. NVIDIA will continue to develop and distribute Slurm as open-source, vendor-neutral software, making it widely available to and supported by the broader HPC and AI community across diverse hardware and software environments. HPC and AI workloads involve complex computations running parallel tasks on clusters that require queuing, scheduling and allocating computational resources. As HPC and AI clusters get larger and more powerful, efficient resource utilization is critical. As the leading workload manager and job scheduler in scalability, throughput and complex policy management, Slurm is used in more than half of the top 10 and top 100 systems in the TOP500 list of supercomputers. Slurm, which is supported on the latest NVIDIA hardware, is also part of the critical infrastructure needed for generative AI, used by foundation model developers and AI builders to manage model training and inference needs. â€œWeâ€™re thrilled to join forces with NVIDIA, as this acquisition is the ultimate validation of Slurmâ€™s critical role in the worldâ€™s most demanding HPC and AI environments,â€ said Danny Auble, CEO of SchedMD. â€œNVIDIAâ€™s deep expertise and investment in accelerated computing will enhance the development of Slurm â€” which will continue to be open source â€” to meet the demands of the next generation of AI and supercomputing.â€ NVIDIA has been collaborating with SchedMD for over a decade and will continue investing in Slurmâ€™s development to ensure it remains the leading open-source scheduler for HPC and AI. NVIDIA will accelerate SchedMDâ€™s access to new systems â€” allowing users of NVIDIAâ€™s accelerated computing platform to optimize workloads across their entire compute infrastructure â€” while also supporting a diverse hardware and software ecosystem, so customers can run heterogeneous clusters with the latest Slurm innovations. NVIDIA will continue to offer open-source software support, training and development for Slurm to SchedMDâ€™s hundreds of customers, which include cloud providers, manufacturers, AI companies and research labs spanning industries such as autonomous driving, healthcare and life sciences, energy, financial services, manufacturing and government. Together with SchedMD, NVIDIA is bolstering the open-source software ecosystem to catalyze HPC and AI innovation across industries, at every scale. Categories: Corporate | Data Center | Software Tags: Artificial Intelligence | Open Source | Parallel Computing | Supercomputing]]></description>
      <author>NVIDIA</author>
      <pubDate>Mon, 15 Dec 2025 16:30:11 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/nvidia-acquires-schedmd/</guid>
    </item>
    <item>
      <title>How to Fine-Tune an LLM on NVIDIA GPUs With Unsloth</title>
      <link>https://blogs.nvidia.com/blog/rtx-ai-garage-fine-tuning-unsloth-dgx-spark/</link>
      <description><![CDATA[Modern workflows showcase the endless possibilities of generative and agentic AI on PCs. Of many, some examples include tuning a chatbot to handle product-support questions or building a personal assistant for managing oneâ€™s schedule. A challenge remains, however, in getting a small language model to respond consistently with high accuracy for specialized agentic tasks. Thatâ€™s where fine-tuning comes in. Unsloth , one of the worldâ€™s most widely used open-source frameworks for fine-tuning LLMs, provides an approachable way to customize models. Itâ€™s optimized for efficient, low-memory training on NVIDIA GPUs â€” from GeForce RTX desktops and laptops to RTX PRO workstations and DGX Spark , the worldâ€™s smallest AI supercomputer. Another powerful starting point for fine-tuning is the just-announced NVIDIA Nemotron 3 family of open models, data and libraries. Nemotron 3 introduces the most efficient family of open models, ideal for agentic AI fine-tuning. Teaching AI New Tricks Fine-tuning is like giving an AI model a focused training session. With examples tied to a specific topic or workflow, the model improves its accuracy by learning new patterns and adapting to the task at hand. Choosing a fine-tuning method for a model depends on how much of the original model the developer wants to adjust. Based on their goals, developers can use one of three main fine-tuning methods: Parameter-efficient fine-tuning (such as LoRA or QLoRA) : How it works: Updates only a small portion of the model for faster, lower-cost training. Itâ€™s a smarter and efficient way to enhance a model without altering it drastically. Target use case: Useful across nearly all scenarios where full fine-tuning would traditionally be applied â€” including adding domain knowledge, improving coding accuracy, adapting the model for legal or scientific tasks, refining reasoning, or aligning tone and behavior. Requirements: Small- to medium-sized dataset (100-1,000 prompt-sample pairs). Full fine-tuning : How it works: Updates all of the modelâ€™s parameters â€” useful for teaching the model to follow specific formats or styles. Target use case: Advanced use cases, such as building AI agents and chatbots that must provide assistance about a specific topic, stay within a certain set of guardrails and respond in a particular manner. Requirements: Large dataset (1,000+ prompt-sample pairs). Reinforcement learning : How it works: Adjusts the behavior of the model using feedback or preference signals. The model learns by interacting with its environment and uses the feedback to improve itself over time. This is a complex, advanced technique that interweaves training and inference â€” and can be used in tandem with parameter-efficient fine-tuning and full fine-tuning techniques. See Unslothâ€™s Reinforcement Learning Guide for details. Target use case: Improving the accuracy of a model in a particular domain â€” such as law or medicine â€” or building autonomous agents that can orchestrate actions on a userâ€™s behalf. Requirements: A process that contains an action model, a reward model and an environment for the model to learn from. Another factor to consider is the VRAM required per each method. The chart below provides an overview of the requirements to run each type of fine-tuning method on Unsloth. Fine-tuning requirements on Unsloth. Unsloth: A Fast Path to Fine-Tuning on NVIDIA GPUs LLM fine-tuning is a memory- and compute-intensive workload that involves billions of matrix multiplications to update model weights at every training step. This type of heavy parallel workload requires the power of NVIDIA GPUs to complete the process quickly and efficiently. Unsloth shines at this workload, translating complex mathematical operations into efficient, custom GPU kernels to accelerate AI training. Unsloth helps boost the performance of the Hugging Face transformers library by 2.5x on NVIDIA GPUs. These GPU-specific optimizations, combined with Unslothâ€™s ease of use, make fine-tuning accessible to a broader community of AI enthusiasts and developers. The framework is built and optimized for NVIDIA hardware â€” from GeForce RTX laptops to RTX PRO workstations and DGX Spark â€” providing peak performance while reducing VRAM consumption. Unsloth provides helpful guides on how to get started and manage different LLM configurations, hyperparameters and options, along with example notebooks and step-by-step workflows. Check out some of these Unsloth guides: Fine-Tuning LLMs With NVIDIA RTX 50 Series GPUs and Unsloth Fine-Tuning LLMs With NVIDIA DGX Spark and Unsloth Learn how to install Unsloth on NVIDIA DGX Spark . Read the NVIDIA technical blog for a deep dive of fine-tuning and reinforcement learning on the NVIDIA Blackwell platform. For a hands-on local fine-tuning walkthrough, watch Matthew Berman showing reinforcement learning running on a NVIDIA GeForce RTX 5090 using Unsloth in the video below. Available Now: NVIDIA Nemotron 3 Family of Open Models The new Nemotron 3 family of open models â€” in Nano, Super, and Ultra sizes â€” built on a new hybrid latent Mixture-of-Experts (MoE) architecture, introduces the most efficient family of open models with leading accuracy, ideal for building agentic AI applications. Nemotron 3 Nano 30B-A3B, available now, is the most compute-efficient model in the lineup. Itâ€™s optimized for tasks such as software debugging, content summarization, AI assistant workflows and information retrieval at low inference costs. Its hybrid MoE design delivers: Up to 60% fewer reasoning tokens, significantly reducing inference cost. A 1 million-token context window, allowing the model to retain far more information for long, multistep tasks. Nemotron 3 Super is a high-accuracy reasoning model for multi-agent applications, while Nemotron 3 Ultra is for complex AI applications. Both are expected to be available in the first half of 2026. NVIDIA also released today an open collection of training datasets and state-of-the-art reinforcement learning libraries. Nemotron 3 Nano fine-tuning is available on Unsloth. Download Nemotron 3 Nano now from Hugging Face , or experiment with it through Llama.cpp and LM Studio. DGX Spark: A Compact AI Powerhouse DGX Spark enables local fine-tuning and brings incredible AI performance in a compact, desktop supercomputer, giving developers access to more memory than a typical PC. Built on the NVIDIA Grace Blackwell architecture, DGX Spark delivers up to a petaflop of FP4 AI performance and includes 128GB of unified CPU-GPU memory, giving developers enough headroom to run larger models, longer context windows and more demanding training workloads locally. For fine-tuning, DGX Spark enables: Larger model sizes. Models with more than 30 billion parameters often exceed the VRAM capacity of consumer GPUs but fit comfortably within DGX Sparkâ€™s unified memory. More advanced techniques. Full fine-tuning and reinforcement-learning-based workflows â€” which demand more memory and higher throughput â€” run significantly faster on DGX Spark. Local control without cloud queues. Developers can run compute-heavy tasks locally instead of waiting for cloud instances or managing multiple environments. DGX Sparkâ€™s strengths go beyond LLMs. High-resolution diffusion models, for example, often require more memory than a typical desktop can provide. With FP4 support and large unified memory, DGX Spark can generate 1,000 images in just a few seconds and sustain higher throughput for creative or multimodal pipelines. The table below shows performance for fine-tuning the Llama family of models on DGX Spark. Performance for fine-tuning Llama family of models on DGX Spark. As fine-tuning workflows advance, the new Nemotron 3 family of open models offer scalable reasoning and long-context performance optimized for RTX systems and DGX Spark. Learn more about how DGX Spark enables intensive AI tasks . #ICYMI â€” The Latest Advancements in NVIDIA RTX AI PCs ðŸš€ FLUX.2 Image-Generation Models Now Released, Optimized for NVIDIA RTX GPUs The new models from Black Forest Labs are available in FP8 quantizations that reduce VRAM and increase performance by 40%. âœ¨ Nexa.ai Expands Local AI on RTX PCs With Hyperlink for Agentic Search The new on-device search agent delivers 3x faster retrieval-augmented generation indexing and 2x faster LLM inference, indexing a dense 1GB folder from about 15 minutes to just four to five minutes. Plus, DeepSeek OCR now runs locally in GGUF via NexaSDK, offering plug-and-play parsing of charts, formulas and multilingual PDFs on RTX GPUs. ðŸ¤Mistral AI Unveils New Model Family Optimized for NVIDIA GPUs The new Mistral 3 models are optimized from cloud to edge and available for fast, local experimentation through Ollama and Llama.cpp. ðŸŽ¨Blender 5.0 Lands With HDR Color and Major Performance Gains The release adds ACES 2.0 wide-gamut/HDR color, NVIDIA DLSS for up to 5x faster hair and fur rendering, better handling of massive geometry, and motion blur for Grease Pencil. Plug in to NVIDIA AI PC on Facebook , Instagram , TikTok and X â€” and stay informed by subscribing to the RTX AI PC newsletter . Follow NVIDIA Workstation on LinkedIn and X . See notice regarding software product information. Categories: Generative AI Tags: Artificial Intelligence | GeForce | NVIDIA RTX | RTX AI Garage]]></description>
      <author>NVIDIA</author>
      <pubDate>Mon, 15 Dec 2025 14:00:11 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/rtx-ai-garage-fine-tuning-unsloth-dgx-spark/</guid>
    </item>
    <item>
      <title>Cheers to AI: ADAM Robot Bartender Makes Drinks at Vegas Golden Knights Game</title>
      <link>https://blogs.nvidia.com/blog/adam-robot-vegas-golden-knights-thor/</link>
      <description><![CDATA[In Las Vegasâ€™s T-Mobile Arena, fans of the Golden Knights are getting more than just hockey â€” theyâ€™re getting a taste of the future. ADAM, a robot developed with NVIDIA Isaac libraries , is pouring drinks and turning heads in one of the NHLâ€™s most exciting venues. ADAM, short for Automated Dual Arm Mixologist, was developed by Las-Vegas based Richtech Robotics. Itâ€™s not just a novelty â€” itâ€™s a solution to real-world challenges in hospitality: labor shortages and demands for unique customer experiences. â€œThe hospitality industry faces significant labor challenges, and ADAM is our answer to meeting those needs while elevating the customer experience,â€ said Matt Casella, president of Richtech Robotics. â€œWith NVIDIAâ€™s Isaac platform, weâ€™ve developed a solution thatâ€™s scalable, consistent, and frankly, creates memorable moments for fans. The response at T-Mobile Arena has been phenomenalâ€”people love interacting with ADAM.â€ Learning to Serve Drinks in Simulation Before ADAM ever poured a drink, it trained in a virtual bar. Richtech used NVIDIA Isaac Sim , an open-source, reference robotic simulation framework built on NVIDIA Omniverse , to build a high-fidelity and physically accurate simulation of ADAMâ€™s workstation, complete with cups, utensils and lighting variations. The team generated synthetic data to teach ADAM how to recognize objects even in tricky conditions like glare or reflection. ADAMâ€™s skills such as pouring and shaking were refined in simulation using Isaac Lab , NVIDIAâ€™s open source robot learning framework. The result: a robot that doesnâ€™t just follow instructions â€” it adapts to its environment with precision. Running Real-Time AI at the Edge With Jetson ADAM runs on NVIDIA Jetson AGX Orin , the powerful edge AI platform capable of 275 TOPS of compute. Using Isaac ROS 2 libraries, ADAM captures camera feeds, detects objects and calibrates the workspace in real time. ADAMâ€™s perception stack â€” built with TAO Toolkit and optimized with TensorRT â€” enables it to identify cups, measure liquid levels and adjust movements with less than 40 milliseconds of latency. That means ADAM can spot a misplaced cup, detect when foam reaches the rim and correct a pour â€” all without missing a beat. Creating Industrial Dexterity With NVIDIA Thor While ADAM is busy serving drinks at Golden Knights games, Richtech Robotics is also making major strides in industrial automation with Dex, a new mobile humanoid robot built for factory and warehouse environments. Recently unveiled at GTC DC , Dex combines the mobility of an autonomous wheeled platform with the precision of dual-arm dexterity. Itâ€™s designed to handle such light-to-medium industrial tasks as machine operation, parts sorting, material handling and packaging â€” all with the flexibility to take on different tools and workflows. Dex runs on NVIDIA Jetson Thor , a next-generation robotics processor that gives it the ability to deliver real-time sensor processing and AI reason in dynamic industrial settings. Dex was trained from a blend of real world and synthetic data generated from Isaac Sim. This allowed Dexâ€™s model to be generalized across a multitude of scenarios. Learn more about Jetson Thor and about festive Jetson platform holiday prices . Categories: Corporate | Robotics Tags: NVIDIA Isaac Sim | NVIDIA Jetson | NVIDIA Omniverse | TensorRT]]></description>
      <author>NVIDIA</author>
      <pubDate>Fri, 12 Dec 2025 16:00:04 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/adam-robot-vegas-golden-knights-thor/</guid>
    </item>
    <item>
      <title>As AI Grows More Complex, Model Builders Rely on NVIDIA</title>
      <link>https://blogs.nvidia.com/blog/leading-models-nvidia/</link>
      <description><![CDATA[Unveiling what it describes as the most capable model series yet for professional knowledge work, OpenAI launched GPT-5.2 today. The model was trained and deployed on NVIDIA infrastructure, including NVIDIA Hopper and GB200 NVL72 systems. Itâ€™s the latest example of how leading AI builders train and deploy at scale on NVIDIAâ€™s full-stack AI infrastructure. Pretraining: The Bedrock of Intelligence AI models are getting more capable thanks to three scaling laws : pretraining, post-training and test-time scaling. Reasoning models , which apply compute during inference to tackle complex queries, using multiple networks working together, are now everywhere. But pretraining and post-training remain the bedrock of intelligence. Theyâ€™re core to making reasoning models smarter and more useful. And getting there takes scale. Training frontier models from scratch isnâ€™t a small job. It takes tens of thousands, even hundreds of thousands, of GPUs working together effectively. That level of scale demands excellence across many dimensions. It requires world-class accelerators, advanced networking across scale-up, scale-out and increasingly scale-across architectures, plus a fully optimized software stack. In short, a purpose-built infrastructure platform built to deliver performance at scale. Compared with the NVIDIA Hopper architecture, NVIDIA GB200 NVL72 systems delivered 3x faster training performance on the largest model tested in the latest MLPerf Training industry benchmarks, and nearly 2x better performance per dollar . And NVIDIA GB300 NVL72 delivers a more than 4x speedup compared with NVIDIA Hopper. These performance gains help AI developers shorten development cycles and deploy new models more quickly. Proof in the Models Across Every Modality The majority of todayâ€™s leading large language models were trained on NVIDIA platforms. AI isnâ€™t just about text. NVIDIA supports AI development across multiple modalities, including speech, image and video generation, as well as emerging areas like biology and robotics. For example, models like Evo 2 decode genetic sequences, OpenFold3 predicts 3D protein structures and Boltz-2 simulates drug interactions, helping researchers identify promising candidates faster. On the clinical side, NVIDIA Clara synthesis models generate realistic medical images to advance screening and diagnosis without exposing patient data. Companies like Runway and Inworld train on NVIDIA infrastructure. Runway last week announced Gen-4.5, a new frontier video generation model thatâ€™s the current top-rated video model in the world, according to the Artificial Analysis leaderboard. Now optimized for NVIDIA Blackwell, Gen-4.5 was developed entirely on NVIDIA GPUs across initial research and development, pre-training, post-training and inference. Runway also announced GWM-1, a state-of-the-art general world model trained on NVIDIA Blackwell thatâ€™s built to simulate reality in real time. Itâ€™s interactive, controllable and general-purpose, with applications in video games, education, science, entertainment and robotics. Benchmarks show why. MLPerf is the industry-standard benchmark for training performance. In the latest round, NVIDIA submitted results across all seven MLPerf Training 5.1 benchmarks , showing strong performance and versatility. It was the only platform to submit in every category. NVIDIAâ€™s ability to support diverse AI workloads helps data centers use resources more efficiently. Thatâ€™s why AI labs such as Black Forest Labs, Cohere, Mistral, OpenAI, Reflection and Thinking Machines Lab and are all training on the NVIDIA Blackwell platform. NVIDIA Blackwell Across Clouds and Data Centers NVIDIA Blackwell is widely available from leading cloud service providers, neo-clouds and server makers. And NVIDIA Blackwell Ultra, offering additional compute, memory and architecture improvements, is now rolling out from server makers and cloud service providers. Major cloud service providers and NVIDIA Cloud Partners , including Amazon Web Services, CoreWeave, Google Cloud, Lambda, Microsoft Azure, Nebius, Oracle Cloud Infrastructure and Together AI, to name a few, already offer instances powered by NVIDIA Blackwell, ensuring scalable performance as pretraining scaling continues. From frontier models to everyday AI, the future is being built on NVIDIA. Learn more about the NVIDIA Blackwell platform . Categories: Cloud | Corporate | Deep Learning]]></description>
      <author>NVIDIA</author>
      <pubDate>Thu, 11 Dec 2025 19:19:57 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/leading-models-nvidia/</guid>
    </item>
    <item>
      <title>Ride Into Adventure With Capcomâ€™s â€˜Monster Hunter Storiesâ€™ Series in the Cloud</title>
      <link>https://blogs.nvidia.com/blog/geforce-now-thursday-monster-hunter-stories/</link>
      <description><![CDATA[Hunters, saddle up â€” adventure awaits in the cloud. Journey into the world of Monster Hunter Stories as Capcomâ€™s acclaimed role-playing classics join GeForce NOW . Monster Hunter Stories and Monster Hunter Stories 2: Wings of Ruin are soaring into the cloud this week, bringing colorful worlds, charming companions and turn-based monster battles across devices. They lead seven new games joining the cloud this week, on top of an ARC Raiders â€œElectrician Backpack: Emerald Wave Variantâ€ reward for Ultimate members who want to drop into battle in style. Itâ€™s also been a big year for games, and this yearâ€™s major gaming awards nominees show just how strong gaming is right now â€” with many of those fan-favorite titles playable on GeForce NOW, no downloads required. Look for the â€œThe Game Awardsâ€ row in the GeForce NOW app to dive in instantly. Saddle Up Capcomâ€™s Monster Hunter Stories and Monster Hunter Stories 2: Wings of Ruin arrive in the cloud this week. Members can explore vibrant worlds, bond with quirky monsters and experience turn-based role-playing game (RPG) adventures across devices. Saddle up for egg-citement. In Monster Hunter Stories, an RPG that expands the Monster Hunter world, players are no longer hunting monsters but raising them. In this story featuring heroes known as Monster Riders, players live alongside monsters and form lifelong bonds with them. The first installment of the Monster Hunter Stories series returns, fully voiced in Japanese and English, with additional features such as a new museum mode where players can listen to music and view concept art â€” offering an even deeper dive into the world of Monster Hunter Stories. When fate calls, answer on a dragonâ€™s back. A new adventure awaits in Monster Hunter Stories 2: Wings of Ruin: the second installment of the turn-based RPG series. Become a Monster Rider and form bonds with friendly monsters known as Monsties to fight alongside them in the gameâ€™s epic story. These adventures can be enjoyed on almost any device, powered by high-performance GeForce RTX technology. Seamlessly switch between phones, laptops and desktops, and experience every lush landscape and thrilling battle with cloud-streamed visuals and smooth gameplay â€” no downloads, installs or upgrades required. And the Cloud Goes to â€¦ GeForce NOW Itâ€™s a big month for games, and this yearâ€™s major gaming awards make it an especially great time to be a gamer. Many of the buzziest nominees and fan-favorite titles are playable on GeForce NOW, where itâ€™s easy to jump into the action, catch up on the hits and see what the hypeâ€™s all about â€” all instantly, no downloads required. What a game. A stack of nominated titles are available in the cloud through GeForce NOW, including a majority of Game of the Year (GOTY) contenders like Clair Obscur: Expedition 33 , Hollow Knight: Silksong and Kingdom Come: Deliverance II . RPG fans can marathon some of the yearâ€™s best titles in the genre through the cloud. Avowed, Clair Obscur: Expedition 33, Kingdom Come: Deliverance II, Monster Hunter Wilds and The Outer Worlds 2 are all streamable on GeForce NOW.â€‹ A masterpiece. Members can also dive into other nominated favorites such as Battlefield 6 and DOOM: The Dark Ages for Best Action, Indiana Jones and the Ancient Circle and Split Fiction for Best Adventure, The Alters and Sid Meierâ€™s Civilization VII for Best Sim/Strategy, ARC Raiders and PEAK for Best Multiplayer, plus esports staples like Counter-Strike 2 and DOTA 2 . Whether chasing GOTY, exploring indies like Blue Prince and Hollow Knight: Silksong , or sticking to long-running hits like Fortnite and No Manâ€™s Sky , gamers can always find a top title ready to stream. Loot, Shoot and Look Good Doing It Pack up and stand out. Ultimate members can claim the ARC Raiders â€œElectrician Backpack: Emerald Wave Variantâ€ â€” an in-game cosmetic item that adds a distinct look. The Emerald Wave design offers a clean, modern touch for Raiders ready to stand out during extraction missions.â€‹â€‹ Jump into battle with style, powered by GeForce RTX 5080-class servers on GeForce NOW, delivering up to 2.8x higher frame rates and a new Cinematic-Quality Streaming mode that makes every firefight shine. The reward is available to Ultimate members through Sunday, Jan. 4, 2026, or while supplies last. Keep an eye on email for instructions to redeem this stylish advantage for the journey ahead. Once claimed, navigate to the Electrician Backpack and select the Emerald Wave color variant to equip it and head off in style. Fresh Crop of Games Where the cows know your name. Everdream Village , a cozy farming adventure from publisher Untold Tales, lets players turn a sleepy island settlement into a thriving, story-filled village. Tend crops, befriend quirky villagers and wrangle a menagerie of charming animals while terraforming the land and sail off to discover new magical islands â€” all while shaping a laid-back little paradise. In addition, members can look for the following: Skate Story (New release on Steam , Dec. 8) Dome Keeper (New release on Xbox , available on Game Pass, Dec. 9) Death Howl (New release on Steam and Xbox , available on Game Pass, Dec. 9) RuneQuest: Warlords (New release on Steam , Dec. 9) Everdream Village (New release on Steam , Dec. 12) Monster Hunter Stories ( Steam ) Monster Hunter Stories 2 ( Steam ) GeForce RTX 5080-ready games: Age of Wonders 4 ( Steam , Epic Games Store and Xbox , available on the Microsoft store) Cities: Skylines ( Steam and Epic Games Store ) Cities: Skylines II ( Steam and Xbox , available on Game Pass) What are you planning to play this weekend? Let us know on X or in the comments below. What's on the top of your gaming wishlist this holiday? âœï¸â„ï¸ â€” ðŸŒ©ï¸ NVIDIA GeForce NOW (@NVIDIAGFN) December 10, 2025 Categories: Gaming Tags: Cloud Gaming | GeForce NOW]]></description>
      <author>NVIDIA</author>
      <pubDate>Thu, 11 Dec 2025 14:00:09 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/geforce-now-thursday-monster-hunter-stories/</guid>
    </item>
    <item>
      <title>NVIDIA Awards up to $60,000 Research Fellowships to PhD Students</title>
      <link>https://blogs.nvidia.com/blog/graduate-fellowship-recipients-2026-2027/</link>
      <description><![CDATA[For 25 years, the NVIDIA Graduate Fellowship Program has supported graduate students doing outstanding work relevant to NVIDIA technologies. Today, the program announced the latest awards of up to $60,000 each to 10 Ph.D. students involved in research that spans all areas of computing innovation. Selected from a highly competitive applicant pool, the awardees will participate in a summer internship preceding the fellowship year. Their work puts them at the forefront of accelerated computing â€” tackling projects in autonomous systems, computer architecture, computer graphics, deep learning, programming systems, robotics and security. The NVIDIA Graduate Fellowship Program is open to applicants worldwide. The 2026-2027 fellowship recipients are: Jiageng Mao , University of Southern California â€” Solving complex physical AI problems by using diverse priors from internet-scale data to enable robust, generalizable intelligence for embodied agents in the real world. Liwen Wu , University of California San Diego â€” Enriching realism and efficiency in physically based rendering with neural materials and neural rendering. Manya Bansal , Massachusetts Institute of Technology â€” Designing programming languages for modern accelerators that enable developers to write modular, reusable code without sacrificing the low-level control required for peak performance. Sizhe Chen , University of California, Berkeley â€” Securing AI in real-world applications, currently securing AI agents against prompt injection attacks with general and practical defenses that preserve the agentâ€™s utility. Yunfan Jiang , Stanford University â€” Developing scalable approaches to build generalist robots for everyday tasks through hybrid data sources spanning real-world whole-body manipulation, large-scale simulation and internet-scale multimodal supervision. Yijia Shao , Stanford University â€” Researching human-agent collaboration by developing AI agents that can communicate and coordinate with humans during task execution, and designing new human-agent interaction interfaces. Shangbin Feng , University of Washington â€” Advancing model collaboration: multiple machine learning models, trained on different data and by different people, collaborate, compose and complement each other for an open, decentralized and collaborative AI future. Shvetank Prakash , Harvard University â€” Advancing hardware architecture and systems design with AI agents built on new algorithms, curated datasets and agent-first infrastructure. Irene Wang , Georgia Institute of Technology â€” Developing a holistic codesign framework that integrates accelerator architecture, network topology and runtime scheduling to enable energy-efficient and sustainable AI training at scale. Chen Geng , Stanford University â€” Modeling 4D physical worlds with scalable data-driven algorithms and physics-inspired principles, advancing physically grounded 3D and 4D world models for robotics and scientific applications. We also acknowledge the 2026-2027 fellowship finalists: Zizheng Guo , Peking University Peter Holderrieth , Massachusetts Institute of Technology Xianghui Xie , Max Planck Institute for Informatics Alexander Root , Stanford University Daniel Palenicek , Technical University of Darmstadt Categories: Generative AI | Research Tags: Artificial Intelligence | Education]]></description>
      <author>NVIDIA</author>
      <pubDate>Thu, 04 Dec 2025 17:00:44 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/graduate-fellowship-recipients-2026-2027/</guid>
    </item>
    <item>
      <title>NVIDIA and AWS Expand Full-Stack Partnership, Providing the Secure, High-Performance Compute Platform Vital for Future Innovation</title>
      <link>https://blogs.nvidia.com/blog/aws-partnership-expansion-reinvent/</link>
      <description><![CDATA[At AWS re:Invent, NVIDIA and Amazon Web Services expanded their strategic collaboration with new technology integrations across interconnect technology, cloud infrastructure, open models and physical AI. As part of this expansion, AWS will support NVIDIA NVLink Fusion â€” a platform for custom AI infrastructure â€” for deploying its custom-designed silicon, including next-generation Trainium4 chips for inference and agentic AI model training, Graviton CPUs for a broad range of workloads and the Nitro System virtualization infrastructure. Using NVIDIA NVLink Fusion, AWS will combine NVIDIA NVLink scale-up interconnect and the NVIDIA MGX rack architecture with AWS custom silicon to increase performance and accelerate time to market for its next-generation cloud-scale AI capabilities. AWS is designing Trainium4 to integrate with NVLink and NVIDIA MGX, the first of a multigenerational collaboration between NVIDIA and AWS for NVLink Fusion. AWS has already deployed MGX racks at scale with NVIDIA GPUs. Integrating NVLink Fusion will allow AWS to further simplify deployment and systems management across its platforms. AWS can also harness the NVLink Fusion supplier ecosystem, which provides all the components required for full rack-scale deployment, from the rack and chassis, to power-delivery and cooling systems. By supporting AWSâ€™s Elastic Fabric Adapter and Nitro System, the NVIDIA Vera Rubin architecture on AWS will give customers robust networking choices while maintaining full compatibility with AWSâ€™s cloud infrastructure and accelerating new AI service rollout. â€œGPU compute demand is skyrocketing â€” more compute makes smarter AI, smarter AI drives broader use and broader use creates demand for even more compute. The virtuous cycle of AI has arrived,â€ said Jensen Huang, founder and CEO of NVIDIA. â€œWith NVIDIA NVLink Fusion coming to AWS Trainium4, weâ€™re unifying our scale-up architecture with AWSâ€™s custom silicon to build a new generation of accelerated platforms. Together, NVIDIA and AWS are creating the compute fabric for the AI industrial revolution â€” bringing advanced AI to every company, in every country, and accelerating the worldâ€™s path to intelligence.â€ â€œAWS and NVIDIA have worked side by side for more than 15 years, and today marks a new milestone in that journey,â€ said Matt Garman, CEO of AWS. â€œWith NVIDIA, weâ€™re advancing our large-scale AI infrastructure to deliver customers the highest performance, efficiency and scalability. The upcoming support of NVIDIA NVLink Fusion in AWS Trainium4, Graviton and the Nitro System will bring new capabilities to customers so they can innovate faster than ever before.â€ Convergence of Scale and Sovereignty AWS has expanded its accelerated computing portfolio with the NVIDIA Blackwell architecture, including NVIDIA HGX B300 and NVIDIA GB300 NVL72 GPUs, giving customers immediate access to the industryâ€™s most advanced GPUs for training and inference. Availability of NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, designed for visual applications, on AWS is expected in the coming weeks. These GPUs form part of the AWS infrastructure backbone powering AWS AI Factories, a new AI cloud offering that will provide customers around the world with the dedicated infrastructure they need to harness advanced AI services and capabilities in their own data centers, operated by AWS, while also letting customers maintain control of their data and comply with local regulations. NVIDIA and AWS are committing to deploy sovereign AI clouds globally and bring the best of AI innovation to the world. With the launch of AWS AI Factories, the companies are providing secure, sovereign AI infrastructure to deliver unprecedented computing capabilities for organizations around the world while meeting increasingly rigorous sovereign AI requirements. For public sector organizations, AWS AI Factories will transform the federal supercomputing and AI landscape. AWS AI Factories customers will be able to seamlessly integrate AWSâ€™s industry-leading cloud infrastructure and services â€” known for its reliability, security and scalability â€” with NVIDIA Blackwell GPUs and the full-stack NVIDIA accelerated computing platform, including NVIDIA Spectrum-X Ethernet switches. The unified architecture will ensure customers can access advanced AI services and capabilities, as well as train and deploy massive models, while maintaining absolute control of proprietary data and full compliance with local regulatory frameworks. NVIDIA Nemotron Integration With Amazon Bedrock Expands Software Optimizations Beyond hardware, the partnership expands integration of NVIDIAâ€™s software stack with the AWS AI ecosystem. NVIDIA Nemotron open models are now integrated with Amazon Bedrock , enabling customers to build generative AI applications and agents at production scale. Developers can access Nemotron Nano 2 and Nemotron Nano 2 VL to build specialized agentic AI applications that process text, code, images and video with high efficiency and accuracy. The integration makes high-performance, open NVIDIA models instantly accessible via Amazon Bedrockâ€™s serverless platform where customers can rely on proven scalability and zero infrastructure management. Industry leaders CrowdStrike and BridgeWise are the first to use the service to deploy specialized AI agents. NVIDIA Software on AWS Simplifies Developer Experience NVIDIA and AWS are also co-engineering at the software layer to accelerate the data backbone of every enterprise. Amazon OpenSearch Service now offers serverless GPU acceleration for vector index building, powered by NVIDIA cuVS , an open-source library for GPU-accelerated vector search and data clustering. This milestone represents a fundamental shift to using GPUs for unstructured data processing, with early adopters seeing up to 10x faster vector indexing at a quarter of the cost. These dramatic gains reduce search latency, accelerate writes and unlock faster productivity for dynamic AI techniques like retrieval-augmented generation by delivering the right amount of GPU power precisely when itâ€™s needed. AWS is the first major cloud provider to offer serverless vector indexing with NVIDIA GPUs. Production-ready AI agents require performance visibility, optimization and scalable infrastructure. By combining Strands Agents for agent development and orchestration, the NVIDIA NeMo Agent Toolkit for deep profiling and performance tuning, and Amazon Bedrock AgentCore for secure, scalable agent infrastructure, organizations can empower developers with a complete, predictable path from prototype to production. This expanded support builds on AWSâ€™s existing integrations with NVIDIA technologies â€” including NVIDIA NIM microservices and frameworks like NVIDIA Riva and NVIDIA BioNeMo , as well as model development tools integrated with Amazon SageMaker and Amazon Bedrock â€” that enable organizations to deploy agentic AI, speech AI and scientific applications faster than ever. Accelerating Physical AI With AWS Developing physical AI demands high-quality and diverse datasets for training robot models, as well as frameworks for testing and validation in simulation before real-world deployment. NVIDIA Cosmos world foundation models (WFMs) are now available as NVIDIA NIM microservices on Amazon EKS , enabling real-time robotics control and simulation workloads with seamless reliability and cloud-native efficiency. For batch-based tasks and offline workloads such as large-scale synthetic data generation , Cosmos WFMs are also available on AWS Batch as containers. Cosmos-generated world states can then be used to train and validate robots using open-source simulation and learning frameworks such as NVIDIA Isaac Sim and Isaac Lab . Leading robotics companies such as Agility Robotics, Agile Robots, ANYbotics, Diligent Robotics, Dyna Robotics, Field AI, Haply Robotics, Lightwheel, RIVR and Skild AI are using the NVIDIA Isaac platform with AWS for use cases ranging from collecting, storing and processing robot-generated data to training and simulation for scaling robotics development. Sustained Collaboration Underscoring years of continued collaboration, NVIDIA earned the AWS Global GenAI Infrastructure and Data Partner of the Year award, which recognizes top technology partners with the Generative AI Competency that support vector embeddings, data storage and management or synthetic data generation in multiple types and formats. Learn more about NVIDIA and AWSâ€™s collaboration and join sessions at AWS re:Invent , running through Friday, Dec. 5, in Las Vegas. Categories: Cloud | Data Center | Generative AI | Hardware | Networking | Robotics | Software Tags: Cosmos | Events | Isaac | Nemotron | NVIDIA Blackwell | NVIDIA NIM | NVIDIA Spectrum-X | NVLink | Open Source | Physical AI | Riva]]></description>
      <author>NVIDIA</author>
      <pubDate>Tue, 02 Dec 2025 16:00:27 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/aws-partnership-expansion-reinvent/</guid>
    </item>
    <item>
      <title>At NeurIPS, NVIDIA Advances Open Model Development for Digital and Physical AI</title>
      <link>https://blogs.nvidia.com/blog/neurips-open-source-digital-physical-ai/</link>
      <description><![CDATA[Researchers worldwide rely on open-source technologies as the foundation of their work. To equip the community with the latest advancements in digital and physical AI, NVIDIA is further expanding its collection of open AI models, datasets and tools â€” with potential applications in virtually every research field. At NeurIPS , one of the worldâ€™s top AI conferences, NVIDIA is unveiling open physical AI models and tools to support research, including Alpamayo-R1, the worldâ€™s first industry-scale open reasoning vision language action (VLA) model for autonomous driving. In digital AI, NVIDIA is releasing new models and datasets for speech and AI safety. NVIDIA researchers are presenting over 70 papers, talks and workshops at the conference, sharing innovative projects that span AI reasoning, medical research, autonomous vehicle (AV) development and more. These initiatives deepen NVIDIAâ€™s commitment to open source â€” an effort recognized by a new Openness Index from Artificial Analysis , an independent organization that benchmarks AI. The Artificial Analysis Open Index rates the NVIDIA Nemotron family of open technologies for frontier AI development among the most open in the AI ecosystem based on the permissibility of the model licenses, data transparency and availability of technical details. NVIDIA DRIVE Alpamayo-R1 Opens New Research Frontier for Autonomous Driving NVIDIA DRIVE Alpamayo-R1 (AR1) , the worldâ€™s first open reasoning VLA model for AV research, integrates chain-of-thought AI reasoning with path planning â€” a component critical for advancing AV safety in complex road scenarios and enabling level 4 autonomy . While previous iterations of self-driving models struggled with nuanced situations â€” a pedestrian-heavy intersection, an upcoming lane closure or a double-parked vehicle in a bike lane â€” reasoning gives autonomous vehicles the common sense to drive more like humans do. AR1 accomplishes this by breaking down a scenario and reasoning through each step. It considers all possible trajectories, then uses contextual data to choose the best route. For example, by tapping into the chain-of-thought reasoning enabled by AR1, an AV driving in a pedestrian-heavy area next to a bike lane could take in data from its path, incorporate reasoning traces â€” explanations on why it took certain actions â€” and use that information to plan its future trajectory, such as moving away from the bike lane or stopping for potential jaywalkers. https://blogs.nvidia.com/wp-content/uploads/2025/12/construction_worker.mp4 AR1â€™s open foundation, based on NVIDIA Cosmos Reason , lets researchers customize the model for their own non-commercial use cases, whether for benchmarking or building experimental AV applications. For post-training AR1, reinforcement learning has proven especially effective â€” researchers observed a significant improvement in reasoning capabilities with AR1 compared with the pretrained model. NVIDIA DRIVE Alpamayo-R1 is now available on GitHub and Hugging Face , and a subset of the data used to train and evaluate the model is available in the NVIDIA Physical AI Open Datasets . NVIDIA has also released the open-source AlpaSim framework to evaluate AR1. Learn more about reasoning VLA models for autonomous driving . Customizing NVIDIA Cosmos for Any Physical AI Use Case Developers can learn how to use and post-train Cosmos-based models using step-by-step recipes, quick-start inference examples and advanced post-training workflows now available in the Cosmos Cookbook . Itâ€™s a comprehensive guide for physical AI developers that covers every step in AI development, including data curation, synthetic data generation and model evaluation. There are virtually limitless possibilities for Cosmos-based applications. The latest examples from NVIDIA include: LidarGen , the first world model that can generate lidar data for AV simulation. Omniverse NuRec Fixer , a model for AV and robotics simulation that taps into NVIDIA Cosmos Predict to near-instantly address artifacts in neurally reconstructed data, such as blurs and holes from novel views or noisy data. Cosmos Policy , a framework for turning large pretrained video models into robust robot policies â€” a set of rules that dictate a robotâ€™s behavior. ProtoMotions3 , an open-source, GPU-accelerated framework built on NVIDIA Newton and Isaac Lab for training physically simulated digital humans and humanoid robots with realistic scenes generated by Cosmos world foundation models (WFMs) . Sample outputs from the LidarGen model, built on Cosmos. The top row shows the input data with generated lidar data overlaid. The middle row shows generated and real lidar range maps. Bottom left shows the real lidar point cloud, while bottom right shows the point cloud generated by LidarGen. Policy models can be trained in NVIDIA Isaac Lab and Isaac Sim , and data generated from the policy models can then be used to post-train NVIDIA GR00T N models for robotics. Humanoid policy trained with ProtoMotions3 in Isaac Sim, with 3D background scene generated by Lyra with Cosmos WFM. NVIDIA ecosystem partners are developing their latest technologies with Cosmos WFMs. AV developer Voxel51 is contributing model recipes to the Cosmos Cookbook. Physical AI developers 1X , Figure AI, Foretellix, Gatik, Oxa, PlusAI and X-Humanoid are using WFMs for their latest physical AI applications. And researchers at ETH Zurich are presenting a NeurIPS paper that highlights using Cosmos models for realistic and cohesive 3D scene creation. NVIDIA Nemotron Additions Bolster the Digital AI Developer Toolkit NVIDIA is also releasing new multi-speaker speech AI models, a new model with reasoning capabilities and datasets for AI safety, as well as open tools to generate high-quality synthetic datasets for reinforcement learning and domain-specific model customization. These tools include: MultiTalker Parakeet : An automatic speech recognition model for streaming audio that can understand multiple speakers, even in overlapped or fast-paced conversations. Sortformer : A state-of-the-art model that can accurately distinguish multiple speakers within an audio stream â€” a process called diarization â€” in real time. Nemotron Content Safety Reasoning : A reasoning-based AI safety model that dynamically enforces custom policies across domains. Nemotron Content Safety Audio Dataset : A synthetic dataset that helps train models to detect unsafe audio content, enabling the development of guardrails that work across text and audio modalities. NeMo Gym : an open-source library that accelerates and simplifies the development of reinforcement learning environments for LLM training. NeMo Gym also contains a growing collection of ready-to-use training environments to enable Reinforcement Learning from Verifiable Reward (RLVR). NeMo Data Designer Library : Now open-sourced under Apache 2.0, this library provides an end-to-end toolkit to generate, validate and refine high-quality synthetic datasets for generative AI development, including domain-specific model customization and evaluation. NVIDIA ecosystem partners using NVIDIA Nemotron and NeMo tools to build secure, specialized agentic AI include CrowdStrike, Palantir and ServiceNow. NeurIPS attendees can explore these innovations at the Nemotron Summit , taking place today, from 4-8 p.m. PT, with an opening address by Bryan Catanzaro, vice president of applied deep learning research at NVIDIA. NVIDIA Research Furthers Language AI Innovation Of the dozens of NVIDIA-authored research papers at NeurIPS , here are a few highlights advancing language models: Audio Flamingo 3: Advancing Audio Intelligence With Fully Open Large Audio Language Models : This large audio language model is capable of reasoning across speech, sound and music. It can understand and reason audio segments up to 10 minutes in length, achieving state-of-the-art results on over 20 benchmarks. Minitron-SSM: Efficient Hybrid Language Model Compression Through Group-Aware SSM Pruning : This poster introduces a pruning method capable of compressing hybrid models, demonstrated by pruning and distilling Nemotron-H 8B from 8 billion to 4 billion parameters. The resulting model surpasses the accuracy of similarly sized models while achieving 2x faster inference throughput. Jet-Nemotron: Efficient Language Model With Post Neural Architecture Search : This work presents a cost-efficient post-training pipeline for developing new efficient language model architectures, and introduces a hybrid-architecture model family produced with the pipeline. These models match or surpass the accuracy of leading full-attention baselines while delivering substantially higher generation throughput. Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models : This project introduces a new small language model (SLM) architecture that redesigns SLMs around real-world latency rather than parameter count â€” achieving state-of-the-art speed and accuracy. ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models : Prolonged reinforcement learning, or ProRL, is a technique that extends model training over longer periods. In this NeurIPS poster, NVIDIA researchers describe how this methodology results in models that consistently outperform base models for reasoning. View the full list of events at NeurIPS , running through Sunday, Dec. 7, in San Diego. See notice regarding software product information. Categories: Corporate | Driving | Generative AI | Research | Robotics | Software Tags: Agentic AI | Artificial Intelligence | Cosmos | NVIDIA Research | Open Source | Physical AI | Synthetic Data Generation | Transportation]]></description>
      <author>NVIDIA</author>
      <pubDate>Mon, 01 Dec 2025 17:00:48 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/neurips-open-source-digital-physical-ai/</guid>
    </item>
    <item>
      <title>From Government to Gaming, AI Is â€˜Strengthening Koreaâ€™s Digital Foundation,â€™ NVIDIA Leader Says at AI Day Seoul</title>
      <link>https://blogs.nvidia.com/blog/ai-day-seoul/</link>
      <description><![CDATA[Last week, more than 1,000 attendees joined NVIDIA AI Day Seoul to learn about sovereign AI â€” including breakout sessions on agentic and physical AI, hands-on workshops and a startupâ€¦Read Article]]></description>
      <author>NVIDIA</author>
      <pubDate>Wed, 26 Nov 2025 17:00:32 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/ai-day-seoul/</guid>
    </item>
    <item>
      <title>FLUX.2 Image Generation Models Now Released, Optimized for NVIDIA RTX GPUs</title>
      <link>https://blogs.nvidia.com/blog/rtx-ai-garage-flux-2-comfyui/</link>
      <description><![CDATA[Black Forest Labs â€” the frontier AI research lab developing visual generative AI models â€” today released the FLUX.2 family of state-of-the-art image generation models. FLUX.2 is packed with new tools and capabilities, including a multi-reference feature that can generate dozens of similar image variations, in photorealistic detail and with cleaner fonts â€” even at scale. NVIDIA has worked with Black Forest Labs and ComfyUI to make the models available with FP8 quantizations and RTX GPU performance optimizations at launch, decreasing the VRAM required to run them by 40% and improving performance by 40%. Requiring no special software package to run, the models are available directly in ComfyUI . State-of-the-Art Visual Intelligence Images generated by FLUX.2 are photorealistic, even at scale, featuring up to 4 megapixel resolution with real-world lighting and physics to eliminate that â€œAI lookâ€ that undermines visual fidelity. The models add direct pose control to explicitly specify the pose of a subject or character in an image, as well as deliver clean, readable text across infographics, user interface screens and even multilingual content. Plus, the new multi-reference feature enables artists to select up to six reference images where the style or subject stays consistent â€” eliminating the need for extensive model fine-tuning. Stunning, photorealistic details. Image courtesy of Black Forest Labs. For a complete overview of new FLUX.2 features, read Black Forest Labsâ€™ blog . Optimized for RTX The new FLUX.2 models are impressive, but also quite demanding. They run a staggering 32-billion-parameter model requiring 90GB VRAM to load completely. Even using lowVRAM mode â€” a popular setting that allows artists to only load the active model at a time â€” the VRAM requirement is still 64GB, which puts the model virtually out of reach for any consumer card to use effectively. To broaden FLUX.2 model accessibility, NVIDIA and Black Forest Labs collaborated to quantize the model to FP8 â€” reducing the VRAM requirements by 40% at comparable quality. FLUX.2 is here. And to make this model accessible on GeForce RTX GPUs, NVIDIA has partnered with ComfyUI â€” a popular application to run visual generative AI models on PC â€” to improve the appâ€™s RAM offload feature, known as weight streaming. Using the upgraded feature, users can offload parts of the model to system memory, extending the available memory on their GPUs â€” albeit with some performance loss, as system memory is slower than GPU memory. NVIDIA has also been collaborating with ComfyUI to optimize model performance on NVIDIA and GeForce RTX GPUs, including optimizations for FP8 checkpoints. Get started with FLUX.2 today. Update ComfyUI and check out the FLUX.2 templates, or visit Black Forest Labsâ€™ Hugging Face page to download the model weights. Plug in to NVIDIA AI PC on Facebook , Instagram , TikTok and X â€” and stay informed by subscribing to the RTX AI PC newsletter . Follow NVIDIA Workstation on LinkedIn and X . Categories: Generative AI Tags: Artificial Intelligence | Conversational AI | Creators | GeForce | NVIDIA RTX | Rendering | RTX AI Garage]]></description>
      <author>NVIDIA</author>
      <pubDate>Tue, 25 Nov 2025 15:53:21 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/rtx-ai-garage-flux-2-comfyui/</guid>
    </item>
    <item>
      <title>AI On: 3 Ways Specialized AI Agents Are Reshaping Businesses</title>
      <link>https://blogs.nvidia.com/blog/specialized-ai-agents/</link>
      <description><![CDATA[Editorâ€™s note: This post is part of the AI On blog series, which explores the latest techniques and real-world applications of agentic AI, chatbots and copilots. The series also highlights the NVIDIA software and hardware powering advanced AI agents, which form the foundation of AI query engines that gather insights and perform tasks to transform everyday experiences and reshape industries. As agentic AI adoption continues to grow, with open-source models and tools maturing, companies across industries are increasingly asking: what AI agents should we build to solve our unique business challenges? Although faster outcomes are a core benefit of using AI, organizations are finding that specialization is the key to business impact and long-term AI adoption. Rather than relying on one-size-fits-all models and services, leading companies are developing specialized AI agents designed to understand and act within the needs of a specific use case. CrowdStrike, PayPal and Synopsys are examples of companies combining NVIDIA Nemotron open foundation models with their proprietary data and institutional knowledge to create specialized applications. The results are intelligent agents that have the level of expertise required to work alongside human colleagues and boost business operations. 1. CrowdStrike Defends Against Modern Cyber Threats In cybersecurity, speed and precision are essential, especially as cyber threats become more advanced and grow to larger scales. To meet these rapidly evolving digital threats, CrowdStrike is building specialized AI agents that can work alongside security teams through Charlotte AI AgentWorks. These agents, powered by NVIDIA Nemotron open models and NVIDIA NIM microservices, automate high-volume tasks such as alert triage and remediation, allowing human analysts to focus on higher-order decision-making. Built on open models and continuously trained by incident responders, CrowdStrikeâ€™s Agentic Security Platform increases accuracy of alert triage from 80% to 98.5% , reducing security analyst teamsâ€™ manual effort tenfold. The platform can adapt to new risks and collaborates across the security operations center. 2. PayPalâ€™s AI Agents Power Frictionless Commerce at Scale PayPal, a leader in payments and e-commerce, is building agent-driven infrastructure to accelerate intelligent commerce . The companyâ€™s specialized AI agents, developed on Nemotron open models, will enable the first wave of conversational commerce experiences, where agents can shop, buy and pay on a userâ€™s behalf. With this approach, PayPal built a fine-tuning pipeline in two weeks and reduced latency by nearly 50% while maintaining the high accuracy required to serve its 430 million customers and 30 million merchants. PayPalâ€™s agents rely on open, modular models that are fine-tuned specifically for payments and commerce, giving the company the control to balance performance, accuracy and cost at a massive scale. 3. Synopsys Advances Agentic AI for Chip Design Workflows The complexity of modern semiconductor design and manufacturing calls for expertise, precision and speed. Synopsys is pioneering an agentic AI framework that can be deployed throughout the chip development workflow. Synopsysâ€™ vision for agentic AI includes Synopsys AgentEngineer technology that can significantly boost productivity in research and development, identifying critical design bugs and helping reduce costly delays that traditional techniques can miss. In early trials of a formal verification workflow, Synopsys AI agents running on NVIDIA accelerated infrastructure achieved a 72% boost in productivity. Using open models fine-tuned for each engineering task, as well as software like the NVIDIA NeMo Agent Toolkit and Blueprints, Synopsys is enabling a new frontier of AI-enabled chip design. Building Specialized AI Agents With NVIDIA Technologies Companies across industries are taking the following steps to transform their proprietary knowledge into specialized AI agents: Evaluate open models, like NVIDIA Nemotron , that provide a powerful building block to create specialized models for any domain. Curate, generate and secure domain data using NVIDIA NeMo for agent lifecycle management. Create specialized agents using customized models that have access to proprietary data. Continue to fine-tune agents over time with a data flywheel . Learn how NVIDIA Nemotron can help businesses build specialized AI agents for maximum productivity and return on investment. Categories: Data Center | Generative AI Tags: Agentic AI | AI On | Artificial Intelligence | Cybersecurity | Financial Services | Industrial and Manufacturing | Nemotron | NVIDIA Blueprints | NVIDIA NeMo | Simulation and Design]]></description>
      <author>NVIDIA</author>
      <pubDate>Mon, 24 Nov 2025 17:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/specialized-ai-agents/</guid>
    </item>
    <item>
      <title>Into the Omniverse: How Smart City AI Agents Transform Urban Operations</title>
      <link>https://blogs.nvidia.com/blog/smart-city-ai-agents-urban-operations/</link>
      <description><![CDATA[Editorâ€™s note: This post is part of Into the Omniverse , a series focused on how developers, 3D practitioners and enterprises can transform their workflows using the latest advancements in OpenUSD and NVIDIA Omniverse . Cities worldwide face unprecedented challenges as urban populations surge and infrastructure strains to keep pace. Operational challenges like traffic congestion and coordinating emergency services are compounded by fragmented data pipelines, siloed local government processes and disparate systems. Technical barriers prevent cities from accessing the comprehensive, real-time insights needed for effective decision-making and city management. Leading cities and technology partners are deploying the NVIDIA Blueprint for smart city AI , a reference application that provides the complete software stack to build, test and operate AI agents in simulation-ready ( SimReady ) digital twins. OpenUSD is an open and extensible framework that connects to each stage of this physical AI workflow. OpenUSD-enabled digital twins serve as SimReady environments where cities can simulate â€œwhat ifâ€ scenarios and generate physically accurate sensor data. The blueprint powers a three-stage workflow: 1) simulate with the NVIDIA Cosmos platform and NVIDIA Omniverse libraries to generate synthetic data, 2) train and fine-tune vision AI models, and 3) deploy real-time video analytics AI agents with the NVIDIA Metropolis platform and the NVIDIA Blueprint for video search and summarization (VSS). This enables cities to move from reactive to proactive operations.â€‹ Based on these simulations, cities can deploy operational platforms where weather data, traffic sensors and emergency response systems converge, supporting rapid testing of rare scenarios, real-time monitoring, city infrastructure planning and optimization of urban systems. From Kaohsiung City, Taiwan, cutting incident response times by 80% with street-level AI to Raleigh, North Carolina, achieving 95% vehicle detection accuracy and French rail networks optimizing energy consumption by 20%, cities across the globe are using digital twins and AI agents to transform urban operations at scale. Smart Cities in Action Akila, With SNCF Gares&Connexions, Uses Digital Twins to Improve Rail Operations Akilaâ€™s digital twin application helps French rail operator SNCF Gares&Connexions optimize its network of nearly 14,000 daily trains with live scenario planning for solar heating, air flow and crowd movement. The OpenUSD-enabled digital twins deliver a 20% reduction in energy consumption, 100% on-time preventive maintenance and a 50% reduction in downtime and response times. Linker Vision Taps Physical AI for Street-Level Intelligence Linker Visionâ€™s physical AI system recognizes infrastructure events in Kaohsiung City, including damaged streetlights and fallen trees, eliminating manual city inspections and enabling faster emergency response. To scale its street-level intelligence to more cities, Linker Vision uses Omniverse libraries for simulation, Cosmos Reason for world understanding and the VSS blueprint for deployment powered by OpenUSD. Esri and Microsoft Enable Comprehensive Urban Intelligence in the City of Raleigh The City of Raleigh achieved 95% vehicle detection accuracy using the NVIDIA DeepStream software development kit, boosting traffic analysis workflows for engineers. This data enhances Raleighâ€™s digital twin, enabled by Esriâ€™s ArcGIS geospatial platform to support visualization and analysis for critical infrastructure planning and management. Integrating this computer vision pipeline with a vision AI agent powered by the NVIDIA VSS blueprint provides comprehensive real-time visibility and insights in ArcGIS on Azure Cloud. Milestone Systemsâ€™ VLM Automates Video Review Milestone Systems is soon launching its Hafnia VLM, which will include a VLM plug-in for its video management software XProtect as well as a VLM-as-a-service. Fine-tuned on more than 75,000 hours of video data, the Hafnia VLM can reduce operator alarm fatigue by up to 30% by automating video review and filtering out false alarms. It was developed with NVIDIA Cosmos Reason VLMs and Metropolis. The Hafnia VLM plug-in for XProtect will make generative AI more easily accessible for XProtect operators and users. K2K Analyzes Italy Video Streams K2Kâ€™s platform uses NVIDIA Cosmos Reason and the VSS blueprint to analyze over 1,000 video streams in Palermo, Italy, processing 7 billion events annually and automatically notifying city officials through natural language queries and video events when critical conditions are extracted and analyzed. Learn more about how cities are transforming with simulation, vision AI and digital twins by watching this on-demand NVIDIA GTC session, â€œ Leadership Strategies to Transform Public Services .â€ Get Started With Smart City AI Learn more about OpenUSD and computer vision workflows through these resources: Watch this video on bringing physical AI to cities with the NVIDIA Blueprint for smart city AI. Read this technical blog on how to integrate computer vision pipelines with generative AI and reasoning with the VSS blueprint. Access step-by-step intelligent traffic system workflows and technical recipes in new cookbooks for NVIDIA Cosmos Predict , NVIDIA Cosmos Transfer and NVIDIA Cosmos Reason . Stay up to date by subscribing to NVIDIA Omniverse news , joining the Omniverse community and following Omniverse on Discord , Instagram , LinkedIn , Threads , X and YouTube . Categories: Generative AI | Pro Graphics Tags: Agentic AI | Artificial Intelligence | Computer Vision | Cosmos | DeepStream | Digital Twin | Into the Omniverse | Metropolis | Mobility | NVIDIA Blueprints | Omniverse | Physical AI | Simulation and Design | Smart Spaces | Synthetic Data Generation | Universal Scene Description | Visual Computing]]></description>
      <author>NVIDIA</author>
      <pubDate>Thu, 20 Nov 2025 16:00:39 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/smart-city-ai-agents-urban-operations/</guid>
    </item>
  </channel>
</rss>
