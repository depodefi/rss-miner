<?xml version="1.0" ?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>NVIDIA Generative AI News</title>
    <link>https://blogs.nvidia.com/blog/category/generative-ai/</link>
    <description><![CDATA[Latest news from NVIDIA Generative AI Blog]]></description>
    <language>en-US</language>
    <lastBuildDate>Tue, 16 Dec 2025 10:04:52 GMT</lastBuildDate>
    <generator>rfeed v1.1.1</generator>
    <docs>https://github.com/svpino/rfeed/blob/master/README.md</docs>
    <item>
      <title>Cheers to AI: ADAM Robot Bartender Makes Drinks at Vegas Golden Knights Game</title>
      <link>https://blogs.nvidia.com/blog/adam-robot-vegas-golden-knights-thor/</link>
      <description><![CDATA[In Las Vegasâ€™s T-Mobile Arena, fans of the Golden Knights are getting more than just hockey â€” theyâ€™re getting a taste of the future. ADAM, a robot developed with NVIDIA Isaac libraries , is pouring drinks and turning heads in one of the NHLâ€™s most exciting venues. ADAM, short for Automated Dual Arm Mixologist, was developed by Las-Vegas based Richtech Robotics. Itâ€™s not just a novelty â€” itâ€™s a solution to real-world challenges in hospitality: labor shortages and demands for unique customer experiences. â€œThe hospitality industry faces significant labor challenges, and ADAM is our answer to meeting those needs while elevating the customer experience,â€ said Matt Casella, president of Richtech Robotics. â€œWith NVIDIAâ€™s Isaac platform, weâ€™ve developed a solution thatâ€™s scalable, consistent, and frankly, creates memorable moments for fans. The response at T-Mobile Arena has been phenomenalâ€”people love interacting with ADAM.â€ Learning to Serve Drinks in Simulation Before ADAM ever poured a drink, it trained in a virtual bar. Richtech used NVIDIA Isaac Sim , an open-source, reference robotic simulation framework built on NVIDIA Omniverse , to build a high-fidelity and physically accurate simulation of ADAMâ€™s workstation, complete with cups, utensils and lighting variations. The team generated synthetic data to teach ADAM how to recognize objects even in tricky conditions like glare or reflection. ADAMâ€™s skills such as pouring and shaking were refined in simulation using Isaac Lab , NVIDIAâ€™s open source robot learning framework. The result: a robot that doesnâ€™t just follow instructions â€” it adapts to its environment with precision. Running Real-Time AI at the Edge With Jetson ADAM runs on NVIDIA Jetson AGX Orin , the powerful edge AI platform capable of 275 TOPS of compute. Using Isaac ROS 2 libraries, ADAM captures camera feeds, detects objects and calibrates the workspace in real time. ADAMâ€™s perception stack â€” built with TAO Toolkit and optimized with TensorRT â€” enables it to identify cups, measure liquid levels and adjust movements with less than 40 milliseconds of latency. That means ADAM can spot a misplaced cup, detect when foam reaches the rim and correct a pour â€” all without missing a beat. Creating Industrial Dexterity With NVIDIA Thor While ADAM is busy serving drinks at Golden Knights games, Richtech Robotics is also making major strides in industrial automation with Dex, a new mobile humanoid robot built for factory and warehouse environments. Recently unveiled at GTC DC , Dex combines the mobility of an autonomous wheeled platform with the precision of dual-arm dexterity. Itâ€™s designed to handle such light-to-medium industrial tasks as machine operation, parts sorting, material handling and packaging â€” all with the flexibility to take on different tools and workflows. Dex runs on NVIDIA Jetson Thor , a next-generation robotics processor that gives it the ability to deliver real-time sensor processing and AI reason in dynamic industrial settings. Dex was trained from a blend of real world and synthetic data generated from Isaac Sim. This allowed Dexâ€™s model to be generalized across a multitude of scenarios. Learn more about Jetson Thor and about festive Jetson platform holiday prices . Categories: Corporate | Robotics Tags: NVIDIA Isaac Sim | NVIDIA Jetson | NVIDIA Omniverse | TensorRT]]></description>
      <author>NVIDIA</author>
      <pubDate>Fri, 12 Dec 2025 16:00:04 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/adam-robot-vegas-golden-knights-thor/</guid>
    </item>
    <item>
      <title>As AI Grows More Complex, Model Builders Rely on NVIDIA</title>
      <link>https://blogs.nvidia.com/blog/leading-models-nvidia/</link>
      <description><![CDATA[Unveiling what it describes as the most capable model series yet for professional knowledge work, OpenAI launched GPT-5.2 today. The model was trained and deployed on NVIDIA infrastructure, including NVIDIA Hopper and GB200 NVL72 systems. Itâ€™s the latest example of how leading AI builders train and deploy at scale on NVIDIAâ€™s full-stack AI infrastructure. Pretraining: The Bedrock of Intelligence AI models are getting more capable thanks to three scaling laws : pretraining, post-training and test-time scaling. Reasoning models , which apply compute during inference to tackle complex queries, using multiple networks working together, are now everywhere. But pretraining and post-training remain the bedrock of intelligence. Theyâ€™re core to making reasoning models smarter and more useful. And getting there takes scale. Training frontier models from scratch isnâ€™t a small job. It takes tens of thousands, even hundreds of thousands, of GPUs working together effectively. That level of scale demands excellence across many dimensions. It requires world-class accelerators, advanced networking across scale-up, scale-out and increasingly scale-across architectures, plus a fully optimized software stack. In short, a purpose-built infrastructure platform built to deliver performance at scale. Compared with the NVIDIA Hopper architecture, NVIDIA GB200 NVL72 systems delivered 3x faster training performance on the largest model tested in the latest MLPerf Training industry benchmarks, and nearly 2x better performance per dollar . And NVIDIA GB300 NVL72 delivers a more than 4x speedup compared with NVIDIA Hopper. These performance gains help AI developers shorten development cycles and deploy new models more quickly. Proof in the Models Across Every Modality The majority of todayâ€™s leading large language models were trained on NVIDIA platforms. AI isnâ€™t just about text. NVIDIA supports AI development across multiple modalities, including speech, image and video generation, as well as emerging areas like biology and robotics. For example, models like Evo 2 decode genetic sequences, OpenFold3 predicts 3D protein structures and Boltz-2 simulates drug interactions, helping researchers identify promising candidates faster. On the clinical side, NVIDIA Clara synthesis models generate realistic medical images to advance screening and diagnosis without exposing patient data. Companies like Runway and Inworld train on NVIDIA infrastructure. Runway last week announced Gen-4.5, a new frontier video generation model thatâ€™s the current top-rated video model in the world, according to the Artificial Analysis leaderboard. Now optimized for NVIDIA Blackwell, Gen-4.5 was developed entirely on NVIDIA GPUs across initial research and development, pre-training, post-training and inference. Runway also announced GWM-1, a state-of-the-art general world model trained on NVIDIA Blackwell thatâ€™s built to simulate reality in real time. Itâ€™s interactive, controllable and general-purpose, with applications in video games, education, science, entertainment and robotics. Benchmarks show why. MLPerf is the industry-standard benchmark for training performance. In the latest round, NVIDIA submitted results across all seven MLPerf Training 5.1 benchmarks , showing strong performance and versatility. It was the only platform to submit in every category. NVIDIAâ€™s ability to support diverse AI workloads helps data centers use resources more efficiently. Thatâ€™s why AI labs such as Black Forest Labs, Cohere, Mistral, OpenAI, Reflection and Thinking Machines Lab and are all training on the NVIDIA Blackwell platform. NVIDIA Blackwell Across Clouds and Data Centers NVIDIA Blackwell is widely available from leading cloud service providers, neo-clouds and server makers. And NVIDIA Blackwell Ultra, offering additional compute, memory and architecture improvements, is now rolling out from server makers and cloud service providers. Major cloud service providers and NVIDIA Cloud Partners , including Amazon Web Services, CoreWeave, Google Cloud, Lambda, Microsoft Azure, Nebius, Oracle Cloud Infrastructure and Together AI, to name a few, already offer instances powered by NVIDIA Blackwell, ensuring scalable performance as pretraining scaling continues. From frontier models to everyday AI, the future is being built on NVIDIA. Learn more about the NVIDIA Blackwell platform . Categories: Cloud | Corporate | Deep Learning]]></description>
      <author>NVIDIA</author>
      <pubDate>Thu, 11 Dec 2025 19:19:57 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/leading-models-nvidia/</guid>
    </item>
    <item>
      <title>Ride Into Adventure With Capcomâ€™s â€˜Monster Hunter Storiesâ€™ Series in the Cloud</title>
      <link>https://blogs.nvidia.com/blog/geforce-now-thursday-monster-hunter-stories/</link>
      <description><![CDATA[Hunters, saddle up â€” adventure awaits in the cloud. Journey into the world of Monster Hunter Stories as Capcomâ€™s acclaimed role-playing classics join GeForce NOW . Monster Hunter Stories and Monster Hunter Stories 2: Wings of Ruin are soaring into the cloud this week, bringing colorful worlds, charming companions and turn-based monster battles across devices. They lead seven new games joining the cloud this week, on top of an ARC Raiders â€œElectrician Backpack: Emerald Wave Variantâ€ reward for Ultimate members who want to drop into battle in style. Itâ€™s also been a big year for games, and this yearâ€™s major gaming awards nominees show just how strong gaming is right now â€” with many of those fan-favorite titles playable on GeForce NOW, no downloads required. Look for the â€œThe Game Awardsâ€ row in the GeForce NOW app to dive in instantly. Saddle Up Capcomâ€™s Monster Hunter Stories and Monster Hunter Stories 2: Wings of Ruin arrive in the cloud this week. Members can explore vibrant worlds, bond with quirky monsters and experience turn-based role-playing game (RPG) adventures across devices. Saddle up for egg-citement. In Monster Hunter Stories, an RPG that expands the Monster Hunter world, players are no longer hunting monsters but raising them. In this story featuring heroes known as Monster Riders, players live alongside monsters and form lifelong bonds with them. The first installment of the Monster Hunter Stories series returns, fully voiced in Japanese and English, with additional features such as a new museum mode where players can listen to music and view concept art â€” offering an even deeper dive into the world of Monster Hunter Stories. When fate calls, answer on a dragonâ€™s back. A new adventure awaits in Monster Hunter Stories 2: Wings of Ruin: the second installment of the turn-based RPG series. Become a Monster Rider and form bonds with friendly monsters known as Monsties to fight alongside them in the gameâ€™s epic story. These adventures can be enjoyed on almost any device, powered by high-performance GeForce RTX technology. Seamlessly switch between phones, laptops and desktops, and experience every lush landscape and thrilling battle with cloud-streamed visuals and smooth gameplay â€” no downloads, installs or upgrades required. And the Cloud Goes to â€¦ GeForce NOW Itâ€™s a big month for games, and this yearâ€™s major gaming awards make it an especially great time to be a gamer. Many of the buzziest nominees and fan-favorite titles are playable on GeForce NOW, where itâ€™s easy to jump into the action, catch up on the hits and see what the hypeâ€™s all about â€” all instantly, no downloads required. What a game. A stack of nominated titles are available in the cloud through GeForce NOW, including a majority of Game of the Year (GOTY) contenders like Clair Obscur: Expedition 33 , Hollow Knight: Silksong and Kingdom Come: Deliverance II . RPG fans can marathon some of the yearâ€™s best titles in the genre through the cloud. Avowed, Clair Obscur: Expedition 33, Kingdom Come: Deliverance II, Monster Hunter Wilds and The Outer Worlds 2 are all streamable on GeForce NOW.â€‹ A masterpiece. Members can also dive into other nominated favorites such as Battlefield 6 and DOOM: The Dark Ages for Best Action, Indiana Jones and the Ancient Circle and Split Fiction for Best Adventure, The Alters and Sid Meierâ€™s Civilization VII for Best Sim/Strategy, ARC Raiders and PEAK for Best Multiplayer, plus esports staples like Counter-Strike 2 and DOTA 2 . Whether chasing GOTY, exploring indies like Blue Prince and Hollow Knight: Silksong , or sticking to long-running hits like Fortnite and No Manâ€™s Sky , gamers can always find a top title ready to stream. Loot, Shoot and Look Good Doing It Pack up and stand out. Ultimate members can claim the ARC Raiders â€œElectrician Backpack: Emerald Wave Variantâ€ â€” an in-game cosmetic item that adds a distinct look. The Emerald Wave design offers a clean, modern touch for Raiders ready to stand out during extraction missions.â€‹â€‹ Jump into battle with style, powered by GeForce RTX 5080-class servers on GeForce NOW, delivering up to 2.8x higher frame rates and a new Cinematic-Quality Streaming mode that makes every firefight shine. The reward is available to Ultimate members through Sunday, Jan. 4, 2026, or while supplies last. Keep an eye on email for instructions to redeem this stylish advantage for the journey ahead. Once claimed, navigate to the Electrician Backpack and select the Emerald Wave color variant to equip it and head off in style. Fresh Crop of Games Where the cows know your name. Everdream Village , a cozy farming adventure from publisher Untold Tales, lets players turn a sleepy island settlement into a thriving, story-filled village. Tend crops, befriend quirky villagers and wrangle a menagerie of charming animals while terraforming the land and sail off to discover new magical islands â€” all while shaping a laid-back little paradise. In addition, members can look for the following: Skate Story (New release on Steam , Dec. 8) Dome Keeper (New release on Xbox , available on Game Pass, Dec. 9) Death Howl (New release on Steam and Xbox , available on Game Pass, Dec. 9) RuneQuest: Warlords (New release on Steam , Dec. 9) Everdream Village (New release on Steam , Dec. 12) Monster Hunter Stories ( Steam ) Monster Hunter Stories 2 ( Steam ) GeForce RTX 5080-ready games: Age of Wonders 4 ( Steam , Epic Games Store and Xbox , available on the Microsoft store) Cities: Skylines ( Steam and Epic Games Store ) Cities: Skylines II ( Steam and Xbox , available on Game Pass) What are you planning to play this weekend? Let us know on X or in the comments below. What's on the top of your gaming wishlist this holiday? âœï¸â„ï¸ â€” ðŸŒ©ï¸ NVIDIA GeForce NOW (@NVIDIAGFN) December 10, 2025 Categories: Gaming Tags: Cloud Gaming | GeForce NOW]]></description>
      <author>NVIDIA</author>
      <pubDate>Thu, 11 Dec 2025 14:00:09 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/geforce-now-thursday-monster-hunter-stories/</guid>
    </item>
    <item>
      <title>Opt-In NVIDIA Software Enables Data Center Fleet Management</title>
      <link>https://blogs.nvidia.com/blog/optional-data-center-fleet-management-software/</link>
      <description><![CDATA[As the scale and complexity of AI infrastructure grows, data center operators need continuous visibility into factors including performance, temperature and power usage. These insights enable data center operators to actively monitor and adjust data center configurations across large-scale, distributed systems â€” validating that these systems are operating at their highest efficiency and reliability. NVIDIA is developing a software solution for visualizing and monitoring fleets of NVIDIA GPUs â€” giving cloud partners and enterprises an insights dashboard that can help them boost GPU uptime across computing infrastructures. The offering is an opt-in, customer-installed service that monitors GPU usage, configuration and errors. It will include an open-source client software agent â€” part of NVIDIAâ€™s ongoing support of open, transparent software that helps customers get the most from their GPU-powered systems. With the service, data center operators will be able to: Track spikes in power usage to keep within energy budgets while maximizing performance per watt. Monitor utilization, memory bandwidth and interconnect health across the fleet. Detect hotspots and airflow issues early to avoid thermal throttling and premature component aging. Confirm consistent software configurations and settings to ensure reproducible results and reliable operation. Spot errors and anomalies to identify failing parts early. These capabilities can help enterprises and cloud providers visualize their GPU fleet, address system bottlenecks and optimize productivity for higher return on investment. This optional service provides real-time monitoring by each GPU system communicating and sharing GPU metrics with the external cloud service. NVIDIA GPUs do not have hardware tracking technology, kill switches and backdoors . Open-Source Agent Offers Insights for Data Center Owners The service will feature a client software agent that the customer can install to stream node-level GPU telemetry data to a portal hosted on NVIDIA NGC . Customers will be able to visualize their GPU fleet utilization in a dashboard, globally or by compute zones â€” groups of nodes enrolled in the same physical or cloud locations. The dashboard provides insight into GPU status across a customerâ€™s global fleet. The client tooling agent is also slated to be open sourced, providing transparency and auditability. Itâ€™ll offer a working example for how customers can incorporate NVIDIA tools into their own solutions for monitoring GPU infrastructure â€” whether for critical compute clusters or entire fleets. The software provides insight into a companyâ€™s GPU inventory but cannot modify GPU configurations or underlying operations. It provides read-only telemetry data thatâ€™s customer managed and customizable. The service will also enable customers to generate reports that detail GPU fleet information. As AI applications grow in number and complexity, modern AI infrastructure management is evolving to keep pace. Making sure that AI data centers are running at peak health is vital as AI revolutionizes every industry and application. This software service is here to help. Register for NVIDIA GTC , taking place March 16-19 in San Jose, California, to learn more. See notice regarding software product information. Categories: Corporate | Software Tags: Cybersecurity]]></description>
      <author>NVIDIA</author>
      <pubDate>Wed, 10 Dec 2025 23:49:26 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/optional-data-center-fleet-management-software/</guid>
    </item>
    <item>
      <title>How NVIDIA H100 GPUs on CoreWeaveâ€™s AI Cloud Platform Delivered a Record-Breaking Graph500 Run</title>
      <link>https://blogs.nvidia.com/blog/h100-coreweave-graph500/</link>
      <description><![CDATA[The worldâ€™s top-performing system for graph processing at scale was built on a commercially available cluster. NVIDIA last month announced a record-breaking benchmark result of 410 trillion traversed edges per second (TEPS), ranking No. 1 on the 31st Graph500 breadth-first search (BFS) list. Performed on an accelerated computing cluster hosted in a CoreWeave data center in Dallas, the winning run used 8,192 NVIDIA H100 GPUs to process a graph with 2.2 trillion vertices and 35 trillion edges. This result is more than double the performance of comparable solutions on the list, including those hosted in national labs. To put this performance in perspective, say every person on Earth has 150 friends. This would represent 1.2 trillion edges in a graph of social relationships. The level of performance recently achieved by NVIDIA and CoreWeave enables searching through every friend relationship on Earth in just about three milliseconds. Speed at that scale is half the story â€” the real breakthrough is efficiency. A comparable entry in the top 10 runs of the Graph500 list used about 9,000 nodes, while the winning run from NVIDIA used just over 1,000 nodes, delivering 3x better performance per dollar. NVIDIA tapped into the combined power of its full-stack compute, networking and software technologies â€” including the NVIDIA CUDA platform, Spectrum-X networking, H100 GPUs and a new active messaging library â€” to push the boundaries of performance while minimizing hardware footprint. By saving significant time and costs at this scale in a commercially available system, the win demonstrates how the NVIDIA computing platform is ready to democratize access to acceleration of the worldâ€™s largest sparse, irregular workloads â€” involving data and work items that come in varying and unpredictable sizes â€” in addition to dense workloads like AI training. How Graphs at Scale Work Graphs are the underlying information structure for modern technology. People interact with them on social networks and banking apps, among other use cases, every day. Graphs capture relationships between pieces of information in massive webs of information. For example, consider LinkedIn. A userâ€™s profile is a vertex. Connections or relationships to other users are edges â€” with other users represented as vertices. Some users have five connections, others have 50,000. This creates variable density across the graph, making it sparse and irregular. Unlike an image or language model, which is structured and dense, a graph is unpredictable. Graph500 BFS has a long history as the industry-standard benchmark because it measures a systemâ€™s ability to navigate this irregularity at scale. BFS measures the speed of traversing the graph through every vertex and edge. A high TEPS score for BFS â€” measuring how fast the system can process these edges â€” proves the system has superior interconnects, such as cables or switches between compute nodes, as well as more memory bandwidth and software able to take advantage of the systemâ€™s capabilities. It validates the engineering of the entire system, not just the speed of the CPU or GPU. Effectively, itâ€™s a measure of how fast a system can â€œthinkâ€ and associate disparate pieces of information. Current Techniques for Processing Graphs GPUs are known for accelerating dense workloads like AI training. Until recently, the largest sparse linear algebra and graph workloads have remained the domain of traditional CPU architectures. To process graphs, CPUs move graph data across compute nodes. As the graph scales to trillions of edges, this constant movement creates bottlenecks and jams communications. Developers use a variety of software techniques to circumvent this issue. A common approach is to process the graph where it is with active messages, where developers send messages that can process graph data in place. The messages are smaller and can be grouped together to maximize network efficiency. While this software technique significantly accelerates processing, active messaging was designed to run on CPUs and is inherently limited by the throughput rate and compute capabilities of CPU systems. Reengineering Graph Processing for the GPU To speed up the BFS run, NVIDIA engineered a full-stack, GPU-only solution that reimagines how data moves across the network. A custom software framework developed using InfiniBand GPUDirect Async (IBGDA) and the NVSHMEM parallel programming interface enables GPU-to-GPU active messages. With IBGDA, the GPU can directly communicate with the InfiniBand network interface card. Message aggregation has been engineered from the ground up to support hundreds of thousands of GPU threads sending active messages simultaneously, compared with just hundreds of threads on a CPU. As such, in this redesigned system, active messaging runs completely on GPUs, bypassing the CPU. This enables taking full advantage of the massive parallelism and memory bandwidth of NVIDIA H100 GPUs to send messages, move them across the network and process them on the receiver. Running on the stable, high-performance infrastructure of NVIDIA partner CoreWeave, this orchestration enabled doubling the performance of comparable runs while using a fraction of the hardware â€” at a fraction of the cost. NVIDIA submission run on CoreWeave cluster with 8,192 H100 GPUs tops the leaderboard on the 31st Graph500 breadth-first search list. Accelerating New Workloads This breakthrough has massive implications for high-performance computing. HPC fields like fluid dynamics and weather forecasting rely on similar sparse data structures and communication patterns that power the graphs that underpin social networks and cybersecurity. For decades, these fields have been tethered to CPUs at the largest scales, even as data scales from billions to trillions of edges. NVIDIAâ€™s winning result on Graph500, alongside two other top 10 entries, validates a new approach for high-performance computing at scale. With the full-stack orchestration of NVIDIA computing, networking and software, developers can now use technologies like NVSHMEM and IBGDA to efficiently scale their largest HPC applications, bringing supercomputing performance to commercially available infrastructure. Stay up to date on the latest Graph500 benchmarks and learn more about NVIDIA networking technologies . Categories: Data Center | Networking Tags: Cloud Services | CUDA | Hardware | NVIDIA Hopper Architecture | Supercomputing]]></description>
      <author>NVIDIA</author>
      <pubDate>Wed, 10 Dec 2025 20:56:53 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/h100-coreweave-graph500/</guid>
    </item>
    <item>
      <title>NVIDIA Awards up to $60,000 Research Fellowships to PhD Students</title>
      <link>https://blogs.nvidia.com/blog/graduate-fellowship-recipients-2026-2027/</link>
      <description><![CDATA[For 25 years, the NVIDIA Graduate Fellowship Program has supported graduate students doing outstanding work relevant to NVIDIA technologies. Today, the program announced the latest awards of up to $60,000 each to 10 Ph.D. students involved in research that spans all areas of computing innovation. Selected from a highly competitive applicant pool, the awardees will participate in a summer internship preceding the fellowship year. Their work puts them at the forefront of accelerated computing â€” tackling projects in autonomous systems, computer architecture, computer graphics, deep learning, programming systems, robotics and security. The NVIDIA Graduate Fellowship Program is open to applicants worldwide. The 2026-2027 fellowship recipients are: Jiageng Mao , University of Southern California â€” Solving complex physical AI problems by using diverse priors from internet-scale data to enable robust, generalizable intelligence for embodied agents in the real world. Liwen Wu , University of California San Diego â€” Enriching realism and efficiency in physically based rendering with neural materials and neural rendering. Manya Bansal , Massachusetts Institute of Technology â€” Designing programming languages for modern accelerators that enable developers to write modular, reusable code without sacrificing the low-level control required for peak performance. Sizhe Chen , University of California, Berkeley â€” Securing AI in real-world applications, currently securing AI agents against prompt injection attacks with general and practical defenses that preserve the agentâ€™s utility. Yunfan Jiang , Stanford University â€” Developing scalable approaches to build generalist robots for everyday tasks through hybrid data sources spanning real-world whole-body manipulation, large-scale simulation and internet-scale multimodal supervision. Yijia Shao , Stanford University â€” Researching human-agent collaboration by developing AI agents that can communicate and coordinate with humans during task execution, and designing new human-agent interaction interfaces. Shangbin Feng , University of Washington â€” Advancing model collaboration: multiple machine learning models, trained on different data and by different people, collaborate, compose and complement each other for an open, decentralized and collaborative AI future. Shvetank Prakash , Harvard University â€” Advancing hardware architecture and systems design with AI agents built on new algorithms, curated datasets and agent-first infrastructure. Irene Wang , Georgia Institute of Technology â€” Developing a holistic codesign framework that integrates accelerator architecture, network topology and runtime scheduling to enable energy-efficient and sustainable AI training at scale. Chen Geng , Stanford University â€” Modeling 4D physical worlds with scalable data-driven algorithms and physics-inspired principles, advancing physically grounded 3D and 4D world models for robotics and scientific applications. We also acknowledge the 2026-2027 fellowship finalists: Zizheng Guo , Peking University Peter Holderrieth , Massachusetts Institute of Technology Xianghui Xie , Max Planck Institute for Informatics Alexander Root , Stanford University Daniel Palenicek , Technical University of Darmstadt Categories: Generative AI | Research Tags: Artificial Intelligence | Education]]></description>
      <author>NVIDIA</author>
      <pubDate>Thu, 04 Dec 2025 17:00:44 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/graduate-fellowship-recipients-2026-2027/</guid>
    </item>
    <item>
      <title>NVIDIA and AWS Expand Full-Stack Partnership, Providing the Secure, High-Performance Compute Platform Vital for Future Innovation</title>
      <link>https://blogs.nvidia.com/blog/aws-partnership-expansion-reinvent/</link>
      <description><![CDATA[At AWS re:Invent, NVIDIA and Amazon Web Services expanded their strategic collaboration with new technology integrations across interconnect technology, cloud infrastructure, open models and physical AI. As part of this expansion, AWS will support NVIDIA NVLink Fusion â€” a platform for custom AI infrastructure â€” for deploying its custom-designed silicon, including next-generation Trainium4 chips for inference and agentic AI model training, Graviton CPUs for a broad range of workloads and the Nitro System virtualization infrastructure. Using NVIDIA NVLink Fusion, AWS will combine NVIDIA NVLink scale-up interconnect and the NVIDIA MGX rack architecture with AWS custom silicon to increase performance and accelerate time to market for its next-generation cloud-scale AI capabilities. AWS is designing Trainium4 to integrate with NVLink and NVIDIA MGX, the first of a multigenerational collaboration between NVIDIA and AWS for NVLink Fusion. AWS has already deployed MGX racks at scale with NVIDIA GPUs. Integrating NVLink Fusion will allow AWS to further simplify deployment and systems management across its platforms. AWS can also harness the NVLink Fusion supplier ecosystem, which provides all the components required for full rack-scale deployment, from the rack and chassis, to power-delivery and cooling systems. By supporting AWSâ€™s Elastic Fabric Adapter and Nitro System, the NVIDIA Vera Rubin architecture on AWS will give customers robust networking choices while maintaining full compatibility with AWSâ€™s cloud infrastructure and accelerating new AI service rollout. â€œGPU compute demand is skyrocketing â€” more compute makes smarter AI, smarter AI drives broader use and broader use creates demand for even more compute. The virtuous cycle of AI has arrived,â€ said Jensen Huang, founder and CEO of NVIDIA. â€œWith NVIDIA NVLink Fusion coming to AWS Trainium4, weâ€™re unifying our scale-up architecture with AWSâ€™s custom silicon to build a new generation of accelerated platforms. Together, NVIDIA and AWS are creating the compute fabric for the AI industrial revolution â€” bringing advanced AI to every company, in every country, and accelerating the worldâ€™s path to intelligence.â€ â€œAWS and NVIDIA have worked side by side for more than 15 years, and today marks a new milestone in that journey,â€ said Matt Garman, CEO of AWS. â€œWith NVIDIA, weâ€™re advancing our large-scale AI infrastructure to deliver customers the highest performance, efficiency and scalability. The upcoming support of NVIDIA NVLink Fusion in AWS Trainium4, Graviton and the Nitro System will bring new capabilities to customers so they can innovate faster than ever before.â€ Convergence of Scale and Sovereignty AWS has expanded its accelerated computing portfolio with the NVIDIA Blackwell architecture, including NVIDIA HGX B300 and NVIDIA GB300 NVL72 GPUs, giving customers immediate access to the industryâ€™s most advanced GPUs for training and inference. Availability of NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, designed for visual applications, on AWS is expected in the coming weeks. These GPUs form part of the AWS infrastructure backbone powering AWS AI Factories, a new AI cloud offering that will provide customers around the world with the dedicated infrastructure they need to harness advanced AI services and capabilities in their own data centers, operated by AWS, while also letting customers maintain control of their data and comply with local regulations. NVIDIA and AWS are committing to deploy sovereign AI clouds globally and bring the best of AI innovation to the world. With the launch of AWS AI Factories, the companies are providing secure, sovereign AI infrastructure to deliver unprecedented computing capabilities for organizations around the world while meeting increasingly rigorous sovereign AI requirements. For public sector organizations, AWS AI Factories will transform the federal supercomputing and AI landscape. AWS AI Factories customers will be able to seamlessly integrate AWSâ€™s industry-leading cloud infrastructure and services â€” known for its reliability, security and scalability â€” with NVIDIA Blackwell GPUs and the full-stack NVIDIA accelerated computing platform, including NVIDIA Spectrum-X Ethernet switches. The unified architecture will ensure customers can access advanced AI services and capabilities, as well as train and deploy massive models, while maintaining absolute control of proprietary data and full compliance with local regulatory frameworks. NVIDIA Nemotron Integration With Amazon Bedrock Expands Software Optimizations Beyond hardware, the partnership expands integration of NVIDIAâ€™s software stack with the AWS AI ecosystem. NVIDIA Nemotron open models are now integrated with Amazon Bedrock , enabling customers to build generative AI applications and agents at production scale. Developers can access Nemotron Nano 2 and Nemotron Nano 2 VL to build specialized agentic AI applications that process text, code, images and video with high efficiency and accuracy. The integration makes high-performance, open NVIDIA models instantly accessible via Amazon Bedrockâ€™s serverless platform where customers can rely on proven scalability and zero infrastructure management. Industry leaders CrowdStrike and BridgeWise are the first to use the service to deploy specialized AI agents. NVIDIA Software on AWS Simplifies Developer Experience NVIDIA and AWS are also co-engineering at the software layer to accelerate the data backbone of every enterprise. Amazon OpenSearch Service now offers serverless GPU acceleration for vector index building, powered by NVIDIA cuVS , an open-source library for GPU-accelerated vector search and data clustering. This milestone represents a fundamental shift to using GPUs for unstructured data processing, with early adopters seeing up to 10x faster vector indexing at a quarter of the cost. These dramatic gains reduce search latency, accelerate writes and unlock faster productivity for dynamic AI techniques like retrieval-augmented generation by delivering the right amount of GPU power precisely when itâ€™s needed. AWS is the first major cloud provider to offer serverless vector indexing with NVIDIA GPUs. Production-ready AI agents require performance visibility, optimization and scalable infrastructure. By combining Strands Agents for agent development and orchestration, the NVIDIA NeMo Agent Toolkit for deep profiling and performance tuning, and Amazon Bedrock AgentCore for secure, scalable agent infrastructure, organizations can empower developers with a complete, predictable path from prototype to production. This expanded support builds on AWSâ€™s existing integrations with NVIDIA technologies â€” including NVIDIA NIM microservices and frameworks like NVIDIA Riva and NVIDIA BioNeMo , as well as model development tools integrated with Amazon SageMaker and Amazon Bedrock â€” that enable organizations to deploy agentic AI, speech AI and scientific applications faster than ever. Accelerating Physical AI With AWS Developing physical AI demands high-quality and diverse datasets for training robot models, as well as frameworks for testing and validation in simulation before real-world deployment. NVIDIA Cosmos world foundation models (WFMs) are now available as NVIDIA NIM microservices on Amazon EKS , enabling real-time robotics control and simulation workloads with seamless reliability and cloud-native efficiency. For batch-based tasks and offline workloads such as large-scale synthetic data generation , Cosmos WFMs are also available on AWS Batch as containers. Cosmos-generated world states can then be used to train and validate robots using open-source simulation and learning frameworks such as NVIDIA Isaac Sim and Isaac Lab . Leading robotics companies such as Agility Robotics, Agile Robots, ANYbotics, Diligent Robotics, Dyna Robotics, Field AI, Haply Robotics, Lightwheel, RIVR and Skild AI are using the NVIDIA Isaac platform with AWS for use cases ranging from collecting, storing and processing robot-generated data to training and simulation for scaling robotics development. Sustained Collaboration Underscoring years of continued collaboration, NVIDIA earned the AWS Global GenAI Infrastructure and Data Partner of the Year award, which recognizes top technology partners with the Generative AI Competency that support vector embeddings, data storage and management or synthetic data generation in multiple types and formats. Learn more about NVIDIA and AWSâ€™s collaboration and join sessions at AWS re:Invent , running through Friday, Dec. 5, in Las Vegas. Categories: Cloud | Data Center | Generative AI | Hardware | Networking | Robotics | Software Tags: Cosmos | Events | Isaac | Nemotron | NVIDIA Blackwell | NVIDIA NIM | NVIDIA Spectrum-X | NVLink | Open Source | Physical AI | Riva]]></description>
      <author>NVIDIA</author>
      <pubDate>Tue, 02 Dec 2025 16:00:27 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/aws-partnership-expansion-reinvent/</guid>
    </item>
    <item>
      <title>At NeurIPS, NVIDIA Advances Open Model Development for Digital and Physical AI</title>
      <link>https://blogs.nvidia.com/blog/neurips-open-source-digital-physical-ai/</link>
      <description><![CDATA[Researchers worldwide rely on open-source technologies as the foundation of their work. To equip the community with the latest advancements in digital and physical AI, NVIDIA is further expanding its collection of open AI models, datasets and tools â€” with potential applications in virtually every research field. At NeurIPS , one of the worldâ€™s top AI conferences, NVIDIA is unveiling open physical AI models and tools to support research, including Alpamayo-R1, the worldâ€™s first industry-scale open reasoning vision language action (VLA) model for autonomous driving. In digital AI, NVIDIA is releasing new models and datasets for speech and AI safety. NVIDIA researchers are presenting over 70 papers, talks and workshops at the conference, sharing innovative projects that span AI reasoning, medical research, autonomous vehicle (AV) development and more. These initiatives deepen NVIDIAâ€™s commitment to open source â€” an effort recognized by a new Openness Index from Artificial Analysis , an independent organization that benchmarks AI. The Artificial Analysis Open Index rates the NVIDIA Nemotron family of open technologies for frontier AI development among the most open in the AI ecosystem based on the permissibility of the model licenses, data transparency and availability of technical details. NVIDIA DRIVE Alpamayo-R1 Opens New Research Frontier for Autonomous Driving NVIDIA DRIVE Alpamayo-R1 (AR1) , the worldâ€™s first open reasoning VLA model for AV research, integrates chain-of-thought AI reasoning with path planning â€” a component critical for advancing AV safety in complex road scenarios and enabling level 4 autonomy . While previous iterations of self-driving models struggled with nuanced situations â€” a pedestrian-heavy intersection, an upcoming lane closure or a double-parked vehicle in a bike lane â€” reasoning gives autonomous vehicles the common sense to drive more like humans do. AR1 accomplishes this by breaking down a scenario and reasoning through each step. It considers all possible trajectories, then uses contextual data to choose the best route. For example, by tapping into the chain-of-thought reasoning enabled by AR1, an AV driving in a pedestrian-heavy area next to a bike lane could take in data from its path, incorporate reasoning traces â€” explanations on why it took certain actions â€” and use that information to plan its future trajectory, such as moving away from the bike lane or stopping for potential jaywalkers. https://blogs.nvidia.com/wp-content/uploads/2025/12/construction_worker.mp4 AR1â€™s open foundation, based on NVIDIA Cosmos Reason , lets researchers customize the model for their own non-commercial use cases, whether for benchmarking or building experimental AV applications. For post-training AR1, reinforcement learning has proven especially effective â€” researchers observed a significant improvement in reasoning capabilities with AR1 compared with the pretrained model. NVIDIA DRIVE Alpamayo-R1 is now available on GitHub and Hugging Face , and a subset of the data used to train and evaluate the model is available in the NVIDIA Physical AI Open Datasets . NVIDIA has also released the open-source AlpaSim framework to evaluate AR1. Learn more about reasoning VLA models for autonomous driving . Customizing NVIDIA Cosmos for Any Physical AI Use Case Developers can learn how to use and post-train Cosmos-based models using step-by-step recipes, quick-start inference examples and advanced post-training workflows now available in the Cosmos Cookbook . Itâ€™s a comprehensive guide for physical AI developers that covers every step in AI development, including data curation, synthetic data generation and model evaluation. There are virtually limitless possibilities for Cosmos-based applications. The latest examples from NVIDIA include: LidarGen , the first world model that can generate lidar data for AV simulation. Omniverse NuRec Fixer , a model for AV and robotics simulation that taps into NVIDIA Cosmos Predict to near-instantly address artifacts in neurally reconstructed data, such as blurs and holes from novel views or noisy data. Cosmos Policy , a framework for turning large pretrained video models into robust robot policies â€” a set of rules that dictate a robotâ€™s behavior. ProtoMotions3 , an open-source, GPU-accelerated framework built on NVIDIA Newton and Isaac Lab for training physically simulated digital humans and humanoid robots with realistic scenes generated by Cosmos world foundation models (WFMs) . Sample outputs from the LidarGen model, built on Cosmos. The top row shows the input data with generated lidar data overlaid. The middle row shows generated and real lidar range maps. Bottom left shows the real lidar point cloud, while bottom right shows the point cloud generated by LidarGen. Policy models can be trained in NVIDIA Isaac Lab and Isaac Sim , and data generated from the policy models can then be used to post-train NVIDIA GR00T N models for robotics. Humanoid policy trained with ProtoMotions3 in Isaac Sim, with 3D background scene generated by Lyra with Cosmos WFM. NVIDIA ecosystem partners are developing their latest technologies with Cosmos WFMs. AV developer Voxel51 is contributing model recipes to the Cosmos Cookbook. Physical AI developers 1X , Figure AI, Foretellix, Gatik, Oxa, PlusAI and X-Humanoid are using WFMs for their latest physical AI applications. And researchers at ETH Zurich are presenting a NeurIPS paper that highlights using Cosmos models for realistic and cohesive 3D scene creation. NVIDIA Nemotron Additions Bolster the Digital AI Developer Toolkit NVIDIA is also releasing new multi-speaker speech AI models, a new model with reasoning capabilities and datasets for AI safety, as well as open tools to generate high-quality synthetic datasets for reinforcement learning and domain-specific model customization. These tools include: MultiTalker Parakeet : An automatic speech recognition model for streaming audio that can understand multiple speakers, even in overlapped or fast-paced conversations. Sortformer : A state-of-the-art model that can accurately distinguish multiple speakers within an audio stream â€” a process called diarization â€” in real time. Nemotron Content Safety Reasoning : A reasoning-based AI safety model that dynamically enforces custom policies across domains. Nemotron Content Safety Audio Dataset : A synthetic dataset that helps train models to detect unsafe audio content, enabling the development of guardrails that work across text and audio modalities. NeMo Gym : an open-source library that accelerates and simplifies the development of reinforcement learning environments for LLM training. NeMo Gym also contains a growing collection of ready-to-use training environments to enable Reinforcement Learning from Verifiable Reward (RLVR). NeMo Data Designer Library : Now open-sourced under Apache 2.0, this library provides an end-to-end toolkit to generate, validate and refine high-quality synthetic datasets for generative AI development, including domain-specific model customization and evaluation. NVIDIA ecosystem partners using NVIDIA Nemotron and NeMo tools to build secure, specialized agentic AI include CrowdStrike, Palantir and ServiceNow. NeurIPS attendees can explore these innovations at the Nemotron Summit , taking place today, from 4-8 p.m. PT, with an opening address by Bryan Catanzaro, vice president of applied deep learning research at NVIDIA. NVIDIA Research Furthers Language AI Innovation Of the dozens of NVIDIA-authored research papers at NeurIPS , here are a few highlights advancing language models: Audio Flamingo 3: Advancing Audio Intelligence With Fully Open Large Audio Language Models : This large audio language model is capable of reasoning across speech, sound and music. It can understand and reason audio segments up to 10 minutes in length, achieving state-of-the-art results on over 20 benchmarks. Minitron-SSM: Efficient Hybrid Language Model Compression Through Group-Aware SSM Pruning : This poster introduces a pruning method capable of compressing hybrid models, demonstrated by pruning and distilling Nemotron-H 8B from 8 billion to 4 billion parameters. The resulting model surpasses the accuracy of similarly sized models while achieving 2x faster inference throughput. Jet-Nemotron: Efficient Language Model With Post Neural Architecture Search : This work presents a cost-efficient post-training pipeline for developing new efficient language model architectures, and introduces a hybrid-architecture model family produced with the pipeline. These models match or surpass the accuracy of leading full-attention baselines while delivering substantially higher generation throughput. Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models : This project introduces a new small language model (SLM) architecture that redesigns SLMs around real-world latency rather than parameter count â€” achieving state-of-the-art speed and accuracy. ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models : Prolonged reinforcement learning, or ProRL, is a technique that extends model training over longer periods. In this NeurIPS poster, NVIDIA researchers describe how this methodology results in models that consistently outperform base models for reasoning. View the full list of events at NeurIPS , running through Sunday, Dec. 7, in San Diego. See notice regarding software product information. Categories: Corporate | Driving | Generative AI | Research | Robotics | Software Tags: Agentic AI | Artificial Intelligence | Cosmos | NVIDIA Research | Open Source | Physical AI | Synthetic Data Generation | Transportation]]></description>
      <author>NVIDIA</author>
      <pubDate>Mon, 01 Dec 2025 17:00:48 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/neurips-open-source-digital-physical-ai/</guid>
    </item>
    <item>
      <title>From Government to Gaming, AI Is â€˜Strengthening Koreaâ€™s Digital Foundation,â€™ NVIDIA Leader Says at AI Day Seoul</title>
      <link>https://blogs.nvidia.com/blog/ai-day-seoul/</link>
      <description><![CDATA[Last week, more than 1,000 attendees joined NVIDIA AI Day Seoul to learn about sovereign AI â€” including breakout sessions on agentic and physical AI, hands-on workshops and a startupâ€¦Read Article]]></description>
      <author>NVIDIA</author>
      <pubDate>Wed, 26 Nov 2025 17:00:32 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/ai-day-seoul/</guid>
    </item>
    <item>
      <title>FLUX.2 Image Generation Models Now Released, Optimized for NVIDIA RTX GPUs</title>
      <link>https://blogs.nvidia.com/blog/rtx-ai-garage-flux-2-comfyui/</link>
      <description><![CDATA[Black Forest Labs â€” the frontier AI research lab developing visual generative AI models â€” today released the FLUX.2 family of state-of-the-art image generation models. FLUX.2 is packed with new tools and capabilities, including a multi-reference feature that can generate dozens of similar image variations, in photorealistic detail and with cleaner fonts â€” even at scale. NVIDIA has worked with Black Forest Labs and ComfyUI to make the models available with FP8 quantizations and RTX GPU performance optimizations at launch, decreasing the VRAM required to run them by 40% and improving performance by 40%. Requiring no special software package to run, the models are available directly in ComfyUI . State-of-the-Art Visual Intelligence Images generated by FLUX.2 are photorealistic, even at scale, featuring up to 4 megapixel resolution with real-world lighting and physics to eliminate that â€œAI lookâ€ that undermines visual fidelity. The models add direct pose control to explicitly specify the pose of a subject or character in an image, as well as deliver clean, readable text across infographics, user interface screens and even multilingual content. Plus, the new multi-reference feature enables artists to select up to six reference images where the style or subject stays consistent â€” eliminating the need for extensive model fine-tuning. Stunning, photorealistic details. Image courtesy of Black Forest Labs. For a complete overview of new FLUX.2 features, read Black Forest Labsâ€™ blog . Optimized for RTX The new FLUX.2 models are impressive, but also quite demanding. They run a staggering 32-billion-parameter model requiring 90GB VRAM to load completely. Even using lowVRAM mode â€” a popular setting that allows artists to only load the active model at a time â€” the VRAM requirement is still 64GB, which puts the model virtually out of reach for any consumer card to use effectively. To broaden FLUX.2 model accessibility, NVIDIA and Black Forest Labs collaborated to quantize the model to FP8 â€” reducing the VRAM requirements by 40% at comparable quality. FLUX.2 is here. And to make this model accessible on GeForce RTX GPUs, NVIDIA has partnered with ComfyUI â€” a popular application to run visual generative AI models on PC â€” to improve the appâ€™s RAM offload feature, known as weight streaming. Using the upgraded feature, users can offload parts of the model to system memory, extending the available memory on their GPUs â€” albeit with some performance loss, as system memory is slower than GPU memory. NVIDIA has also been collaborating with ComfyUI to optimize model performance on NVIDIA and GeForce RTX GPUs, including optimizations for FP8 checkpoints. Get started with FLUX.2 today. Update ComfyUI and check out the FLUX.2 templates, or visit Black Forest Labsâ€™ Hugging Face page to download the model weights. Plug in to NVIDIA AI PC on Facebook , Instagram , TikTok and X â€” and stay informed by subscribing to the RTX AI PC newsletter . Follow NVIDIA Workstation on LinkedIn and X . Categories: Generative AI Tags: Artificial Intelligence | Conversational AI | Creators | GeForce | NVIDIA RTX | Rendering | RTX AI Garage]]></description>
      <author>NVIDIA</author>
      <pubDate>Tue, 25 Nov 2025 15:53:21 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/rtx-ai-garage-flux-2-comfyui/</guid>
    </item>
    <item>
      <title>AI On: 3 Ways Specialized AI Agents Are Reshaping Businesses</title>
      <link>https://blogs.nvidia.com/blog/specialized-ai-agents/</link>
      <description><![CDATA[Editorâ€™s note: This post is part of the AI On blog series, which explores the latest techniques and real-world applications of agentic AI, chatbots and copilots. The series also highlights the NVIDIA software and hardware powering advanced AI agents, which form the foundation of AI query engines that gather insights and perform tasks to transform everyday experiences and reshape industries. As agentic AI adoption continues to grow, with open-source models and tools maturing, companies across industries are increasingly asking: what AI agents should we build to solve our unique business challenges? Although faster outcomes are a core benefit of using AI, organizations are finding that specialization is the key to business impact and long-term AI adoption. Rather than relying on one-size-fits-all models and services, leading companies are developing specialized AI agents designed to understand and act within the needs of a specific use case. CrowdStrike, PayPal and Synopsys are examples of companies combining NVIDIA Nemotron open foundation models with their proprietary data and institutional knowledge to create specialized applications. The results are intelligent agents that have the level of expertise required to work alongside human colleagues and boost business operations. 1. CrowdStrike Defends Against Modern Cyber Threats In cybersecurity, speed and precision are essential, especially as cyber threats become more advanced and grow to larger scales. To meet these rapidly evolving digital threats, CrowdStrike is building specialized AI agents that can work alongside security teams through Charlotte AI AgentWorks. These agents, powered by NVIDIA Nemotron open models and NVIDIA NIM microservices, automate high-volume tasks such as alert triage and remediation, allowing human analysts to focus on higher-order decision-making. Built on open models and continuously trained by incident responders, CrowdStrikeâ€™s Agentic Security Platform increases accuracy of alert triage from 80% to 98.5% , reducing security analyst teamsâ€™ manual effort tenfold. The platform can adapt to new risks and collaborates across the security operations center. 2. PayPalâ€™s AI Agents Power Frictionless Commerce at Scale PayPal, a leader in payments and e-commerce, is building agent-driven infrastructure to accelerate intelligent commerce . The companyâ€™s specialized AI agents, developed on Nemotron open models, will enable the first wave of conversational commerce experiences, where agents can shop, buy and pay on a userâ€™s behalf. With this approach, PayPal built a fine-tuning pipeline in two weeks and reduced latency by nearly 50% while maintaining the high accuracy required to serve its 430 million customers and 30 million merchants. PayPalâ€™s agents rely on open, modular models that are fine-tuned specifically for payments and commerce, giving the company the control to balance performance, accuracy and cost at a massive scale. 3. Synopsys Advances Agentic AI for Chip Design Workflows The complexity of modern semiconductor design and manufacturing calls for expertise, precision and speed. Synopsys is pioneering an agentic AI framework that can be deployed throughout the chip development workflow. Synopsysâ€™ vision for agentic AI includes Synopsys AgentEngineer technology that can significantly boost productivity in research and development, identifying critical design bugs and helping reduce costly delays that traditional techniques can miss. In early trials of a formal verification workflow, Synopsys AI agents running on NVIDIA accelerated infrastructure achieved a 72% boost in productivity. Using open models fine-tuned for each engineering task, as well as software like the NVIDIA NeMo Agent Toolkit and Blueprints, Synopsys is enabling a new frontier of AI-enabled chip design. Building Specialized AI Agents With NVIDIA Technologies Companies across industries are taking the following steps to transform their proprietary knowledge into specialized AI agents: Evaluate open models, like NVIDIA Nemotron , that provide a powerful building block to create specialized models for any domain. Curate, generate and secure domain data using NVIDIA NeMo for agent lifecycle management. Create specialized agents using customized models that have access to proprietary data. Continue to fine-tune agents over time with a data flywheel . Learn how NVIDIA Nemotron can help businesses build specialized AI agents for maximum productivity and return on investment. Categories: Data Center | Generative AI Tags: Agentic AI | AI On | Artificial Intelligence | Cybersecurity | Financial Services | Industrial and Manufacturing | Nemotron | NVIDIA Blueprints | NVIDIA NeMo | Simulation and Design]]></description>
      <author>NVIDIA</author>
      <pubDate>Mon, 24 Nov 2025 17:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/specialized-ai-agents/</guid>
    </item>
    <item>
      <title>Into the Omniverse: How Smart City AI Agents Transform Urban Operations</title>
      <link>https://blogs.nvidia.com/blog/smart-city-ai-agents-urban-operations/</link>
      <description><![CDATA[Editorâ€™s note: This post is part of Into the Omniverse , a series focused on how developers, 3D practitioners and enterprises can transform their workflows using the latest advancements in OpenUSD and NVIDIA Omniverse . Cities worldwide face unprecedented challenges as urban populations surge and infrastructure strains to keep pace. Operational challenges like traffic congestion and coordinating emergency services are compounded by fragmented data pipelines, siloed local government processes and disparate systems. Technical barriers prevent cities from accessing the comprehensive, real-time insights needed for effective decision-making and city management. Leading cities and technology partners are deploying the NVIDIA Blueprint for smart city AI , a reference application that provides the complete software stack to build, test and operate AI agents in simulation-ready ( SimReady ) digital twins. OpenUSD is an open and extensible framework that connects to each stage of this physical AI workflow. OpenUSD-enabled digital twins serve as SimReady environments where cities can simulate â€œwhat ifâ€ scenarios and generate physically accurate sensor data. The blueprint powers a three-stage workflow: 1) simulate with the NVIDIA Cosmos platform and NVIDIA Omniverse libraries to generate synthetic data, 2) train and fine-tune vision AI models, and 3) deploy real-time video analytics AI agents with the NVIDIA Metropolis platform and the NVIDIA Blueprint for video search and summarization (VSS). This enables cities to move from reactive to proactive operations.â€‹ Based on these simulations, cities can deploy operational platforms where weather data, traffic sensors and emergency response systems converge, supporting rapid testing of rare scenarios, real-time monitoring, city infrastructure planning and optimization of urban systems. From Kaohsiung City, Taiwan, cutting incident response times by 80% with street-level AI to Raleigh, North Carolina, achieving 95% vehicle detection accuracy and French rail networks optimizing energy consumption by 20%, cities across the globe are using digital twins and AI agents to transform urban operations at scale. Smart Cities in Action Akila, With SNCF Gares&Connexions, Uses Digital Twins to Improve Rail Operations Akilaâ€™s digital twin application helps French rail operator SNCF Gares&Connexions optimize its network of nearly 14,000 daily trains with live scenario planning for solar heating, air flow and crowd movement. The OpenUSD-enabled digital twins deliver a 20% reduction in energy consumption, 100% on-time preventive maintenance and a 50% reduction in downtime and response times. Linker Vision Taps Physical AI for Street-Level Intelligence Linker Visionâ€™s physical AI system recognizes infrastructure events in Kaohsiung City, including damaged streetlights and fallen trees, eliminating manual city inspections and enabling faster emergency response. To scale its street-level intelligence to more cities, Linker Vision uses Omniverse libraries for simulation, Cosmos Reason for world understanding and the VSS blueprint for deployment powered by OpenUSD. Esri and Microsoft Enable Comprehensive Urban Intelligence in the City of Raleigh The City of Raleigh achieved 95% vehicle detection accuracy using the NVIDIA DeepStream software development kit, boosting traffic analysis workflows for engineers. This data enhances Raleighâ€™s digital twin, enabled by Esriâ€™s ArcGIS geospatial platform to support visualization and analysis for critical infrastructure planning and management. Integrating this computer vision pipeline with a vision AI agent powered by the NVIDIA VSS blueprint provides comprehensive real-time visibility and insights in ArcGIS on Azure Cloud. Milestone Systemsâ€™ VLM Automates Video Review Milestone Systems is soon launching its Hafnia VLM, which will include a VLM plug-in for its video management software XProtect as well as a VLM-as-a-service. Fine-tuned on more than 75,000 hours of video data, the Hafnia VLM can reduce operator alarm fatigue by up to 30% by automating video review and filtering out false alarms. It was developed with NVIDIA Cosmos Reason VLMs and Metropolis. The Hafnia VLM plug-in for XProtect will make generative AI more easily accessible for XProtect operators and users. K2K Analyzes Italy Video Streams K2Kâ€™s platform uses NVIDIA Cosmos Reason and the VSS blueprint to analyze over 1,000 video streams in Palermo, Italy, processing 7 billion events annually and automatically notifying city officials through natural language queries and video events when critical conditions are extracted and analyzed. Learn more about how cities are transforming with simulation, vision AI and digital twins by watching this on-demand NVIDIA GTC session, â€œ Leadership Strategies to Transform Public Services .â€ Get Started With Smart City AI Learn more about OpenUSD and computer vision workflows through these resources: Watch this video on bringing physical AI to cities with the NVIDIA Blueprint for smart city AI. Read this technical blog on how to integrate computer vision pipelines with generative AI and reasoning with the VSS blueprint. Access step-by-step intelligent traffic system workflows and technical recipes in new cookbooks for NVIDIA Cosmos Predict , NVIDIA Cosmos Transfer and NVIDIA Cosmos Reason . Stay up to date by subscribing to NVIDIA Omniverse news , joining the Omniverse community and following Omniverse on Discord , Instagram , LinkedIn , Threads , X and YouTube . Categories: Generative AI | Pro Graphics Tags: Agentic AI | Artificial Intelligence | Computer Vision | Cosmos | DeepStream | Digital Twin | Into the Omniverse | Metropolis | Mobility | NVIDIA Blueprints | Omniverse | Physical AI | Simulation and Design | Smart Spaces | Synthetic Data Generation | Universal Scene Description | Visual Computing]]></description>
      <author>NVIDIA</author>
      <pubDate>Thu, 20 Nov 2025 16:00:39 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/smart-city-ai-agents-urban-operations/</guid>
    </item>
    <item>
      <title>The Largest Digital Zoo: Biology Model Trained on NVIDIA GPUs Identifies Over a Million Species</title>
      <link>https://blogs.nvidia.com/blog/bioclip2-foundation-ai-model/</link>
      <description><![CDATA[Tanya Berger-Wolfâ€™s first computational biology project started as a bet with a colleague: that she could build an AI model capable of identifying individual zebras faster than a zoologist. She won. Now, the director of the Translational Data Analytics Institute and a professor at The Ohio State University, Berger-Wolf is taking on the whole animal kingdom with BioCLIP 2 , a biology-based foundation model trained on the biggest, most diverse dataset of organisms to date. The model will be showcased at this yearâ€™s NeurIPS AI research conference. BioCLIP 2 goes beyond extracting information from images. It can distinguish speciesâ€™ traits and determine inter-and intraspecies relationships. For example, the model arranged Darwinâ€™s finches by beak size, without teaching the concept of size, shown in the image below. Scatter plot shows how BioCLIP 2 arranges Darwinâ€™s finches by beak size from left to right. These capabilities will allow researchers to use the model as both a biological encyclopedia, a powerful scientific platform and an interactive research tool with inference capabilities to help address an ongoing issue in conservation biology: data deficiency for certain species. â€œFor iconic species like killer whales, we lack enough data to determine population size and for polar bears, the population is unknown,â€ said Berger-Wolf. â€œIf we donâ€™t have data for those species, what hope do the beetles and fungi have?â€ AI models can enhance existing conservation efforts for threatened species and their habitats by filling this data-deficiency gap. BioCLIP 2 is available under an open-source license on Hugging Face , where it was downloaded over 45,000 times last month. This paper builds on the first BioCLIP model, released over a year ago, which was also trained on NVIDIA GPUs and received the Best Student Paper award at the Computer Vision and Pattern Recognition (CVPR) conference. The BioCLIP 2 paper will be presented at NeurIPS, taking place Nov. 30-Dec. 5 in Mexico City, and Dec. 2-7 in San Diego. Building the Worldâ€™s Biggest Biological Flash Card Deck The project began with the compilation of a massive dataset, TREEOFLIFE-200M , which comprises 214 million images of organisms that span over 925,000 taxonomic classes â€” from monkeys to mealworms and magnolias. To curate this vast amount of data, Berger-Wolfâ€™s team at the Imageomics Institute collaborated with the Smithsonian Institution , experts from various universities and other field-related organizations. These researchers set out to discover what would happen if they trained a biology model on more data than ever. The team wanted to see if it was possible to move â€œbeyond the science of individual organisms to the science of ecosystems,â€ said Berger-Wolf. After 10 days of training on 32 NVIDIA H100 GPUs, BioCLIP 2 displayed novel abilities, such as distinguishing between adult and juvenile as well as male and female animals within species â€” without being explicitly taught these concepts. It also made associations between related species â€” like understanding how zebras relate to other equids. â€œThis model learns that at every level of taxonomy, all of these images of zebras have a particular genus label, and of these images of equids â€” including zebras, horses and donkeys â€” they have a particular family trait and so on,â€ she said. â€œIt learns the hierarchy without ever being told it, just through these associations.â€ The model can even determine the health of an organism based on training data. For example, it separated healthy apple or blueberry leaves from diseased leaves, as well as could recognize differing types of diseases, when generating the scatter plot below. The scatter plots show plant species better separated as the model is trained. The intra-species variations also form clusters, making them easier to separate. Berger-Wolfâ€™s team used a cluster of 64 NVIDIA Tensor Core GPUs to accelerate model training, plus individual Tensor Core GPUs for inference . â€œFoundation models like BioCLIP would not be possible without NVIDIA accelerated computing,â€ said Berger-Wolf. Wildlife Digital Twins: The Future of Studying Ecosystem Relationships The researchersâ€™ next endeavor is to develop a wildlife-based interactive digital twin that can be used to visualize and simulate ecological interactions between species as well as their ways of engaging with the environment. The goal is to provide a safe, easy way to study organismal relationships that naturally occur in the wild, while minimizing impact and disturbance on ecosystems. â€œThe digital twin allows us to visualize species interactions and put them in context, as well as to play the what-if scenarios and test our models without destroying the actual environment â€” creating as light a footprint as possible,â€ said Berger-Wolf. The digital twin will give scientists the opportunity to explore the points of view of the species theyâ€™re studying within the simulated environment, opening endless possibilities for more complex and accurate ecological research. Eventually, versions of this technology could even be deployed for public use â€” such as through interactive platforms at zoos. People could explore, visualize and learn about the natural environment and its many species from entirely new vantage points. â€œIâ€™m getting goosebumps just imagining that scenario of a kid coming into the zoo and being like, wow â€” this is what you would see if you were another zebra part of that herd, or if you were the little spider sitting on that scratching post,â€ Berger-Wolf said. Learn more about BioCLIP 2 . Categories: Generative AI | Research Tags: Artificial Intelligence | Education | Science]]></description>
      <author>NVIDIA</author>
      <pubDate>Thu, 20 Nov 2025 14:00:17 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/bioclip2-foundation-ai-model/</guid>
    </item>
    <item>
      <title>Powering AI Superfactories, NVIDIA and Microsoft Integrate Latest Technologies for Inference, Cybersecurity, Physical AI</title>
      <link>https://blogs.nvidia.com/blog/nvidia-microsoft-ai-superfactories/</link>
      <description><![CDATA[Timed with the Microsoft Ignite conference running this week, NVIDIA is expanding its collaboration with Microsoft, including through the adoption of next-generation NVIDIA Spectrum-X Ethernet switches for the new Microsoft Fairwater AI superfactory, powered by the NVIDIA Blackwell platform. The collaboration brings new integrations across Microsoft 365 Copilot, as well as the public preview of next-generation Azure NC Series VMs powered by NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs , NVIDIA Nemotron integrations to accelerate AI for Microsoft SQL Server 2025, capabilities for onboarding AI agents in Microsoft 365 and optimizations for high-performance inference, cybersecurity and physical AI. Microsoftâ€™s AI Superfactory connects the landmark Fairwater data center in Wisconsin with a new, state-of-the-art facility in Atlanta , Georgia. This massive-scale infrastructure will integrate hundreds of thousands of NVIDIA Blackwell GPUs for large-scale training. In addition, Microsoft is deploying more than 100,000 Blackwell Ultra GPUs in NVIDIA GB300 NVL72 systems being deployed globally for inference. â€œOur collaboration with NVIDIA is built on driving innovation across the entire system and full stack, from silicon to services,â€ said Nidhi Chappell, corporate vice president of product management at Microsoft. â€œBy coupling Microsoft Azureâ€™s unmatched data center scale with NVIDIAâ€™s accelerated computing, we are maximizing AI data center performance and efficiency, which is of paramount importance for our customers leading the new AI era.â€ The most demanding workloads for OpenAI, the Microsoft AI Superintelligence Team, Microsoft 365 Copilot and Microsoft Foundry services will be powered by this infrastructure. Customers like Black Forest Labs are also using NVIDIA GB200 NVL72 systems to train next-generation multimodal FLUX models that power visual intelligence. To connect this massive infrastructure, Microsoft is deploying next-generation NVIDIA Spectrum-X Ethernet switches in its Fairwater AI data center â€” the largest and most sophisticated AI factories ever built â€” delivering the performance, scale and efficiency required for OpenAI to run large-scale AI models and applications. New Azure NCv6 Series VMs with NVIDIA RTX PRO 6000 Blackwell GPUs are now in public preview on Azure, expanding the Blackwell platform to provide right-sized acceleration for multiple workloads including multimodal agentic AI, industrial digitalization with NVIDIA Omniverse libraries, scientific simulation and visual computing. This flexibility extends from the cloud to the edge with Azure Local , enabling powerful sovereign AI solutions while bringing low-latency, real-time AI to wherever data needs to reside. This allows enterprises to seamlessly develop, deploy and manage AI-powered digital twins and generative AI applications with NVIDIA RTX PRO 6000 Blackwell GPUs from the Azure cloud directly to their factory floors, on-premises data centers or secure edge locations. Software Optimizations Deliver a Fungible AI Fleet The NVIDIA platform on Azure, spanning NVIDIA Blackwell and Hopper GPUs, accelerates the latest models from the Microsoft AI Superintelligence Team, including text (MAI-1-preview), real-time voice (MAI-Voice-1) and high-fidelity image generation (MAI-Image-1) â€” bringing new multimodal experiences across Bing Image Creator and Microsoft Copilot. Central to NVIDIAâ€™s collaboration with Microsoft is building a fungible fleet â€” a flexible, continuously modernized infrastructure that can accelerate any workload with maximum efficiency. This is achieved through continuous, full-stack software optimizations that deliver compounding performance gains and maximize throughput across the entire AI lifecycle and across multiple NVIDIA architectures on Azure. The gains also extend to workloads beyond generative AI, including data processing, vector search, databases, digital twins, scientific computing and 3D design. This co-engineering saves significant costs for customers, making AI projects that were once theoretical now economically viable. For example, the continuous full-stack optimization work has directly contributed to an over 90% drop in the price of popular GPT models for end users on Azure in two years. Ongoing optimization work now extends to Microsoft Foundry , where the NVIDIA TensorRT-LLM library helps boost throughput, reduce latency and lower costs for a wide range of popular open models. NVIDIA and Microsoft have also partnered to optimize their fleet for AI workload performance through the NVIDIA DGX Cloud Benchmarking suite. Engineering teams from both companies worked closely together to identify bottlenecks and implement infrastructure tuning, driving performance gains. By achieving 95% of the performance possible using the NVIDIA reference architecture, Microsoft was named an Exemplar Cloud for H100 training. From Intelligent Data to AI Agents NVIDIA and Microsoft are integrating AI into the core of the enterprise, unlocking decades of proprietary data stored in one of the worldâ€™s most trusted databases. NVIDIA is accelerating AI in the new Microsoft SQL Server 2025 by integrating it with NVIDIA Nemotron open models and NVIDIA NIM microservices. This solution delivers GPU-optimized, secure and scalable retrieval-augmented generation directly where enterprise data lives, in the cloud or on premises. Plus, the collaboration extends to the new frontier of agentic AI in the workplace. The NVIDIA NeMo Agent Toolkit now connects with Microsoft Agent 365 , enabling developers to build, deploy and onboard compliant, enterprise-ready AI agents directly into the Microsoft 365 app ecosystem, including Outlook, Teams, Word and SharePoint. To power these new enterprise agents, Microsoft Foundry now offers NVIDIA Nemotron models for digital AI and NVIDIA Cosmos models for physical AI as secure NIM microservices. Developers can use them to build enterprise-grade agentic AI for a vast range of applications that benefit from multimodal intelligence, multilingual reasoning, math, coding and physical AI capabilities. The collaboration is also tackling cyber threats for enterprises. Microsoft and NVIDIA are collaborating on research for new adversarial learning models , built on the NVIDIA Dynamo-Triton framework and the NVIDIA TensorRT suite of tools, that can help enterprises defend against real-time cybersecurity threats with a 160x performance speedup compared with CPU methods. Physical AI and Industrial Digitalization NVIDIA and Microsoft are building the future of physical AI . With NVIDIA Omniverse libraries available on Microsoft Azure, NVIDIA is unlocking end-to-end reindustrialization in the cloud through its developer ecosystem. Developers are transforming industrial workflows, from computer-aided engineering with Synopsys to factory operations with Sight Machine and SymphonyAI . Robotics developers can tap into the NVIDIA Isaac Sim open-source robotics simulation framework to unlock critical workflows, from synthetic data generation to software-in-the-loop testing for all types of robot embodiments. Hexagon is building its AEON humanoid robot primarily using NVIDIAâ€™s full robotics stack on Azure. Similarly, the robotics platform, Wandelbots NOVA , running on Azure integrates Isaac Sim and Isaac Lab to simplify and speed up simulation to real-world deployment. In addition, NVIDIA and Microsoft are using a standardized approach for digital engineering to enable seamless OpenUSD interoperability across 3D workflows, making simulation and digital content creation accessible in the cloud. This expanded collaboration comes on the heels of a partnership announced with Anthropic and Microsoft earlier today. NVIDIA and Anthropic will collaborate on design and engineering to optimize Anthropic models for performance, efficiency and total cost of ownership, as well as optimize future NVIDIA architectures for Anthropic workloads. Learn more about NVIDIA and Microsoftâ€™s collaboration and sessions at Microsoft Ignite . Categories: Cloud | Data Center | Generative AI | Hardware | Networking | Robotics | Software Tags: Agentic AI | Artificial Intelligence | Cosmos | DGX Cloud | Digital Twin | Industrial and Manufacturing | Nemotron | NVIDIA Blackwell | NVIDIA Isaac Sim | NVIDIA NeMo | NVIDIA NIM | NVIDIA Omniverse | NVIDIA RTX | NVIDIA Spectrum-X]]></description>
      <author>NVIDIA</author>
      <pubDate>Tue, 18 Nov 2025 20:00:22 GMT</pubDate>
      <guid isPermaLink="true">https://blogs.nvidia.com/blog/nvidia-microsoft-ai-superfactories/</guid>
    </item>
  </channel>
</rss>
