<?xml version="1.0" ?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>ElevenLabs Blog</title>
    <link>https://elevenlabs.io/blog</link>
    <description><![CDATA[Latest updates from ElevenLabs]]></description>
    <language>en-US</language>
    <lastBuildDate>Sun, 14 Dec 2025 10:04:37 GMT</lastBuildDate>
    <generator>rfeed v1.1.1</generator>
    <docs>https://github.com/svpino/rfeed/blob/master/README.md</docs>
    <item>
      <title>ElevenLabs Welcomes Matthew McConaughey as New Investor</title>
      <link>https://elevenlabs.io/blog/elevenlabs-welcomes-matthew-mcconaughey-as-new-investor</link>
      <description><![CDATA[At ElevenLabs’ inaugural Summit, the company revealed thatAcademy Award-winning actor Matthew McConaughey has been a part of ElevenLabs story for years– as an investor, early supporter, and now, as a creator. In a video played at the Summit, Matthew McConaughey shared that his newsletter,Lyrics of Livin’, is expanding with a Spanish language version – powered by ElevenLabs. Now, Matthew’s stories and content will be made available in Spanish audio, using his unmistakable voice, and reaching an even wider audience. Subscribe here:https://lyricsoflivin.com/hola “I’m proud to share that I’ve been an investor in ElevenLabs for several years now,” said Matthew McConaughey. “It’s been amazing to see the growth from those early days to where the company, and the technology, is now. What’s remained constant is theextraordinary storytelling capabilities and creative potentialthat ElevenLabs unlocks – something that stood out to me from the start and that speaks to me as a professional storyteller.” “When I first met Matthew, I was struck by how genuinely he connected with our vision and what we’re trying to do at ElevenLabs,” addedMati Staniszewski, CEO and Co-Founder of ElevenLabs. “He wasn’t just excited by the tech – he understood what we’re aiming to achieve creatively. We’re so grateful for his continued insight and support, especially as we expand our work in the creative space.” [To see more highlights from the ElevenLabs Summit, visit:https://summit.elevenlabs.io/]]]></description>
      <pubDate>Fri, 12 Dec 2025 18:05:38 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/elevenlabs-welcomes-matthew-mcconaughey-as-new-investor</guid>
    </item>
    <item>
      <title>Introducing Eleven v3 (alpha)</title>
      <link>https://elevenlabs.io/blog/eleven-v3</link>
      <description><![CDATA[We're pleased to revealEleven v3 (alpha)— the most expressive Text to Speech model. This research preview brings unprecedented control and realism to speech generation with: 70+ languages Multi-speaker dialogue Audio tagslike [excited], [whispers], and [sighs] Eleven v3 (alpha) requires moreprompt engineeringthan previous models — but the generations are breathtaking. If you’re working on videos, audiobooks, or media tools — this unlocks a new level of expressiveness. For real-time and conversational use cases, we recommend staying with v2.5 Turbo or Flash for now. A real-time version of v3 is in development. Eleven v3 is available today on our website and in theAPI. Why we built v3 Since launching Multilingual v2, we’ve seen voice AI adopted in professional film, game development, education, and accessibility. But the consistent limitation wasn’t sound quality — it wasexpressiveness. More exaggerated emotions, conversational interruptions, and believable back-and-forth were difficult to achieve. Eleven v3 addresses this gap. It was built from the ground up to deliver voices that sigh, whisper, laugh, and react — producing speech that feels genuinely responsive and alive. What’s new in Eleven v3 (alpha) Hear v3 for yourself Using audio tags Audio tags live inline with your script and are formatted with lowercase square brackets. You can see more about audio tags in ourprompting guide for v3 in the docs. Professional Voice Clones (PVCs) are currently not fully optimized for Eleven v3, resulting in potentially lower clone quality compared to earlier models. During this research preview stage it would be best to find an Instant Voice Clone (IVC) or designed voice for your project if you need to use v3 features. PVC optimization for v3 is coming in the near future. For example, you could prompt: “[whispers] Something’s coming… [sighs] I can feel it.” Or for more expressive control, you can combine multiple tags: Crafting multi-speaker dialogue Eleven v3 is supported in our existing Text to Speech endpoint. Additionally, we introduce a newText to Dialogue API endpoint. Provide a structured array of JSON objects — each representing a speaker turn — and the model generates a cohesive, overlapping audio file: The endpoint automatically manages speaker transitions, emotional changes, and interruptions. Learn morehere. v3 is our most expressive model Pricing and availability To enable v3: Use theModel Pickerand selectEleven v3 (alpha) API access and support in Studio are coming soon. For early access, pleasecontact sales. When not to use v3 Eleven v3 (alpha) requires more prompt engineering than our previous models. When it works the output is breathtaking but the reliability and higher latency means it’s not suitable for real-time and conversational use cases. For these, we recommend Eleven v2.5 Turbo/Flash. For more, refer to the fullv3 documentationand FAQ. Try it today Log in toElevenLabs UI Select v3 (alpha)in the model dropdown Paste your script — use tags or dialogue Generate audio We’re excited to see how you bring v3 to life across new use cases — from immersive storytelling to cinematic production pipelines. How does the Eleven v3 80% discount work? How were the samples in the video and website generated? How does dialogue generation work? Is this available over API? What audio tags are supported? What languages does it support?]]></description>
      <pubDate>Fri, 12 Dec 2025 14:09:10 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/eleven-v3</guid>
    </item>
    <item>
      <title>Introducing Scribe v2 Realtime</title>
      <link>https://elevenlabs.io/blog/introducing-scribe-v2-realtime</link>
      <description><![CDATA[Scribe v2 Realtime: the most accurate model for live transcription Scribe v2 Realtime sets a new standard for low-latencySpeech to Text. Designed for live use cases—voice agents, meeting assistants, and real-time captioning—it transcribes speech in under 150 ms across English, French, German, Italian, Spanish, and Portuguese, and 90 languages. Scribe v2 Realtime is specifically built for agentic use cases. On 500 hard samples containing background noise and complex information, it significantly outperforms all other models. Key features Negative latency:Next word and punctuation prediction Automatic language detection:Speak in any language, switch language mid conversation Text conditioning: Scribe v2 Realtime continues the transcription based on the previous batch, useful when restarting a connection Voice Activity Detection(VAD) Manual commit: Full control over when to finalize transcript segments Multiple audio formats: Support for PCM (48kHz) and μ-law encoding Enterprise readywith SOC 2, ISO 27001, PCI DSS L1, HIPAA, and GDPR compliance, EU and India data residency options and Zero retention mode for sensitive workloads Scribe v2 Realtime delivers human-level understanding in real time, enabling natural conversation and immediate response in live environments. Scribe v2 Realtime achieves 93.5% accuracy across 30 commonly used European and Asian languages. Build with the API Scribe v2 Realtime is available today through the ElevenLabs API. Explore the documentation:https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming Use Scribe v2 Realtime in ElevenLabs Agents Deploy natural, human-sounding agents powered by Scribe v2 Realtime. Build voice assistants for support, sales, or in-product experiences that can understand and respond in real time. Learn more:https://elevenlabs.io/agents Start building today Use Scribe v2 Realtime through our API or directly within ElevenLabs Agents. Sign up here:https://elevenlabs.io/app/sign-up]]></description>
      <pubDate>Thu, 11 Dec 2025 21:03:00 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/introducing-scribe-v2-realtime</guid>
    </item>
    <item>
      <title>Eleven Music is Here</title>
      <link>https://elevenlabs.io/blog/eleven-music-is-here</link>
      <description><![CDATA[Today, we launchedEleven Music– the next step on our mission to build the most comprehensive AI audio platform in the world. With Eleven Music, businesses, creators, artists, and every single one of our users can generate studio-grade music from natural language prompts, with: - Complete control over genre, style, and structure - Vocals or just instrumental - Multi-lingual, including English, Spanish, German, Japanese and more - Edit the sound and lyrics of individual sections or the whole song A few of our favorite samples Check out a few of our favorite songs generated by the ElevenLabs team thus far: Echoes of Midnight Prompt: “Dreamy, psychedelic, slow Indie Rock, reverb-soaked vocals, retro keys, catchy chorus, analog, phased guitars, liminal, nostalgic feeling, anthem.” Saddles and Shadows Prompt: “An epic track for a cowboy show, wild west, cinematic sound design, guitar twanging with awesome orchestral elements crescendoing to a powerful finale, soundtrack.” Don’t Let Me Go Prompt: “A very retro track from the 1950s with an old crooner male vocalist, charming, vintage, classic, nostalgic, golden oldies, vinyl crackle, catchy vocal hooks.” Obsidian Prompt: “Extremely dark, tense and powerful, cinematic sound design, electronic hybrid, trailer music, evil, braam, braam horns, impacts, boom, rising tension, completely instrumental.” Wanderer of the Moor Prompt: “A young english girl singing an old english folk song, stunning, lonely, thoughtful and almost haunting, fiddle and english folk instrumentation, reverb, short song.” Yellow Bus Jam Jam band song about driving through new york city in a big yellow school bus with 2 long guitar solos and lots of harmonizing We can’t wait to see what you create. Commercial use Created in collaboration with labels, publishers, and artists, Eleven Music is cleared for nearly all commercial uses, from film and television to podcasts and social media videos, and from advertisements to gaming. For more information on supported usage across our different plans,head here. Eleven Music is available today on our website and public API access (please seeeleven music API documentation), with public API access and integration into ourConversational AIplatform coming soon. Check out ourprompt engineering guideto help you master the full range of the model’s capabilities.]]></description>
      <pubDate>Wed, 10 Dec 2025 22:17:45 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/eleven-music-is-here</guid>
    </item>
    <item>
      <title>Introducing ElevenLabs UI: Open-source audio &amp; agent components for the web</title>
      <link>https://elevenlabs.io/blog/elevenlabs-ui</link>
      <description><![CDATA[ElevenLabs UIis a new open source library of customizable React components for building interfaces with theElevenLabs Agents& Audio SDKs. Built onshadcn/ui, it provides full control over UI primitives like waveforms, orbs, messages & more. Examples transcriber-01- An open-source voice dictation component you can drop into any web app: voice-chat-03- a rich multimodal chat interface with state management built in. Pass your Elevenlabs Agent ID as a prop and ship it: Getting started Components are available via the@elevenlabs/agents-clicommand. For example, to install theOrbcomponent, you can run: Read the docsand start building better agent & audio interfaces, faster.]]></description>
      <pubDate>Mon, 01 Dec 2025 12:41:27 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/elevenlabs-ui</guid>
    </item>
    <item>
      <title>Deliveroo partners with ElevenLabs to enhance rider and restaurant experience</title>
      <link>https://elevenlabs.io/blog/deliveroo</link>
      <description><![CDATA[Deliveroo’s mission is to transform the way people shop and eat - bringing the neighbourhood to their doors by connecting consumers, restaurants, shops, and riders. Operating one of Europe’s largest on-demand delivery networks, with millions of consumers and more than 176,000 local businesses, Deliveroo is focused on maintaining service quality at scale through constant communication across its network. To support rapid growth across multiple markets and languages, Deliveroo’s teams continually explore new innovations to improve the experience for riders, partners, and consumers. With teams operating across multiple regions and languages, Deliveroo was looking for a way to improve the rider onboarding process, and to help restaurants maximise orders, while maintaining accuracy and trust. Improving rider onboarding and engagement As Deliveroo scales, streamlining rider onboarding is essential in order to meet demand whilst delivering a consistent and high-quality user experience. Deliveroo’s rider onboarding process includes several steps that help ensure applicants are verified and ready to begin delivering. However, Deliveroo found that a portion of applicants tended to drop off before completing the onboarding, and subsequent outreach to re-engage these riders was time-intensive and inconsistent across regions. To address this issue, Deliveroo deployed an ElevenLabs Agent to automatically contact rider applicants who had been inactive for more than two weeks. The voice agent confirmed the applicant’s continued interest and guided them through the next steps to help them complete onboarding in their preferred language. The results in the first few weeks of deployment showed a substantial increase in engagement and throughout: The agent reached the majority of the target cohort via call or voicemail. 30% of riders confirmed their intent to continue onboarding and continued their application within seven days of the call. By leveraging agentic support, Deliveroo reached thousands of riders in hours instead of days or weeks. This reduced manual workload for local operations teams allowing them to focus on more strategic work like unique edge cases where they could offer more personalized support, and improved overall rider activation rates. Helping maximize restaurant orders Deliveroo’s operations teams manage a large and varied network of restaurant partners. Maintaining accurate live status data for each restaurant is critical to ensuring reliable consumer experiences and efficient rider allocation. Traditionally, this process required restaurant support teams to make thousands of calls each week to verify whether or not restaurants reported as “closed” by riders were, in fact, operational. To streamline this process and help businesses maximize orders during opening hours, Deliveroo deployed an ElevenLabs Agent to automatically confirm the live status of restaurants flagged as potentially closed. The agent placed outbound calls, validated opening hours, and updated Deliveroo’s systems in real time. Over the evaluation period, ElevenLabs Agents achieved a 75% success rate in reaching restaurants by phone using a voice agent to verify operating hours. This eliminated the need for thousands of manual check-ins and enabled Deliveroo to monitor the network’s live status in a fraction of the time previously required, enabling the team to focus on higher-impact operational tasks. The Deliveroo team highlighted how impressed they were with ElevenLabs agents platform ability to achieve their goals: Expanding Rider Check-In (RCI) tag activation Following the success of its other pilots, Deliveroo extended its partnership with ElevenLabs to drive partner activation of Rider Check-In (RCI) tags - a key operational tool to streamline order handover between restaurants and riders. Together we developed an ElevenLabs Agent that would proactively contact sites that had not activated tags after five business days of delivery, with the goal of guiding managers through installation and activation steps. In early results, Deliveroo’s ElevenLabs Agent was able to successfully contact 86% of partner sites, helping to drive meaningful increases in activation. By automating these interactions, Deliveroo was able to improve partner communications and the overall consumer experience through faster, more reliable deliveries. Simple setup without technical expertise Amy Marangon, Senior Manager Operations Strategy at Deliveroo, highlighted how quickly the team was able to launch multiple agents: Summary of results with ElevenLabs Agents With proven results across rider, restaurant, and partner operations, Deliveroo has demonstrated how intelligent automation can drive measurable efficiency, stronger engagement, and a better experience for riders, restaurants, and consumers alike.]]></description>
      <pubDate>Wed, 26 Nov 2025 12:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/deliveroo</guid>
    </item>
    <item>
      <title>Introducing ElevenLabs Agents</title>
      <link>https://elevenlabs.io/blog/introducing-elevenlabs-agents</link>
      <description><![CDATA[FromConversational AIto ElevenLabs Agents We’re renaming Conversational AI to ElevenLabs Agents. It’s a complete platform where you can build, launch and monitor conversational agents that talk, type and take action across phone, web and apps. ElevenLabs Agents is a better name for this. Since launch, customers have created more than 2 million agents. Together, they’ve handled over 33 million conversations this year. What makes ElevenLabs Agents different Connected to your knowledge base, tools, and telephony, our multimodal agents can manage complex workflows while maintaining enterprise-grade reliability and control. Customers are already usingElevenLabs Agentsto: Resolve customer issues Qualify leads Run outbound calling at scale Support employee learning and development Power dynamic NPCs in games Act as personal assistants or tutors Our goal is simple: make conversations with technology as natural as speaking with a person. With our audio research and orchestration platform, startups, SMBs, and enterprises can deliver personalized one-to-one interactions at scale. What’s next for ElevenLabs Agents We’re expanding the platform to give developers more control and better performance. Coming soon: Visual workflow builderto handle complex business logic Testing suiteto run simulations to ensure agents act as expected Expressive modefor more realistic voice interactions Expanded integrationswith Google Calendar, Salesforce, Zendesk, and more Build your first ElevenLabs Agent We believe conversationalvoice agentswill become a core part of how people interact with technology. With ElevenLabs Agents, you can build, deploy, and monitor them in one place. Start building today:https://elevenlabs.io/app/agents]]></description>
      <pubDate>Tue, 25 Nov 2025 21:06:53 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/introducing-elevenlabs-agents</guid>
    </item>
    <item>
      <title>Expanding access: patients and clinicians can now apply directly on the ElevenLabs website</title>
      <link>https://elevenlabs.io/blog/expanding-access-patients-and-clinicians-can-now-apply-directly-on-the-elevenlabs-website</link>
      <description><![CDATA[Patients with permanent speech loss - and their speech-language pathologists, occupational therapists, or AAC specialists - can now apply for free voice licenses directly on the ElevenLabs website through our Impact partners. How it works To begin, applicants need to create a free ElevenLabs account. After clicking on their profile photo, they will select"Apply for Impact Program,"then follow the on-screen steps to apply through the nonprofit organization that supports their region and diagnosis.Clinicianscan also apply for a free 1-year licenses by selecting "Clinicians/Staff" rather than a nonprofit organization when applying. This enables them to guide their patients through the process of creating personalized synthetic voices. There are no discount codes or credit card details required. Approved applicants receive a 5-year, extendable free license. How individuals with permanent speech loss can apply for a free voice How clinicians supporting individuals with permanent speech loss can apply for a free voice Who is eligible We partner with nonprofit organizations who help us distribute free access to ElevenLabs for individuals affected by permanent voice loss or visual impairment. Our current application partners support individuals across a range of diagnoses and regions, including: ALS/MND(USA –Bridging Voice; UK –MND Association; Australia –MND and Me,MND NSW - FlexEquip; Global –Scott-Morgan Foundation,UCL) PSP, MSA, CBD(USA/Canada –CurePSP; UK/Ireland –MSA Trust; Global –Mission MSA) Stroke(USA –Stroke Onward; New Zealand –TalkLink Trust) Tay-Sachs & SandhoffDisease (England, Wales, Northern Ireland –CATS Foundation) Head & Neck Cancer, Laryngectomy, Glossectomy(Global –Lary’s Speakeasy,TalkLink Trust) Permanent speech impairment and specific AAC users(Global –Smartbox,Jabbla,Therapy Box,Cboard,REHAVISTA,UCL) Blind and Low-Vision(USA –National Federation of the Blind) Building toward one million voices By enabling users to apply directly through the ElevenLabs website, we’re removing friction and making accessibility faster and simpler. Each improvement brings us closer to our goal of giving one million people their voices back. Note: This new workflow isonly for individuals with permanent speech loss and their clinicians, who can use it to support patients through onboarding andvoice cloning. Organizations seeking to help distribute free access to patients, especially to represent a new region or diagnosis not currently supported, should apply through our standardImpact Program Application. If your nonprofit organization would like to complete a project using ElevenLabs technology, please also applythere.]]></description>
      <pubDate>Tue, 25 Nov 2025 21:06:04 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/expanding-access-patients-and-clinicians-can-now-apply-directly-on-the-elevenlabs-website</guid>
    </item>
    <item>
      <title>Introducing ElevenLabs Image &amp; Video</title>
      <link>https://elevenlabs.io/blog/introducing-elevenlabs-image-and-video</link>
      <description><![CDATA[Today we’re introducing ElevenLabs Image & Video (Beta). The best audio, image, and video models all in one platform. Within ElevenLabs, you can now bring ideas to life in one complete creative workflow. Use leading models like Veo, Sora, Kling, Wan and Seedance to create high-quality visuals, then bring them to life with the best voices,music, andsound effectsfrom ElevenLabs. Creators, marketers, and content teams can generate images, compose clips, adjust narration, and export final content all inside a single, unified workflow. Create with leading image and video models ElevenLabs Image & Video (Beta) brings together the best models for visual creation. You can: Createstill images using leading models including Nanobanana, Flux Kontext, GPT Image, and Seedream. Usethese as storyboards, thumbnails, or as source material for video projects. Generatevideos with models including Veo, Sora, Kling, Wan, and Seedance. Refineoutputs and compose multiple clips for seamless storytelling. Upscaleyour images and videos for higher-quality results. Add lipsyncto your generated videos using ElevenLabs voices for perfectly aligned narration. Refine and edit in Studio Once your visuals are ready, export to Studio to complete your project. Studio lets you: Add expressivevoiceoversusing voices from our library or your own clones. Compose bespoke background music and layer in sound effects. Adjust timing and refine narration on a single timeline. Export polished, production-ready videos. Built for creators, marketers, and content teams Image & Video is designed for creators of every kind, from filmmakers and freelancers to marketers and educators. Whether you’re creating product videos, social content, or educational materials, ElevenLabs provides the full toolset to go from idea to final export in one platform. This launch marks a major step toward true multimodal creation, where every element — from visuals to sound — can be generated, edited, and refined together. Available in ElevenLabs Creative Platform Start creating with ElevenLabsImage & Video(Beta).]]></description>
      <pubDate>Tue, 25 Nov 2025 21:05:16 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/introducing-elevenlabs-image-and-video</guid>
    </item>
    <item>
      <title>Giving voice back to stroke survivors</title>
      <link>https://elevenlabs.io/blog/giving-voice-back-to-stroke-survivors</link>
      <description><![CDATA[Each year,more than 12 million people worldwide experience a stroke. For many, recovery involves relearning how to walk, think, and communicate. Some regain their speech fully. Others live with long-term motor-speech challenges that make verbal communication difficult or impossible. Today, on World Stroke Day, we’re proud to announce our partnership withStroke Onward. Founded by stroke survivors, Stroke Onward helps people navigate the emotional and identity challenges of rebuilding life after a stroke. Together, we aim to make voice restoration technology available to everyone who needs it, and to strengthen the community of those rebuilding life after stroke. Bringing voice restoration to the stroke survivor community Through this partnership, individuals affected by permanent speech loss can now apply for the ElevenLabs Impact Program. Approved applicants receive free access to our advancedvoice cloningandText to Speechtools, allowing them to create and use a digital voice that represents them authentically. For those living with dysarthria or other motor-speech impairments, this technology can help restore a vital part of their identity. It enables them to communicate naturally with loved ones, participate in conversations, and express themselves in their own voice. Stroke Onward Community Circle Stroke Onward has also launched theStroke Onward Community Circle (SOCC)—a free, online community where survivors, carepartners, and professionals connect around the emotional and identity sides of recovery. In a world that often focuses only on physical rehabilitation, SOCC creates space for everything else—the emotional, invisible, and deeply personal parts of rebuilding life after stroke. Members can join live events, share experiences, and access curated tools that support emotional recovery. By introducing ElevenLabs voice technology into this community, we hope to empower members to rediscover and reclaim their voices as a part of that recovery process. Our shared goal We believe everyone should have the ability to express themselves in their own voice. Partnering with Stroke Onward helps us reach people living with speech loss, ensuring that technology serves as an enabler, not a barrier, to human connection. On World Stroke Day, we’re reminded that recovery from stroke is about more than physical healing. It’s about rebuilding identity, connection, and purpose. Together with Stroke Onward, we aim to make that journey more accessible, helping survivors regain their voices and their sense of self. Learn more about the partnership and how to apply.]]></description>
      <pubDate>Tue, 25 Nov 2025 20:47:09 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/giving-voice-back-to-stroke-survivors</guid>
    </item>
    <item>
      <title>We’re partnering with Liberty Global to accelerate voice AI expansion across Europe</title>
      <link>https://elevenlabs.io/blog/liberty-global-partnership</link>
      <description><![CDATA[We’ve started a commercial partnership with Liberty Global Ventures, the technology investment arm of Liberty Global. As part of this, Liberty Global will also be making a strategic investment in ElevenLabs. Our work together will focus on howvoice AIcan make everyday interactions with technology feel more natural - especially across telecommunications and entertainment products. Liberty Global is looking at several applications of our technology - from AI-powered customer service agents that offer faster, more human support, to voice interfaces for connected TV and streaming products that make content discovery simple and intuitive. We’re also looking at new ways voice can shape customer communication and marketing. The investment was led by Rebecca Hunt, Partner at Liberty Global Ventures, based in London, and supports our continued work to scale our foundational voice model globally and bring lifelike, multilingual voice AI to more people. Our Co-Founder Mati says: “Entering a strategic partnership with Liberty Global is a welcome endorsement from one of the world’s biggest providers of connectivity services and marks a further step forward in bringing emotionally rich, lifelike voice AI to millions of households.” Rebecca Hunt, Partner, Liberty Global Ventures, adds: “Voice is becoming the next major interface for technology, and ElevenLabs is defining what’s possible in this space. The investment continues our track record of providing early backing for transformational tech infrastructure companies; we are honoured to be backing this category-defining team.” We founded ElevenLabs in 2022 to build voice AI that lets people and technology speak naturally - in every language. This partnership brings that vision closer.]]></description>
      <pubDate>Fri, 21 Nov 2025 12:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/liberty-global-partnership</guid>
    </item>
    <item>
      <title>Harvey and ElevenLabs Partner to Give Lawyers a Global Voice</title>
      <link>https://elevenlabs.io/blog/harvey</link>
      <description><![CDATA[We've partnered with Harvey, the AI legal platform used by leading law firms and enterprises, to create the first global, multilingual voice for the legal profession. Our collaboration brings spoken intelligence to law, enabling Harvey to communicate naturally in dozens of languages, dialects, or accents.Powered by ElevenLabs’Text to SpeechandSpeech to Text, Harvey will make legal knowledge more accessible and human across jurisdictions and cultures. “This partnership makes legal AI more global, accessible, and human,” said Winston Weinberg, CEO at Harvey. “With ElevenLabs, we’re ensuring every lawyer can engage with Harvey in their own language and context." “Our mission has always been to break down language barriers,” said Mati Staniszewski, CEO of ElevenLabs. “By bringing Harvey’s legal intelligence to voice, in dozens of dialects and accents, we are helping transform how law is experienced globally.” The first phase will allow Harvey to deliver answers audibly in almost any language or dialect. Future developments will introduce new features like multi-lingual voice translation, voice mode, spoken trial simulations, tone customization, and more. Together, we're are redefining how legal professionals interact with AI, with knowledge that isn’t just written, butspokenwith clarity and precision.]]></description>
      <pubDate>Wed, 12 Nov 2025 12:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/harvey</guid>
    </item>
    <item>
      <title>Honoring veterans and their voices: Lt Col Thomas Brittingham’s story</title>
      <link>https://elevenlabs.io/blog/honoring-veterans-and-their-voices-lt-col-thomas-brittinghams-story</link>
      <description><![CDATA[When Lt Col Thomas Brittingham first heard his own voice again, it was Mother’s Day and his wedding anniversary. His wife Jessi was sitting beside him when he typed out a short message using his new ElevenLabs voice: “Hey Jessi, does this sound like me? Happy Mother’s Day and Happy Anniversary. I love you.” The moment stopped her. “It brought tears to my eyes,” she recalled. “It was the most amazing gift I could have ever received—hearing his voice again.” Lt Col Thomas Brittingham A lifetime of service Lt Col Brittingham has dedicated his life to service and excellence. A 2006 graduate of the Coast Guard Academy and a 2004 Air Force Academy Exchange Cadet, he began his career aboard the Coast Guard Cutter Sequoia in Guam, where he conducted the first bilateral boardings of foreign ships in the Western Pacific. From there, his path led to commanding his own vessel, the Coast Guard Cutter Haddock, and later serving as Military Aide to the Coast Guard’s Chief Acquisition Officer, overseeing $30 billion in modernization programs. In 2011, he was selected for Air Force pilot training—a transition that would mark the next chapter in a distinguished career. Over the following decade, Lt Col Brittingham served as flight lead and mission commander across the Mediterranean, Atlantic, and Pacific. He deployed four times in support of Operation Inherent Resolve, logging nearly 1,000 combat hours. Confronting ALS In 2023, Thomas received a diagnosis that would change his life—amyotrophic lateral sclerosis (ALS). The disease began in his legs and moved upward, affecting his arms, diaphragm, and eventually his ability to speak. “His voice was always strong,” Jessi said. “Even as ALS progressed, it was something that made him feel like himself.” But as muscle weakness advanced, Thomas’s voice grew quieter until it disappeared entirely in April 2024. Without a natural voice, Thomas initially relied on a generic computer-generated one that was robotic and difficult to understand. “We depended mostly on reading his screen,” Jessi said. “It didn’t sound like him. It didn’t sound human.” Finding his voice again Through Team Gleason, a nonprofit that supports people living with ALS, Thomas connected withBridging Voice, an organization that helps individuals preserve and recreate their voices. There, he met Trinity, who guided him through the process of restoring his natural voice with ElevenLabs. Bridging Voice guided his family through the process—collecting past videos, preparing samples, and building a model of how Thomas sounded before ALS. “It was healing to go back through those clips,” Jessi said. “We watched them with our two boys, who loved hearing their dad’s voice again.” Once the recordings were submitted, the ElevenLabs team created a Professional Voice Clone for Thomas, a precise recreation of how he sounded before the disease. The moment it all came back When Thomas used his new AI voice for the first time, he chose to surprise Jessi. The words he typed carried all the warmth and cadence of his real speech. “I made him say it over and over again,” Jessi laughed. “Our family couldn’t believe how real it sounded. The boys thought it was hilarious hearing their dad’s voice saying silly things.” It wasn’t just a technological milestone, it was a return of identity, presence, and connection. “With two young children, it means everything for them to hear their dad’s voice,” Jessi said. “It keeps him present in their lives in a way that text alone can’t.” A message for Veterans Day For Lt Col Brittingham, Veterans Day carries deep meaning. It’s a reminder not only of service and sacrifice, but of the strength that comes from community and innovation. He hopes his story shows what’s possible when technology serves humanity, especially for veterans facing the challenges of illness or injury. Recent studies have shown that Air Force pilots are ten times more likely to be diagnosed with ALS than civilians. For Thomas, that statistic is personal. His experience underscores the urgency of advancing accessible technology that restores independence and dignity to those who have given so much in service. Continuing the mission TheElevenLabs Impact Programexists to help individuals like Lt Col Brittingham regain their voice and agency through AI. By combining advanced voice synthesis with human-centered design, the program ensures that every person can preserve the sound of who they are. Thomas’s journey, from commanding aircraft across the world to communicating again in his own voice, shows what this technology makes possible. When so much is taken away, being able to speak again, even through an artificial voice, gives something profoundly human back. This Veterans Day, we honor Lt Col Brittingham and all who have served, and recommit to building technology that gives them their voices back. It’s not just about speech. It’s about memory, identity, and the ability to stay connected to the people who matter most.]]></description>
      <pubDate>Tue, 11 Nov 2025 16:25:55 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/honoring-veterans-and-their-voices-lt-col-thomas-brittinghams-story</guid>
    </item>
    <item>
      <title>Building the First Agentic Government with Ukraine</title>
      <link>https://elevenlabs.io/blog/building-the-first-agentic-government-with-ukraine</link>
      <description><![CDATA[We travelled to Kyiv to deepen our partnership with the Government of Ukraine and signed a memorandum of understanding with Minister Mykhailo Fedorov to take AI public services from concept to production. The visit showed how Ukraine continues to build with purpose, clarity, and an engineering-first mindset focused on outcomes. Guided by the Ministry of Digital Transformation, we met with several ministries - Health, Education, Economy, and Foreign Affairs - each exploring how AI can make public services more efficient, accessible, and human. Ukraine is leading on that front, creating the world’s first agentic government - where AI agents work on citizens’ behalf across ministries, connecting national systems with individual needs. At the Ministry of Education, teams are developing Mriia, an app for personalised AI tutors that adapt to each learner’s knowledge and pace, and exploring agents to make educational content more accessible throughdubbingand translation. The Ministry of Economy is integrating agents into Obriy, a platform supporting businesses and gathering public feedback. In healthcare, speech technology is being used to reduce administrative work and make care more accessible. All these efforts are part of Ukraine’s plan, led by the Ministry of Digital Transformation, to become a leader in applying AI to public services by 2030. The ministry has already taken a first step with Diia.AI - the world’s first public-service agent app and platform - and we’re proud to support the ambition of making public services available through voice. Ukraine’s governance model - putting engineering at the heart of decision-making - is both natural and effective. Each ministry has its own technical team, building fast and iterating in the open. It’s a structure we relate to at ElevenLabs, where we embed engineers directly across functions to move ideas from prototype to production. The memorandum we signed marks the beginning of a shared effort to bring AI from concept to production across government. Our Forward Deployed Engineers remain in Kyiv, working alongside Ukrainian teams to turn these ideas into working systems. The main bottleneck in AI adoption has never been discovery - it’s deployment - and Ukraine is leading the way in making AI work for its people. We’re grateful to our partners - Mykhailo Fedorov, Oleksandr Bornyakov, Valeriya Ionan, Danylo Tsvok, Dmytro Ovcharenko, and Nelli Blinova - for their hospitality, openness, and collaboration. Ukraine’s pace of work is a reminder that innovation is not a luxury of peace but the quiet work of moving forward.]]></description>
      <pubDate>Thu, 06 Nov 2025 12:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/building-the-first-agentic-government-with-ukraine</guid>
    </item>
    <item>
      <title>Freedom Forever cuts cost per support call by 90% using ElevenLabs Agents</title>
      <link>https://elevenlabs.io/blog/freedom-forever-cuts-cost-per-support-call-by-90percent-using-elevenlabs-agents</link>
      <description><![CDATA[Freedom Forever is one of the largest U.S. residential solar installation companies, with more than 2,500 employees and a nationwide network of 10,000–20,000 independent sales representatives. The company operates multiple support lines that serve both end-customers and its contractor network, managing hundreds of thousands of customer accounts. High call volume and seasonal demand spikes Freedom Forever receives thousands of daily calls across customer and sales support lines, with more than 120 agents dedicated to sales support and 90 to customer support lines. Demand peaks sharply in summer and slows through winter, creating major staffing fluctuations that are difficult to manage with human agents. Inconsistent call volumes led to long hold times and high call abandonment rates. For those that did wait on hold, the time to first answer varied significantly, on peak volume days reaching up to 25 minutes Freedom Forever needed a more responsive and cost-efficient way to manage call volumes year-round. To improve responsiveness and deliver faster, more consistent support to both customers and sales representatives, the team began exploring conversational agents. Choosing a unified, low-latency agents platform with integrated testing tools Freedom Forever evaluated several speech-to-speech architectures, including OpenAI’s realtime API and custom pipelines built by combining Speech to Text, an LLM, and Text to Speech through separate APIs. These setups introduced latency and turn-taking issues, and required significant work to manage routing, scaling, and evaluations. ElevenLabs offered a unified alternative: natural, low-latency voice interactions with built-in routing, testing, and evaluation tools that integrate directly with existing infrastructure and handle human hand-offs seamlessly. This end-to-end platform delivered both the caller experience and the operational reliability Freedom Forever needed, and freed up human operators to focus on more complex tasks. From prototype to production in one week The team prototyped within days and moved to production in a week. The constraint was not infrastructure - it was selecting which scenarios to automate first. In production, Freedom Forever runs inbound support for both its contractor network and customer base. A router agent identifies the caller type and directs them to specialized agents equipped to handle their requests. Calls are managed through Twilio numbers connected directly to ElevenLabs Agents, with seamless transfers to human representatives when needed and transcript context automatically posted to the CRM. The system operates in English and Spanish, including support for Puerto Rico dialects. – Rob Richardson, VP of Product at Freedom Forever 90% cost reduction and instant support response Freedom Forever reduced cost per call by 90%, eliminated hold times, and brought call abandonment rates down by 98% after migrating to ElevenLabs Agents. What’s next In addition to transforming customer support, Freedom Forever is exploring outbound sales agents to help its independent sales network engage leads faster and follow up on customer inquiries more efficiently.]]></description>
      <pubDate>Tue, 04 Nov 2025 12:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/freedom-forever-cuts-cost-per-support-call-by-90percent-using-elevenlabs-agents</guid>
    </item>
    <item>
      <title>Introducing Agent Workflows</title>
      <link>https://elevenlabs.io/blog/introducing-agent-workflows</link>
      <description><![CDATA[Our agents platform now offers Workflows - a visual editor for designing conversation flows. Instead of building all business logic in a single agent, Agent Workflows let you handle complex scenarios by routing to specialized Subagents and, when needed, transferring to human operators. You map the flow, declare decision points, and control handoffs to Subagents or humans - making behavior explicit, auditable, and testable. This moves beyond a single large prompt so you can decompose tasks, apply guardrails, and orchestrate the right action at the right time. Scope context and tools with Subagents Subagents each have their own system prompt, tools, and scoped knowledge base. You choose which Subagent handles a task, what data it can access, and when to hand off to another agent or a human. This reduces prompt bloat, limits access to sensitive systems, and improves response quality with narrower context. Enforce security and business policy Workflows connect agents to your internal systems with scoped credentials and access. You can embed business rules - validations, approvals, thresholds, and escalation paths - so conversations follow the same policies your teams use today. Optimize for cost, latency, and accuracy With Agent Workflows, you can pick the ideal LLM for each step. Use lightweight models for classification and routing, and higher-accuracy models for complex reasoning. Because prompts and knowledge bases are scoped per Subagent, you reduce token usage and latency while improving precision. An example workflow Intake and classify the request with a lightweight model. Route billing questions to a billing Subagent with scoped tools and data and route technical issues to a support Subagent that can run diagnostics. Escalate to a human when confidence drops below a threshold or when approval is required. Return to the parent agent to summarize the outcome for the user. Start building Agent Workflows put you in control of how conversations are designed, routed, and supervised. Build structured, secure, and scalable agents with ElevenLabs Agents. To learn moreread the documentationor get started with setting upan Agent Workflow today.]]></description>
      <pubDate>Thu, 16 Oct 2025 15:57:02 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/introducing-agent-workflows</guid>
    </item>
    <item>
      <title>On track to help 1 million people regain their voice</title>
      <link>https://elevenlabs.io/blog/impact-program-v2</link>
      <description><![CDATA[We build AI to help people communicate. Through ourImpact Program, we provide free access to those who need it most. Last year, we started by supporting ALS patients. Now, we’re expanding to include people affected by Multiple System Atrophy (MSA) and mouth cancers. We’ve partnered withMSA Trust,Mission MSA, and theMouth Cancer Foundationto reach more people who lose their voice due to illness. These organizations work directly with patients, offering support, advocacy, and resources. How it works MSA Trust & Mission MSA: verified MSA patients get free lifetime access to ElevenLabs’ AI voice tools to create and use digital voice replicas. Mouth Cancer Foundation: patients in the UK diagnosed with oral and head and neck cancers can apply for a free Pro plan, letting them clone their voice before speech loss. Losing the ability to speak is deeply isolating. AI voice technology gives people a way to keep their voice, making communication feel familiar and natural. That’s why we’re committed to helping 1 million people through the Impact Program. If your non-profit could benefit from AI advancements,reach out to us.]]></description>
      <pubDate>Thu, 16 Oct 2025 14:33:16 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/impact-program-v2</guid>
    </item>
  </channel>
</rss>
