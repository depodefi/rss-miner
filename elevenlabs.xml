<?xml version="1.0" ?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>ElevenLabs Blog</title>
    <link>https://elevenlabs.io/blog</link>
    <description><![CDATA[Latest updates from ElevenLabs]]></description>
    <language>en-US</language>
    <lastBuildDate>Sat, 06 Dec 2025 22:04:51 GMT</lastBuildDate>
    <generator>rfeed v1.1.1</generator>
    <docs>https://github.com/svpino/rfeed/blob/master/README.md</docs>
    <item>
      <title>Introducing Scribe v2 Realtime</title>
      <link>https://elevenlabs.io/blog/introducing-scribe-v2-realtime</link>
      <description><![CDATA[Scribe v2 Realtime: the most accurate model for live transcription Scribe v2 Realtime sets a new standard for low-latencySpeech to Text. Designed for live use cases—voice agents, meeting assistants, and real-time captioning—it transcribes speech in under 150 ms across English, French, German, Italian, Spanish, and Portuguese, and 90 languages. Scribe v2 Realtime is specifically built for agentic use cases. On 500 hard samples containing background noise and complex information, it significantly outperforms all other models. Key features Negative latency:Next word and punctuation prediction Automatic language detection:Speak in any language, switch language mid conversation Text conditioning: Scribe v2 Realtime continues the transcription based on the previous batch, useful when restarting a connection Voice Activity Detection(VAD) Manual commit: Full control over when to finalize transcript segments Multiple audio formats: Support for PCM (48kHz) and μ-law encoding Enterprise readywith SOC 2, ISO 27001, PCI DSS L1, HIPAA, and GDPR compliance, EU and India data residency options and Zero retention mode for sensitive workloads Scribe v2 Realtime delivers human-level understanding in real time, enabling natural conversation and immediate response in live environments. Scribe v2 Realtime achieves 93.5% accuracy across 30 commonly used European and Asian languages. Build with the API Scribe v2 Realtime is available today through the ElevenLabs API. Explore the documentation:https://elevenlabs.io/docs/cookbooks/speech-to-text/streaming Use Scribe v2 Realtime in ElevenLabs Agents Deploy natural, human-sounding agents powered by Scribe v2 Realtime. Build voice assistants for support, sales, or in-product experiences that can understand and respond in real time. Learn more:https://elevenlabs.io/agents Start building today Use Scribe v2 Realtime through our API or directly within ElevenLabs Agents. Sign up here:https://elevenlabs.io/app/sign-up]]></description>
      <pubDate>Mon, 01 Dec 2025 12:41:32 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/introducing-scribe-v2-realtime</guid>
    </item>
    <item>
      <title>Introducing ElevenLabs UI: Open-source audio &amp; agent components for the web</title>
      <link>https://elevenlabs.io/blog/elevenlabs-ui</link>
      <description><![CDATA[ElevenLabs UIis a new open source library of customizable React components for building interfaces with theElevenLabs Agents& Audio SDKs. Built onshadcn/ui, it provides full control over UI primitives like waveforms, orbs, messages & more. Examples transcriber-01- An open-source voice dictation component you can drop into any web app: voice-chat-03- a rich multimodal chat interface with state management built in. Pass your Elevenlabs Agent ID as a prop and ship it: Getting started Components are available via the@elevenlabs/agents-clicommand. For example, to install theOrbcomponent, you can run: Read the docsand start building better agent & audio interfaces, faster.]]></description>
      <pubDate>Mon, 01 Dec 2025 12:41:27 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/elevenlabs-ui</guid>
    </item>
    <item>
      <title>Traba deploys AI interview agents to scale industrial staffing</title>
      <link>https://elevenlabs.io/blog/traba</link>
      <description><![CDATA[Trabais building a next-generation staffing platform for the industrial supply chain. Their mission is to match businesses with vetted, qualified temp workers at scale. To reach that goal, Traba builtScout, an AI-powered interviewing system integrated directly into their operations. Scout now conducts over 50,000 interviews monthly across warehousing, logistics, and manufacturing roles - reducing manual workload, improving placement rates, and delivering consistent evaluations across every region. Staffing is the bottleneck in industrial supply chains While millions of workers are ready to work, high-friction hiring processes hold back fulfillment centers, logistics hubs, and manufacturers from operating at peak efficiency. These jobs require qualification. Shift schedules vary. Language barriers exist. Regulatory requirements must be followed. All of this slows down staffing. Traba needed to scale without hiring thousands of recruiters. They needed a consistent, reliable system that could assess worker fit faster. Why Traba chose ElevenLabs In late 2024, real-timeText to SpeechandSpeech to Textbecame viable for phone-based interviewing. Traba began testing vendors with one goal: find a partner that could support advanced conversational AI without requiring full pipeline ownership. ElevenLabs offered: High-quality voices: natural, multilingual voices that made conversations feel human rather than robotic. Low latency: fast enough for real-time interactions without awkward delays. Flexibility and control: the ability to orchestrate multiple agents, experiment with prompting strategies, and integrate directly into their systems. Reduced complexity: handling challenging parts of the audio pipeline so they can focus on their unique workflows. Building the AI interviewer Scout launched with a single-agent architecture. Its first version proved that AI could conduct structured interviews, qualify candidates, and return useful evaluations. Scout V1: Monolingual: Only supported English, limiting reach Single-agent logic: One LLM handled all steps — introduction, Q&A, logistics Static question sets: Role-based, predefined queries with limited flexibility Basic evaluation: One-pass summary prompt at the end of the interview Operator handoff: AI provided directional signal; humans made final decisions Despite its simplicity, V1 ran thousands of calls in parallel and delivered time savings immediately. Scaling to 250,000+ calls: solving for depth, speed, and consistency By March 2025, Scout had run over 17,000 interviews and saved more than 1,400 hours of manual vetting time. To prepare for peak seasonal demand, the system was rebuilt to operate autonomously. Key upgrades included: Multilingual voices and dynamic switching ElevenLabs shipped multilingual support, enabling Scout to switch between English and Spanish mid-call based on user preference. This unlocked access to a previously underserved worker segment. Multi-agent orchestration As the interview context expanded, Traba encountered model degradation. ElevenLabs provided the tools to split calls across specialized agents - introduction, vetting, logistics, and FAQ support - with seamless transitions during the conversation. Deduplicated interview logic Workers applying for multiple jobs were getting asked the same questions. Traba engineered a preprocessing pipeline to deduplicate semantically similar questions across interviews. This reduced redundancy by up to 20% per candidate. Custom evaluation framework Operators needed more control over assessments. Traba built Custom Scout, a framework to define what ‘good’ answers look like on a per-question basis. Evaluations now align with each client’s unique criteria. Ground truth feedback and prompt iteration Traba developed an internal prompt testing framework with instant feedback loops. By generating human-verified datasets through Langfuse, the team could A/B test prompts against real-world performance — allowing fast iteration at scale. Results Traba’s AI-led interviewing system now powers over 50,000 interviews per month and85% of all worker vetting across the platform is fully automated. At an average of 5 minutes per conversation,this saves over 4k operator hours per month. 15% higher shift completion ratesfor AI-qualified workers vs. human-qualified Consistent assessmentsacross roles, shifts, and geographies Reduced time-to-hirewith structured decision-grade evaluations Scalable vetting layerthat runs 24/7 with minimal operator input By refining their question banks, evaluation logic, and call flows through continuous feedback, Traba built a system that scales while improving outcome quality. What’s next Traba’s roadmap includes agent-led onboarding, video-based Q&A, timesheet processing, and emotion detection via multimodal LLMs. They’re also working on agent-led prompt refinement, using performance data to train agents that optimize interview design autonomously. Throughout this journey, Traba continues to partner with us as we develop the next generation ofour Agents Platform, pushing the boundaries of language intelligence in complex real-world workflows.]]></description>
      <pubDate>Mon, 01 Dec 2025 01:37:19 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/traba</guid>
    </item>
    <item>
      <title>Harvey and ElevenLabs Partner to Give Lawyers a Global Voice</title>
      <link>https://elevenlabs.io/blog/harvey</link>
      <description><![CDATA[We've partnered with Harvey, the AI legal platform used by leading law firms and enterprises, to create the first global, multilingual voice for the legal profession. Our collaboration brings spoken intelligence to law, enabling Harvey to communicate naturally in dozens of languages, dialects, or accents.Powered by ElevenLabs’Text to SpeechandSpeech to Text, Harvey will make legal knowledge more accessible and human across jurisdictions and cultures. “This partnership makes legal AI more global, accessible, and human,” said Winston Weinberg, CEO at Harvey. “With ElevenLabs, we’re ensuring every lawyer can engage with Harvey in their own language and context." “Our mission has always been to break down language barriers,” said Mati Staniszewski, CEO of ElevenLabs. “By bringing Harvey’s legal intelligence to voice, in dozens of dialects and accents, we are helping transform how law is experienced globally.” The first phase will allow Harvey to deliver answers audibly in almost any language or dialect. Future developments will introduce new features like multi-lingual voice translation, voice mode, spoken trial simulations, tone customization, and more. Together, we're are redefining how legal professionals interact with AI, with knowledge that isn’t just written, butspokenwith clarity and precision.]]></description>
      <pubDate>Sun, 30 Nov 2025 23:59:33 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/harvey</guid>
    </item>
    <item>
      <title>ElevenLabs powers voice for Cisco’s Webex AI Agent</title>
      <link>https://elevenlabs.io/blog/cisco-webex</link>
      <description><![CDATA[ElevenLabs is now powering the voice technology behind the Webex AI Agent. At ElevenLabs, we believe that natural, expressive voice should be the standard for all AI agents. Expressive voices keep customers engaged throughout conversations, allowing agents to deliver meaningful results and create genuine value. We're proud to partner with an industry leader like Cisco to make this vision a reality, bringing voice-first, agentic customer support to the enterprise. Addressing a Critical Customer Experience Gap Recent research from Cisco¹ has revealed major gaps between consumer expectations and reality in today's customer service landscape: Only 25% of customers report being "very satisfied" with their last customer service engagement 94% have abandoned interactions due to poor experiences 95% would switch brands due to sub-par customer service The three biggest frustrations? Having to repeatedly explain their issue (54%), dealing with voice or chatbots that aren't intelligent enough to help (48%), and being kept on hold too long (31%). Beyond Traditional Chatbots Traditional chatbots have often frustrated customers with rigid experiences and an inability to interpret natural language. Webex AI Agent uses large language models (LLMs) to deliver more human-like customer experiences that understand an individual’s needs, remember their history, and adapt to their preferences. By integratingElevenLabs' voice technology, Webex AI Agent can deliver voice interactions that sound and feel like conversing with a real person—thanks to the agent’s human-like intonation, inflections and rhythm. What’s more, its voice AI can respond to a customer's emotional cues and adapt its delivery — sounding warm and welcoming when needed, or serious and empathetic when the situation calls for it. This new partnership addresses the evolving needs of enterprises by combining advanced voice technology with Cisco’s scalable channel support and intuitive design tools — enabling seamless integration with custom knowledge bases and critical backend systems such as CRM, ERP, and HR platforms. Meet the all-new Webex AI Agent “At Cisco, we're focused on delivering AI-powered customer experiences that are natural, responsive, and scalable,” says Jay Patel, Senior Vice President and General Manager for Webex Customer Experience Solutions. “Voice plays a critical role in humanizing these interactions, and ElevenLabs' Text to Speech technology has helped us bring greater nuance and clarity to our AI agents. It's a valuable component in our broader strategy to make customer engagement more intuitive and effective. Together, we’re delivering human-sounding AI with enterprise-grade performance, security and scalability.” “Our mission is to make AI sound more like us - empathetic, dynamic, real,” adds Mati Staniszewski, CEO and Co-founder of ElevenLabs. “By joining forces with Cisco, we’re ensuring that our innovative technology can meet the complex demands of any enterprise environment, by bridging the gap between life-like AI interactions and the enterprise infrastructure required to deliver them at scale.” We're excited to see how Webex AI Agent transforms customer support operations worldwide and look forward to continuing our collaboration with Cisco on future innovations. For more information about Webex AI Agent and how it’s helping organizations bridge the AI divide, visithttps://www.webex.ai/ai-agent.html ¹ "AI and the Art of Customer Experience", Cisco Webex, May 2024.]]></description>
      <pubDate>Sun, 30 Nov 2025 23:55:06 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/cisco-webex</guid>
    </item>
    <item>
      <title>Deliveroo partners with ElevenLabs to enhance rider and restaurant experience</title>
      <link>https://elevenlabs.io/blog/deliveroo</link>
      <description><![CDATA[Deliveroo’s mission is to transform the way people shop and eat - bringing the neighbourhood to their doors by connecting consumers, restaurants, shops, and riders. Operating one of Europe’s largest on-demand delivery networks, with millions of consumers and more than 176,000 local businesses, Deliveroo is focused on maintaining service quality at scale through constant communication across its network. To support rapid growth across multiple markets and languages, Deliveroo’s teams continually explore new innovations to improve the experience for riders, partners, and consumers. With teams operating across multiple regions and languages, Deliveroo was looking for a way to improve the rider onboarding process, and to help restaurants maximise orders, while maintaining accuracy and trust. Improving rider onboarding and engagement As Deliveroo scales, streamlining rider onboarding is essential in order to meet demand whilst delivering a consistent and high-quality user experience. Deliveroo’s rider onboarding process includes several steps that help ensure applicants are verified and ready to begin delivering. However, Deliveroo found that a portion of applicants tended to drop off before completing the onboarding, and subsequent outreach to re-engage these riders was time-intensive and inconsistent across regions. To address this issue, Deliveroo deployed an ElevenLabs Agent to automatically contact rider applicants who had been inactive for more than two weeks. The voice agent confirmed the applicant’s continued interest and guided them through the next steps to help them complete onboarding in their preferred language. The results in the first few weeks of deployment showed a substantial increase in engagement and throughout: The agent reached the majority of the target cohort via call or voicemail. 30% of riders confirmed their intent to continue onboarding and continued their application within seven days of the call. By leveraging agentic support, Deliveroo reached thousands of riders in hours instead of days or weeks. This reduced manual workload for local operations teams allowing them to focus on more strategic work like unique edge cases where they could offer more personalized support, and improved overall rider activation rates. Helping maximize restaurant orders Deliveroo’s operations teams manage a large and varied network of restaurant partners. Maintaining accurate live status data for each restaurant is critical to ensuring reliable consumer experiences and efficient rider allocation. Traditionally, this process required restaurant support teams to make thousands of calls each week to verify whether or not restaurants reported as “closed” by riders were, in fact, operational. To streamline this process and help businesses maximize orders during opening hours, Deliveroo deployed an ElevenLabs Agent to automatically confirm the live status of restaurants flagged as potentially closed. The agent placed outbound calls, validated opening hours, and updated Deliveroo’s systems in real time. Over the evaluation period, ElevenLabs Agents achieved a 75% success rate in reaching restaurants by phone using a voice agent to verify operating hours. This eliminated the need for thousands of manual check-ins and enabled Deliveroo to monitor the network’s live status in a fraction of the time previously required, enabling the team to focus on higher-impact operational tasks. The Deliveroo team highlighted how impressed they were with ElevenLab agents platform ability to achieve their goals: Expanding Rider Check-In (RCI) tag activation Following the success of its other pilots, Deliveroo extended its partnership with ElevenLabs to drive partner activation of Rider Check-In (RCI) tags - a key operational tool to streamline order handover between restaurants and riders. Together we developed an ElevenLabs Agent that would proactively contact sites that had not activated tags after five business days of delivery, with the goal of guiding managers through installation and activation steps. In early results, Deliveroo’s ElevenLabs Agent was able to successfully contact 86% of partner sites, helping to drive meaningful increases in activation. By automating these interactions, Deliveroo was able to improve partner communications and the overall consumer experience through faster, more reliable deliveries. Simple setup without technical expertise Amy Marangon, Senior Manager Operations Strategy at Deliveroo, highlighted how quickly the team was able to launch multiple agents: Summary of results with ElevenLabs Agents With proven results across rider, restaurant, and partner operations, Deliveroo has demonstrated how intelligent automation can drive measurable efficiency, stronger engagement, and a better experience for riders, restaurants, and consumers alike.]]></description>
      <pubDate>Wed, 26 Nov 2025 12:43:29 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/deliveroo</guid>
    </item>
    <item>
      <title>ElevenLabs establishes Japanese Subsidiary, ElevenLabs G.K.</title>
      <link>https://elevenlabs.io/blog/elevenlabs-establishes-japanese-subsidiary-elevenlabs-gk</link>
      <description><![CDATA[Today we launched ElevenLabs G.K., an international subsidiary based in Tokyo, Japan. Our new Japanese entity will focus on adapting ElevenLabs' cutting-edge voice generation platform for the Japanese market while addressing the unique linguistic and cultural requirements of the region. About ElevenLabs Japan Company Name: ElevenLabs Japan G.K. Location: 1-6-5 Marunouchi, Chiyoda-ku, Tokyo, Japan General Manager: Hajime Jim Tamura has over 35 years of experience helping companies enhance performance through business applications. A pioneer in Japan’s cloud computing landscape since the late 2000s, he has consistently led the advancement of operational efficiency through SaaS solutions. His past roles include Vice President of Marketing at SAP Japan, President of NetSuite Japan, Director of Business Applications at Microsoft Japan, and General Manager of Asana Japan. After serving as COO of the virtual office platform ovice, he assumed his current role at ElevenLabs Japan in 2025. Ongoing Strategic Partnership in Asia Pacific While we're just now announcing ElevenLabs G.K., we've already got to work in Japan, partnering with: - DOCOMO Innovations, Inc.: A Silicon Valley-based R&D subsidiary of NTT DOCOMO, Inc., Japan’s largest mobile operator. - TBS: One of Japan’s leading private broadcasters, engaged in a wide range of television, radio, and content production. - MBC C&I CO., LTD: A subsidiary of MBC, one of Korea's leading broadcasters, focusing on programme production and media business development. - LLSOLLU: A South Korean technology company with proprietary translation and localization technologies. They are integrating ElevenLabs' dubbing with their proprietary translation technology to provide more customer-specific dubbing services to their clients. For example, TBS is also leveraging ElevenLabs’ dubbing to make their KASSO program available in multiple languages for international viewers. Furthermore, MBC C&I CO., LTD has been using ElevenLabs' TTS and SFX technology to create commercial AI video content. In particular, “Mateo”, produced by the AI Content Lab under MBC C&I, won the Grand Prize at the Korea International AI Film Festival, and “Art In the World” won first place in the Narrative category, demonstrating the potential of AI-powered storytelling provided by ElevenLabs. Strategic Expansion into Japan "Japan represents a critical market for ElevenLabs' international expansion strategy," said Carles Reina, VP of Revenue at ElevenLabs. "We chose Japan as our first international subsidiary because of its rich linguistic heritage, technological innovation, and the potential impact our technology can have on bridging communication gaps and preserving cultural narratives." ElevenLabs G.K. will be led by Hajime Jim Tamura, who brings extensive experience in the Japanese AI and technology sectors at Asana and Microsoft. "The Japanese market presents unique opportunities for voice AI technology that go beyond traditional applications," said Jim Tamura, Head of ElevenLabs Japan. "From enhancing accessibility services for an aging population to enabling more immersive entertainment experiences, we see tremendous potential to address domestic needs through our platform. Our voice synthesis technology's ability to preserve natural intonation and emotional nuance is particularly valuable in Japanese, where pitch accent and contextual subtleties carry significant meaning." Linguistic and Phonetic Advantages From enhancing accessibility for an aging population to creating immersive entertainment experiences available in multiple languages, our platform is well-positioned to meet the country's diverse needs. In Japanese conversation and reading, subtle nuances of pitch, accent, and context carry significant meaning. That's why speech synthesis technology capable of expressing natural intonation and delicate emotions will be incredibly valuable in this market. Investor Support The establishment of ElevenLabs G.K. has received strong support from the company's investment partners, who see Japan as a strategic market for AI voice technology. Andreessen Horowitz Voice is quickly becoming a core interface for how we interact with technology, and ElevenLabs is at the forefront of enabling high-quality, scalable voice AI. Their platform delivers lifelike, emotionally expressive output that is particularly well-suited for the Japanese language. As businesses globally adopt innovative AI tools, Japan stands out as a dynamic market leading that charge. We’re proud to support ElevenLabs as they expand their presence and bring powerful voice capabilities to industries across Japan. Jennifer Li, General Partner at Andreessen Horowitz World Innovation Lab (WiL) We’ve had the privilege of working closely with the ElevenLabs team in Japan over the last several months, and we couldn’t be more excited about their expanded presence in the market. ElevenLab’s leading audio and voice platform is rapidly transforming industries all over the globe, and we’ve already seen strong interest in their offerings from Japanese enterprises in our corporate network. We look forward to continuing to support their growth in the market. Todd Grover, Partner at World Innovation Lab (WiL) NTT DOCOMO Ventures, Inc.Silicon Valley Office Manager Yuki TeranishiNTT DOCOMO Ventures has invested in ElevenLabs, recognising the vast potential of its groundbreaking voice generation AI technology as a strategic partner to support global business expansion. ElevenLabs’s technology, which enables the generation of human-like, natural-sounding speech, has the potential to significantly enhance customer experiences across sectors such as entertainment and customer support. We are confident that it represents a new frontier in generative AI applications. With an eye toward future use cases involving the Japanese language, the NTT DOCOMO Group’s R&D division (DOCOMO Innovations, Inc.) is currently conducting technical evaluations in preparation for a full-scale launch in the Japanese market. We have strong confidence that ElevenLabs’s solution will seamlessly address the varied needs of industries and users throughout Japan. japan-pr@elevenlabs.io 音声AIユニコーンのElevenLabs（イレブンラボ ）シリーズCで1.8億ドルを調達後、初の海外拠点として日本法人を設立 音声AI分野で業界を牽引するイレブンラボアジアパシフィックの最初のハブとして日本を選択 AI音声技術をリードするイレブンラボは2025年4月14日、初の海外拠点となる日本法人「イレブンラボ合同会社（ElevenLabs G.K., ）」を東京に設立し、日本およびアジアパシフィックでの活動を本格化いたします。今回の日本進出は、当社が2025年1月に実施した1.8億ドルのシリーズC資金調達に続くもので、グローバル成長戦略における重要なマイルストーンとして位置付けております。 新たに設立された日本法人では、イレブンラボの最先端の音声生成プラットフォームを日本ならびに韓国マーケット向けに提供・サポートすることのほかに、プラットフォームのローカライズや日本語ならではの言語的・文化的な特性に対応していくことを主なミッションとしています。 イレブンラボジャパンについて 社名：イレブンラボジャパン合同会社（ElevenLabs Japan G.K., ） 所在地：東京都千代田区丸の内１丁目６番５号 Japan＆Korea ゼネラルマネージャー：田村 元（たむらはじめ） 略歴： 35年以上にわたりビジネスアプリケーションを通じて企業のパフォーマンス向上に従事。特に、 SaaSビジネスに関しては、2000年代後半の日本におけるクラウドコンピューティング黎明期から、常に先駆的な立場でクラウド活用による業務効率化を推進。SAPジャパンではマーケティングバイスプレジデント、ネットスイート株式会社の代表取締役、日本マイクロソフト業務執行役、Asana Japan株式会社代表取締役ゼネラルマネージャーなどを歴任。その後バーチャルオフィスツールoviceのCOO（最高執行責任者）を経て2025年より現職。 アジアパシフィックですでに進む協業 イレブンラボは、下記の企業を代表例に、協業を進めております。 - DOCOMO Innovations, Inc：NTTドコモ（日本最大のモバイル通信事業者）のR&D拠点としてシリコンバレーに設立されたグループ会社。 - TBS：日本を代表する民間放送局で、テレビ、ラジオ、コンテンツ制作を幅広く手がける。 - MBC C&I CO.LTD：韓国を代表する放送局の一つであるMBCの子会社で、番組制作やメディアビジネスの展開を手がけている。 - LLSOLLU： 独自の翻訳・ローカライズ技術を持つ韓国のテクノロジー企業。 例えばTBSではイレブンラボの音声吹き替え技術を、世界的に有名なスケーターたちが巨大な特設コースで競い合う番組『KASSO』に活用。番組の音声を多言語対応させることで、海外視聴者に臨場感溢れるコンテンツを届けています。 またMBC C&I CO., LTD.でも、商業向けのAI映像コンテンツ制作において、イレブンラボのTTS（音声合成）およびSFX（効果音）技術を活用されています。 特に、MBC C&I傘下のAIコンテンツラボが制作した「Mateo」は、Korea International AI Film Festivalでグランプリを受賞し、「Art In the World」はNarrative（ナラティブ）部門で1位を獲得。これらの受賞は、イレブンラボのAIがもたらすストーリーテリングの新たな可能性を強く示しています。 日本への戦略的進出の背景 イレブンラボ売上統括部門 ヴァイスプレジデント カルレス・レイナからのコメント 「日本は、イレブンラボのグローバル展開戦略において極めて重要な市場です。日本を初の海外拠点として選んだのは、豊かな言語文化、技術革新の土壌があるからです。そして私どもの技術がコミュニケーションの壁を越える架け橋となり、豊かな文化を守り未来へと繋げる力になると信じています。」 イレブンラボジャパン合同会社 Japan＆Korea ゼネラルマネージャー 田村元からのコメント 「日本市場には、これまでの枠組みにとらわれない、音声AIならではの独自の可能性が広がっています。高齢化社会に向けたアクセシビリティの向上から、より没入感のあるエンターテインメント体験の創出とその多言語化まで、私たちのプラットフォームは、多様化する国内のニーズに応えうる力を備えていると確信しています。とりわけ会話や読み上げといった話し言葉においては、音の高低やアクセント、文脈による繊細なニュアンスが大きな意味を持つため、自然なイントネーションや感情の機微まで表現できる音声合成技術が、極めて高い価値を発揮すると考えています。」 各言語が持つ特有の複雑さへ、自然に、繊細に対応 イレブンラボの技術は、各種言語特有の複雑さに対応できる点が大きな強みです。 話し言葉には、ピッチアクセントや文脈による多様な表現など、音声AIにとっても非常に難易度が高いとされる課題が存在します。イレブンラボの生成AIは、こうした微妙な音声的特徴を的確に捉えることができます。この技術は、各言語の自然な話し方を再現しながら、実際のコミュニケーションに不可欠な感情表現の幅を実現しています。 投資家からのコメント イレブンラボ合同会社の設立は、AI音声技術にとって日本は戦略的市場だという共通認識のもと、世界有数のベンチャーキャピタルなどさまざまな投資パートナーからの強い支持をいただいています。 Andreessen Horowitzゼネラル・パートナー Jennifer Li 音声は、人とテクノロジーをつなぐ新しい手段として急速に重要性を増しています。イレブンラボは高品質かつスケーラブルな音声AIの実現を、最前線でリードしています。 同社のプラットフォームは、感情豊かで自然な音声を安定的かつ大規模に提供でき、日本語のような繊細な言語にも非常に適しています。世界中の企業が革新的なAIツールを取り入れ始めている中、日本はその動きをけん引する存在です。イレブンラボが日本での展開を加速させ、さまざまな業界に音声AIの力を届けていくことを、私たちは誇りを持って支援してまいります。 WiL (World Innovation Lab)パートナー Todd Grover ここまで数ヶ月、イレブンラボ日本チームとの密な連携を行ってまいりました。そして今回の日本市場へのさらなる展開にこれ以上ないほどの期待を寄せています。同社の先進的な音声プラットフォームは、世界中で多彩な業界に変革をもたらしており、私たちWiLが持つ日本の大企業ネットワークの中でも、すでに高い関心が寄せられています。今後もイレブンラボの日本市場における成長を継続してサポートしていけることを楽しみにしています。 株式会社NTTドコモ・ベンチャーズシリコンバレー支店 マネージャー 寺西 勇樹 当社は、イレブンラボの革新的な音声生成AI技術に大きな可能性を感じ、グローバルでの事業展開を支えるパートナーとして出資を行いました。 人間らしい自然な音声の生成を可能にする同社のテクノロジーは、エンターテインメントやカスタマーサポートといった分野における顧客体験の進化を強く後押しするものであり、生成AIの新たな活用モデルを切り拓くと確信しています。 今後の日本語を利用したユースケースを見据え、NTTドコモグループのR&D（DOCOMO Innovations, Inc.）と技術評価を実施しており、日本市場での本格展開に向けた準備も進めています。イレブンラボのソリューションが、日本の多様な産業やユーザーのニーズに応えていくことを大いに期待しています。 イレブンラボとは イレブンラボは、AI音声に特化した研究・実用化を進めるテクノロジーカンパニーです。CEOであるマティ・スタニセフスキーと、CTOのピョートル・ダブコフスキー（TIME誌「AI Top 100 Innovators」に選出）は、ともにポーランド・ワルシャワ出身の幼なじみ。自国での映画などの吹き替え版の質が低いことに問題意識を持ったことが共同創業のきっかけとなりました。 同社はこの1年で社員数を30名から160名へと拡大し、現在はロンドン、ニューヨーク、ワルシャワに拠点を構えています。そして25年1月に、シリーズCの資金調達を完了しました。 イレブンラボは、あらゆる声・言語・音で情報へアクセスできる未来の実現をミッションとし、音声AIの可能性を拡張する、唯一無二の統合型プラットフォームの構築に挑んでいます。 本件に関する報道メディアからのお問い合わせ先 japan-pr@elevenlabs.io]]></description>
      <pubDate>Wed, 26 Nov 2025 03:54:18 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/elevenlabs-establishes-japanese-subsidiary-elevenlabs-gk</guid>
    </item>
    <item>
      <title>Introducing ElevenLabs Agents</title>
      <link>https://elevenlabs.io/blog/introducing-elevenlabs-agents</link>
      <description><![CDATA[FromConversational AIto ElevenLabs Agents We’re renaming Conversational AI to ElevenLabs Agents. It’s a complete platform where you can build, launch and monitor conversational agents that talk, type and take action across phone, web and apps. ElevenLabs Agents is a better name for this. Since launch, customers have created more than 2 million agents. Together, they’ve handled over 33 million conversations this year. What makes ElevenLabs Agents different Connected to your knowledge base, tools, and telephony, our multimodal agents can manage complex workflows while maintaining enterprise-grade reliability and control. Customers are already usingElevenLabs Agentsto: Resolve customer issues Qualify leads Run outbound calling at scale Support employee learning and development Power dynamic NPCs in games Act as personal assistants or tutors Our goal is simple: make conversations with technology as natural as speaking with a person. With our audio research and orchestration platform, startups, SMBs, and enterprises can deliver personalized one-to-one interactions at scale. What’s next for ElevenLabs Agents We’re expanding the platform to give developers more control and better performance. Coming soon: Visual workflow builderto handle complex business logic Testing suiteto run simulations to ensure agents act as expected Expressive modefor more realistic voice interactions Expanded integrationswith Google Calendar, Salesforce, Zendesk, and more Build your first ElevenLabs Agent We believe conversationalvoice agentswill become a core part of how people interact with technology. With ElevenLabs Agents, you can build, deploy, and monitor them in one place. Start building today:https://elevenlabs.io/app/agents]]></description>
      <pubDate>Tue, 25 Nov 2025 21:06:53 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/introducing-elevenlabs-agents</guid>
    </item>
    <item>
      <title>Expanding into Brazil - ElevenLabs Launches Iconic Partnership with Fábio Porchat</title>
      <link>https://elevenlabs.io/blog/fabio-porchat</link>
      <description><![CDATA[Even before we launched local operations in 2025, it was clear that Brazil would be central to the future of voice-driven experiences. With more than 220 million Portuguese speakers, a top-five global creator economy, and some of the highest social media engagement rates worldwide, the country has become a natural hub for innovation in voice. It is also home to a $10B+ customer service industry, where businesses face rising demand for faster, more natural, and human-like interactions. Today, we are deepening our commitment to the country with a new partnership with Brazilian icon Fábio Porchat. Watch the campaign video and try the Judite 2.0 experience for yourself. Recognized for his work as co-founder of Porta dos Fundos, host ofQue História É Essa, Porchat?, lead in numerous Brazilian comedies, and the voice of characters inFrozenandMonsters University.Porchat’s voice is instantly familiar across Brazil, but its energy is universal: witty, warm, and full of life. In him, we see not just a voice, but a bridge between Brazil and the world, showing how Latin creativity and humor can be amplified through technology. For all these reasons, we are honored to enable voice licensing through ourIconic Marketplace, giving creators and enterprises the ability to request the license of Porchat’s voice for real-time AI applications with local authenticity and global scalability. As part of this partnership, ElevenLabs is launching its first advertising campaign in Brazil - “Judite 2.0” - a voice-first initiative that highlights how our Agents Platform can radically improve customer service interactions. Originally introduced in 2012, the original Judite video symbolized everything broken in Brazilian customer service: confusing call flows, poor support, and endless wait times. Judite 2.0 is the complete opposite - an AI agent built with ElevenLabs’ real-time Agents Platform and powered by ourText to Speechengine, capable of responding naturally and clearly in real time. Judite became iconic because she reflected a very Brazilian way of facing hardship: with humor, satire, and creativity. Reviving her as Judite 2.0 shows how Brazilian storytelling doesn’t just endure, it evolves, and with AI, it now leads. In Brazil, we’ve always found ways to turn challenges into art, samba born from struggle, comedy that reimagines chaos, and a creator economy that thrives even through crises. Partnering with Fábio Porchat reflects this same resilience: taking what was once a cultural symbol of frustration (Judite) and transforming her into a symbol of progress. “Judite was part of an iconic moment in my career and in the lives of many people who watched that video. For years, she was remembered as the symbol of a complicated customer service experience that every Brazilian has faced at some point. Now, I’ve had the chance to meet her again in a new version - more modern, efficient, and even friendly. It’s fun to turn that old ‘trauma’ into a partnership. Today, I can say that Judite has become my friend. And this reunion makes the campaign even more fun and special,” says Fábio Porchat. Developed in partnership with comedian Porchat, the campaign revives one of Brazil’s most iconic characters and reimagines her as an intelligent voice assistant - powered by ElevenLabs. More than a campaign, it is a celebration of Brazilian creativity, a testament to Latin resilience, and an homage to the voices that have always carried our stories, our humor, and our humanity into the world. Judite Then vs. Judite Now - A Revolution in Voice As part of the campaign, we’ve built an interactive experience where users can talk to both versions of Judite - side by side. Judite 2012 → Endless menus. Robotic replies. Zero resolution. Judite 2.0 → Instant responses. Natural conversations. Context that feels human. The contrast is immediate and powerful. What once symbolized everything broken in customer service now demonstrates the future of real-time AIvoice agents- fast, intelligent, and deeply realistic. What’s Next This is just the start. As we invest further in Brazil, we’ll continue to collaborate with local creators, enterprises, and cultural icons to redefine how voice technology connects people and businesses - locally and globally.]]></description>
      <pubDate>Tue, 25 Nov 2025 21:06:51 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/fabio-porchat</guid>
    </item>
    <item>
      <title>Expanding access: patients and clinicians can now apply directly on the ElevenLabs website</title>
      <link>https://elevenlabs.io/blog/expanding-access-patients-and-clinicians-can-now-apply-directly-on-the-elevenlabs-website</link>
      <description><![CDATA[Patients with permanent speech loss - and their speech-language pathologists, occupational therapists, or AAC specialists - can now apply for free voice licenses directly on the ElevenLabs website through our Impact partners. How it works To begin, applicants need to create a free ElevenLabs account. After clicking on their profile photo, they will select"Apply for Impact Program,"then follow the on-screen steps to apply through the nonprofit organization that supports their region and diagnosis.Clinicianscan also apply for a free 1-year licenses by selecting "Clinicians/Staff" rather than a nonprofit organization when applying. This enables them to guide their patients through the process of creating personalized synthetic voices. There are no discount codes or credit card details required. Approved applicants receive a 5-year, extendable free license. How individuals with permanent speech loss can apply for a free voice How clinicians supporting individuals with permanent speech loss can apply for a free voice Who is eligible We partner with nonprofit organizations who help us distribute free access to ElevenLabs for individuals affected by permanent voice loss or visual impairment. Our current application partners support individuals across a range of diagnoses and regions, including: ALS/MND(USA –Bridging Voice; UK –MND Association; Australia –MND and Me,MND NSW - FlexEquip; Global –Scott-Morgan Foundation,UCL) PSP, MSA, CBD(USA/Canada –CurePSP; UK/Ireland –MSA Trust; Global –Mission MSA) Stroke(USA –Stroke Onward; New Zealand –TalkLink Trust) Tay-Sachs & SandhoffDisease (England, Wales, Northern Ireland –CATS Foundation) Head & Neck Cancer, Laryngectomy, Glossectomy(Global –Lary’s Speakeasy,TalkLink Trust) Permanent speech impairment and specific AAC users(Global –Smartbox,Jabbla,Therapy Box,Cboard,REHAVISTA,UCL) Blind and Low-Vision(USA –National Federation of the Blind) Building toward one million voices By enabling users to apply directly through the ElevenLabs website, we’re removing friction and making accessibility faster and simpler. Each improvement brings us closer to our goal of giving one million people their voices back. Note: This new workflow isonly for individuals with permanent speech loss and their clinicians, who can use it to support patients through onboarding andvoice cloning. Organizations seeking to help distribute free access to patients, especially to represent a new region or diagnosis not currently supported, should apply through our standardImpact Program Application. If your nonprofit organization would like to complete a project using ElevenLabs technology, please also applythere.]]></description>
      <pubDate>Tue, 25 Nov 2025 21:06:04 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/expanding-access-patients-and-clinicians-can-now-apply-directly-on-the-elevenlabs-website</guid>
    </item>
    <item>
      <title>Introducing ElevenLabs Image &amp; Video</title>
      <link>https://elevenlabs.io/blog/introducing-elevenlabs-image-and-video</link>
      <description><![CDATA[Today we’re introducing ElevenLabs Image & Video (Beta). The best audio, image, and video models all in one platform. Within ElevenLabs, you can now bring ideas to life in one complete creative workflow. Use leading models like Veo, Sora, Kling, Wan and Seedance to create high-quality visuals, then bring them to life with the best voices,music, andsound effectsfrom ElevenLabs. Creators, marketers, and content teams can generate images, compose clips, adjust narration, and export final content all inside a single, unified workflow. Create with leading image and video models ElevenLabs Image & Video (Beta) brings together the best models for visual creation. You can: Createstill images using leading models including Nanobanana, Flux Kontext, GPT Image, and Seedream. Usethese as storyboards, thumbnails, or as source material for video projects. Generatevideos with models including Veo, Sora, Kling, Wan, and Seedance. Refineoutputs and compose multiple clips for seamless storytelling. Upscaleyour images and videos for higher-quality results. Add lipsyncto your generated videos using ElevenLabs voices for perfectly aligned narration. Refine and edit in Studio Once your visuals are ready, export to Studio to complete your project. Studio lets you: Add expressivevoiceoversusing voices from our library or your own clones. Compose bespoke background music and layer in sound effects. Adjust timing and refine narration on a single timeline. Export polished, production-ready videos. Built for creators, marketers, and content teams Image & Video is designed for creators of every kind, from filmmakers and freelancers to marketers and educators. Whether you’re creating product videos, social content, or educational materials, ElevenLabs provides the full toolset to go from idea to final export in one platform. This launch marks a major step toward true multimodal creation, where every element — from visuals to sound — can be generated, edited, and refined together. Available in ElevenLabs Creative Platform Start creating with ElevenLabsImage & Video(Beta).]]></description>
      <pubDate>Tue, 25 Nov 2025 21:05:16 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/introducing-elevenlabs-image-and-video</guid>
    </item>
    <item>
      <title>We’re partnering with Liberty Global to accelerate voice AI expansion across Europe</title>
      <link>https://elevenlabs.io/blog/liberty-global-partnership</link>
      <description><![CDATA[We’ve started a commercial partnership with Liberty Global Ventures, the technology investment arm of Liberty Global. As part of this, Liberty Global will also be making a strategic investment in ElevenLabs. Our work together will focus on howvoice AIcan make everyday interactions with technology feel more natural - especially across telecommunications and entertainment products. Liberty Global is looking at several applications of our technology - from AI-powered customer service agents that offer faster, more human support, to voice interfaces for connected TV and streaming products that make content discovery simple and intuitive. We’re also looking at new ways voice can shape customer communication and marketing. The investment was led by Rebecca Hunt, Partner at Liberty Global Ventures, based in London, and supports our continued work to scale our foundational voice model globally and bring lifelike, multilingual voice AI to more people. Our Co-Founder Mati says: “Entering a strategic partnership with Liberty Global is a welcome endorsement from one of the world’s biggest providers of connectivity services and marks a further step forward in bringing emotionally rich, lifelike voice AI to millions of households.” Rebecca Hunt, Partner, Liberty Global Ventures, adds: “Voice is becoming the next major interface for technology, and ElevenLabs is defining what’s possible in this space. The investment continues our track record of providing early backing for transformational tech infrastructure companies; we are honoured to be backing this category-defining team.” We founded ElevenLabs in 2022 to build voice AI that lets people and technology speak naturally - in every language. This partnership brings that vision closer.]]></description>
      <pubDate>Tue, 25 Nov 2025 21:03:36 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/liberty-global-partnership</guid>
    </item>
    <item>
      <title>Voice AI for India Scale</title>
      <link>https://elevenlabs.io/blog/voice-ai-for-india-scale</link>
      <description><![CDATA[India has become one of the fastest-growing markets for artificial intelligence, withvoice AIadoption rising sharply across sectors and the creator economy. In just one year, India has grown into our largest market by signups and our second-largest by enterprise revenue. This growth is driven by the country’s diverse linguistic landscape and massive consumer base, which make India a natural fit for voice AI solutions. In just twelve months, with a dedicated go-to-market team on the ground, ElevenLabs has forged local partnerships, and worked alongside Indian companies and developers to reimagine how people connect, learn, and do business through natural-sounding AI voices. A defining moment came when our AIdubbingtechnology helped dub Prime Minister Narendra Modi’s three-hour conversation with Lex Fridman from Hindi to English – a showcase of how far AI voice synthesis has come. Scaling Enterprises with Voice AI Leading Indian enterprises across e-commerce, fintech, edtech, telecom, media, and technology have embraced ElevenLabs voice AI as core infrastructure to engage customers at scale: Meeshoautomates over 60,000 customer support callsper dayin Hindi and English 99acresandNoBrokeruse natural-sounding AI agents to qualify leads and schedule site visits Cars24uses voice AI tech to turn 20,000 multilingual customer conversations each month into actionable insights leading to a 50% faster issue resolution Pocket FM,Kuku FM,Sharechatuse voice AI to produce multilingual storytelling, trailers, and audiobooks reducing up to 90% production cost Adobe CaptivateandSuperNovalocalize e-learning content in multiple Indian languages These companies are reducing costs, increasing efficiency, and improving customer satisfaction by using expressive, voice AI agents that sound human and empathetic. In India, voice AI is no longer experimental - it’s foundational. Investing in India’s Voice AI Ecosystem Our commitment goes beyond product: India Data Residencylaunched for local compliance and lower latency for enterprises OurVoice Actor Marketplaceis projected topay out upwards of $1M to Indian voice talent, by end-2025. It also ensures robust Indian voices are available in the ElevenLabs Voice Library for enterprise use cases across sectors OurStartup Grants Programhas so far supported over 500 Indian startups and developers with free access to ElevenLabs APIs ElevenLabsImpact Programthat partners with nonprofits focused on healthcare, accessibility, and education to provide free licenses for projects that drive social good, is set to be formally launched soon, with projects already underway We’re building an ecosystem where Indian businesses and creators can thrive locally and scale globally. Mati Staniszewski, Co-founder and CEO, ElevenLabs Looking Ahead With native Hindi and Tamil support already built into our models, and 12 Indian languages supported in V3 Alpha, we’ve prioritized regional accessibility from day one. Our platform is designed for India-scale adoption - whether that means supporting millions of customer interactions daily, powering multilingual content ecosystems, or enabling startups to build new categories on top of voice AI. As Indian enterprises and creators expand their reach, the demand for reliable, expressive, and truly multilingual voice AI infrastructure will only accelerate.With India-focused pricing, local GTM expertise, and compliance-first infrastructure, we’re committed to powering this growth at scale. What excites us most is that this is just the beginning. The appetite to build with voice AI in India is only getting stronger – and we’re here to be a long-term partner in that journey. If you’re building with voice AI in India, we invite you toget in touch with our team.]]></description>
      <pubDate>Tue, 25 Nov 2025 21:03:34 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/voice-ai-for-india-scale</guid>
    </item>
    <item>
      <title>Ukrainian Public Services Will Speak Through AI: Announcing a Partnership with ElevenLabs</title>
      <link>https://elevenlabs.io/blog/ukrainian-public-services</link>
      <description><![CDATA[The Ministry of Digital Transformation of Ukraine is launching a collaboration with ElevenLabs, the global leader invoice AItechnology. The company will help integrate voice interfaces into Ukrainian public services. This was announced by Mykhailo Fedorov at the IT Arena conference. “The future belongs to agentic states. Ukraine is already moving towards a model where interaction with the government is as simple as a single request or a voice message. Our partnership with ElevenLabs, a world leader in voice technology, gives our digital services a human voice and makes them more accessible to everyone. We have proven our capacity for large-scale innovation, and this collaboration will accelerate our transition to a proactive, agentic state where artificial intelligence genuinely makes citizens' lives easier,”stated Mykhailo Fedorov, First Deputy Prime Minister and Minister of Digital Transformation of Ukraine. The company's voice technology was first used to voice the digital twin of Mykhailo Fedorov, which operates as a chatbot. The twin recognizes voice messages and provides responses in the same format. “Together with Ukraine’s Ministry of Digital Transformation, we’re adding a clear human voice to digital services - starting with Minister Fedorov’s digital twin and soon expanding into Diia and other tools. Our goal is simple: make public services in Ukraine faster and more accessible for everyone.” -Mati Staniszewski, Co-founder & CEO, ElevenLabs ElevenLabs' technologies will also "give voice" to other public services. The plans include: Integrating voice AI into the Diia portal and application.This will allow citizens to voice their requests and receive services seamlessly. Driving innovation in educational platforms.Voice functionality will be added to state educational applications and initiatives. Adding voice capabilities to the Ministry’s internal tools.This includes AI assistants for onboarding and for the HR team. By combining cutting-edge Ukrainian public services with the world's best voice technologies, Ukraine continues to set the standard for the digital nations of the future.]]></description>
      <pubDate>Tue, 25 Nov 2025 21:03:34 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/ukrainian-public-services</guid>
    </item>
    <item>
      <title>Eleven Music is Here</title>
      <link>https://elevenlabs.io/blog/eleven-music-is-here</link>
      <description><![CDATA[Today, we launchedEleven Music– the next step on our mission to build the most comprehensive AI audio platform in the world. With Eleven Music, businesses, creators, artists, and every single one of our users can generate studio-grade music from natural language prompts, with: - Complete control over genre, style, and structure - Vocals or just instrumental - Multi-lingual, including English, Spanish, German, Japanese and more - Edit the sound and lyrics of individual sections or the whole song A few of our favorite samples Check out a few of our favorite songs generated by the ElevenLabs team thus far: Echoes of Midnight Prompt: “Dreamy, psychedelic, slow Indie Rock, reverb-soaked vocals, retro keys, catchy chorus, analog, phased guitars, liminal, nostalgic feeling, anthem.” Saddles and Shadows Prompt: “An epic track for a cowboy show, wild west, cinematic sound design, guitar twanging with awesome orchestral elements crescendoing to a powerful finale, soundtrack.” Don’t Let Me Go Prompt: “A very retro track from the 1950s with an old crooner male vocalist, charming, vintage, classic, nostalgic, golden oldies, vinyl crackle, catchy vocal hooks.” Obsidian Prompt: “Extremely dark, tense and powerful, cinematic sound design, electronic hybrid, trailer music, evil, braam, braam horns, impacts, boom, rising tension, completely instrumental.” Wanderer of the Moor Prompt: “A young english girl singing an old english folk song, stunning, lonely, thoughtful and almost haunting, fiddle and english folk instrumentation, reverb, short song.” Yellow Bus Jam Jam band song about driving through new york city in a big yellow school bus with 2 long guitar solos and lots of harmonizing We can’t wait to see what you create. Commercial use Created in collaboration with labels, publishers, and artists, Eleven Music is cleared for nearly all commercial uses, from film and television to podcasts and social media videos, and from advertisements to gaming. For more information on supported usage across our different plans,head here. Eleven Music is available today on our website and public API access (please seeeleven music API documentation), with public API access and integration into ourConversational AIplatform coming soon. Check out ourprompt engineering guideto help you master the full range of the model’s capabilities.]]></description>
      <pubDate>Tue, 25 Nov 2025 21:02:16 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/eleven-music-is-here</guid>
    </item>
    <item>
      <title>Building the First Agentic Government with Ukraine</title>
      <link>https://elevenlabs.io/blog/building-the-first-agentic-government-with-ukraine</link>
      <description><![CDATA[We travelled to Kyiv to deepen our partnership with the Government of Ukraine and signed a memorandum of understanding with Minister Mykhailo Fedorov to take AI public services from concept to production. The visit showed how Ukraine continues to build with purpose, clarity, and an engineering-first mindset focused on outcomes. Guided by the Ministry of Digital Transformation, we met with several ministries - Health, Education, Economy, and Foreign Affairs - each exploring how AI can make public services more efficient, accessible, and human. Ukraine is leading on that front, creating the world’s first agentic government - where AI agents work on citizens’ behalf across ministries, connecting national systems with individual needs. At the Ministry of Education, teams are developing Mriia, an app for personalised AI tutors that adapt to each learner’s knowledge and pace, and exploring agents to make educational content more accessible throughdubbingand translation. The Ministry of Economy is integrating agents into Obriy, a platform supporting businesses and gathering public feedback. In healthcare, speech technology is being used to reduce administrative work and make care more accessible. All these efforts are part of Ukraine’s plan, led by the Ministry of Digital Transformation, to become a leader in applying AI to public services by 2030. The ministry has already taken a first step with Diia.AI - the world’s first public-service agent app and platform - and we’re proud to support the ambition of making public services available through voice. Ukraine’s governance model - putting engineering at the heart of decision-making - is both natural and effective. Each ministry has its own technical team, building fast and iterating in the open. It’s a structure we relate to at ElevenLabs, where we embed engineers directly across functions to move ideas from prototype to production. The memorandum we signed marks the beginning of a shared effort to bring AI from concept to production across government. Our Forward Deployed Engineers remain in Kyiv, working alongside Ukrainian teams to turn these ideas into working systems. The main bottleneck in AI adoption has never been discovery - it’s deployment - and Ukraine is leading the way in making AI work for its people. We’re grateful to our partners - Mykhailo Fedorov, Oleksandr Bornyakov, Valeriya Ionan, Danylo Tsvok, Dmytro Ovcharenko, and Nelli Blinova - for their hospitality, openness, and collaboration. Ukraine’s pace of work is a reminder that innovation is not a luxury of peace but the quiet work of moving forward.]]></description>
      <pubDate>Tue, 25 Nov 2025 20:50:41 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/building-the-first-agentic-government-with-ukraine</guid>
    </item>
    <item>
      <title>Giving voice back to stroke survivors</title>
      <link>https://elevenlabs.io/blog/giving-voice-back-to-stroke-survivors</link>
      <description><![CDATA[Each year,more than 12 million people worldwide experience a stroke. For many, recovery involves relearning how to walk, think, and communicate. Some regain their speech fully. Others live with long-term motor-speech challenges that make verbal communication difficult or impossible. Today, on World Stroke Day, we’re proud to announce our partnership withStroke Onward. Founded by stroke survivors, Stroke Onward helps people navigate the emotional and identity challenges of rebuilding life after a stroke. Together, we aim to make voice restoration technology available to everyone who needs it, and to strengthen the community of those rebuilding life after stroke. Bringing voice restoration to the stroke survivor community Through this partnership, individuals affected by permanent speech loss can now apply for the ElevenLabs Impact Program. Approved applicants receive free access to our advancedvoice cloningandText to Speechtools, allowing them to create and use a digital voice that represents them authentically. For those living with dysarthria or other motor-speech impairments, this technology can help restore a vital part of their identity. It enables them to communicate naturally with loved ones, participate in conversations, and express themselves in their own voice. Stroke Onward Community Circle Stroke Onward has also launched theStroke Onward Community Circle (SOCC)—a free, online community where survivors, carepartners, and professionals connect around the emotional and identity sides of recovery. In a world that often focuses only on physical rehabilitation, SOCC creates space for everything else—the emotional, invisible, and deeply personal parts of rebuilding life after stroke. Members can join live events, share experiences, and access curated tools that support emotional recovery. By introducing ElevenLabs voice technology into this community, we hope to empower members to rediscover and reclaim their voices as a part of that recovery process. Our shared goal We believe everyone should have the ability to express themselves in their own voice. Partnering with Stroke Onward helps us reach people living with speech loss, ensuring that technology serves as an enabler, not a barrier, to human connection. On World Stroke Day, we’re reminded that recovery from stroke is about more than physical healing. It’s about rebuilding identity, connection, and purpose. Together with Stroke Onward, we aim to make that journey more accessible, helping survivors regain their voices and their sense of self. Learn more about the partnership and how to apply.]]></description>
      <pubDate>Tue, 25 Nov 2025 20:47:09 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/giving-voice-back-to-stroke-survivors</guid>
    </item>
    <item>
      <title>Immobiliare.it builds conversational real estate agent in days using ElevenLabs</title>
      <link>https://elevenlabs.io/blog/immobiliare</link>
      <description><![CDATA[Immobiliare.itis the largest real estate platform in Italy. As part of its transformation into an AI-native company, the team explored new ways to improve the experience for both users and agents — starting with how people interact with property listings. They built a conversational voice agent using ElevenLabs’Agents Platformto solve a long-standing problem in property marketplaces: sellers want to avoid spam calls, while buyers are often frustrated by a lack of response. Immobiliare’s new voice agent works on behalf of sellers to answer listing-specific questions, gather lead information, and summarize the interaction. It runs 24/7, responds in natural Italian, and was built in just days using ElevenLabs. From JSON to voice in minutes The original goal was to create an assistant that could take listing data in JSON format, hold a natural conversation with users, and return a structured summary of the interaction. While evaluating tools, the team started with OpenAI APIs. But when more flexibility and Italian language support was needed, the assistant itself, running inside a prototype built with Lovable, recommended ElevenLabs. They set up an ElevenLabs account, created a voice agent, and had it integrated in five minutes. The demo was shared with product leadership and quickly approved for further development. Building with speed and autonomy The team followed a two-stage build process: Prototype:Using n8n and ElevenLabs, they created a working backend that handled voice input and response generation using live listing data. Production:Once the prototype was stable, engineers implemented a scalable backend integration. Handoff was seamless thanks to early prompt tuning and data validation. This approach enabled rapid iteration with minimal engineering overhead. “Normally, after you launch a feature, there’s a short moment when the dust settles. You catch your breath, you wait for data to come in, you plan the next iteration. Not this time. With ElevenLabs, our feedback loop went from weeks to hours… Thanks to the transcripts, we could take a real conversation, tweak the prompt in staging, test multiple variations, and then push the change live to production. It felt like fine chiseling: every small adjustment brought the agent closer to behaving the way we needed it to.” –Gaia Businaro, AI Product Manager Better experiences for users and agents The AI agent helps Immobiliare.it solve two critical problems: User response quality:Every user receives an immediate, accurate, and human-sounding reply to their listing queries. Lead qualification:The agent asks questions to determine how interested the user is - filtering for serious inquiries. Adoption numbers confirm this shift, with more than 70% of sellers opting in. Lead qualification has risen from 19% to 63%, and the share of users providing a phone number for follow up has increased from 42% to 73%. Roughly 80% of users also rated the feature positively and early feedback indicates that buyers are more comfortable sharing personal details over voice than text, generating stronger and more actionable leads. “These early outcomes confirm that the ElevenLabs-powered voice assistant is the right solution to the problem we set out to solve. They give us the confidence to rapidly scale the approach across more listings and additional use cases.” -Paolo Sabatinelli, Chief Product Officer The result is higher satisfaction on both ends: users get the information they need quickly, and agents receive better leads with clear intent data.]]></description>
      <pubDate>Tue, 25 Nov 2025 19:48:01 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/immobiliare</guid>
    </item>
    <item>
      <title>ElevenLabs Welcomes Matthew McConaughey as New Investor</title>
      <link>https://elevenlabs.io/blog/elevenlabs-welcomes-matthew-mcconaughey-as-new-investor</link>
      <description><![CDATA[At ElevenLabs’ inaugural Summit, the company revealed thatAcademy Award-winning actor Matthew McConaughey has been a part of ElevenLabs story for years– as an investor, early supporter, and now, as a creator. In a video played at the Summit, Matthew McConaughey shared that his newsletter,Lyrics of Livin’, is expanding with a Spanish language version – powered by ElevenLabs. Now, Matthew’s stories and content will be made available in Spanish audio, using his unmistakable voice, and reaching an even wider audience. Subscribe here:https://lyricsoflivin.com/hola “I’m proud to share that I’ve been an investor in ElevenLabs for several years now,” said Matthew McConaughey. “It’s been amazing to see the growth from those early days to where the company, and the technology, is now. What’s remained constant is theextraordinary storytelling capabilities and creative potentialthat ElevenLabs unlocks – something that stood out to me from the start and that speaks to me as a professional storyteller.” “When I first met Matthew, I was struck by how genuinely he connected with our vision and what we’re trying to do at ElevenLabs,” addedMati Staniszewski, CEO and Co-Founder of ElevenLabs. “He wasn’t just excited by the tech – he understood what we’re aiming to achieve creatively. We’re so grateful for his continued insight and support, especially as we expand our work in the creative space.” [To see more highlights from the ElevenLabs Summit, visit:https://summit.elevenlabs.io/]]]></description>
      <pubDate>Wed, 12 Nov 2025 17:25:01 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/elevenlabs-welcomes-matthew-mcconaughey-as-new-investor</guid>
    </item>
    <item>
      <title>Honoring veterans and their voices: Lt Col Thomas Brittingham’s story</title>
      <link>https://elevenlabs.io/blog/honoring-veterans-and-their-voices-lt-col-thomas-brittinghams-story</link>
      <description><![CDATA[When Lt Col Thomas Brittingham first heard his own voice again, it was Mother’s Day and his wedding anniversary. His wife Jessi was sitting beside him when he typed out a short message using his new ElevenLabs voice: “Hey Jessi, does this sound like me? Happy Mother’s Day and Happy Anniversary. I love you.” The moment stopped her. “It brought tears to my eyes,” she recalled. “It was the most amazing gift I could have ever received—hearing his voice again.” Lt Col Thomas Brittingham A lifetime of service Lt Col Brittingham has dedicated his life to service and excellence. A 2006 graduate of the Coast Guard Academy and a 2004 Air Force Academy Exchange Cadet, he began his career aboard the Coast Guard Cutter Sequoia in Guam, where he conducted the first bilateral boardings of foreign ships in the Western Pacific. From there, his path led to commanding his own vessel, the Coast Guard Cutter Haddock, and later serving as Military Aide to the Coast Guard’s Chief Acquisition Officer, overseeing $30 billion in modernization programs. In 2011, he was selected for Air Force pilot training—a transition that would mark the next chapter in a distinguished career. Over the following decade, Lt Col Brittingham served as flight lead and mission commander across the Mediterranean, Atlantic, and Pacific. He deployed four times in support of Operation Inherent Resolve, logging nearly 1,000 combat hours. Confronting ALS In 2023, Thomas received a diagnosis that would change his life—amyotrophic lateral sclerosis (ALS). The disease began in his legs and moved upward, affecting his arms, diaphragm, and eventually his ability to speak. “His voice was always strong,” Jessi said. “Even as ALS progressed, it was something that made him feel like himself.” But as muscle weakness advanced, Thomas’s voice grew quieter until it disappeared entirely in April 2024. Without a natural voice, Thomas initially relied on a generic computer-generated one that was robotic and difficult to understand. “We depended mostly on reading his screen,” Jessi said. “It didn’t sound like him. It didn’t sound human.” Finding his voice again Through Team Gleason, a nonprofit that supports people living with ALS, Thomas connected withBridging Voice, an organization that helps individuals preserve and recreate their voices. There, he met Trinity, who guided him through the process of restoring his natural voice with ElevenLabs. Bridging Voice guided his family through the process—collecting past videos, preparing samples, and building a model of how Thomas sounded before ALS. “It was healing to go back through those clips,” Jessi said. “We watched them with our two boys, who loved hearing their dad’s voice again.” Once the recordings were submitted, the ElevenLabs team created a Professional Voice Clone for Thomas, a precise recreation of how he sounded before the disease. The moment it all came back When Thomas used his new AI voice for the first time, he chose to surprise Jessi. The words he typed carried all the warmth and cadence of his real speech. “I made him say it over and over again,” Jessi laughed. “Our family couldn’t believe how real it sounded. The boys thought it was hilarious hearing their dad’s voice saying silly things.” It wasn’t just a technological milestone, it was a return of identity, presence, and connection. “With two young children, it means everything for them to hear their dad’s voice,” Jessi said. “It keeps him present in their lives in a way that text alone can’t.” A message for Veterans Day For Lt Col Brittingham, Veterans Day carries deep meaning. It’s a reminder not only of service and sacrifice, but of the strength that comes from community and innovation. He hopes his story shows what’s possible when technology serves humanity, especially for veterans facing the challenges of illness or injury. Recent studies have shown that Air Force pilots are ten times more likely to be diagnosed with ALS than civilians. For Thomas, that statistic is personal. His experience underscores the urgency of advancing accessible technology that restores independence and dignity to those who have given so much in service. Continuing the mission TheElevenLabs Impact Programexists to help individuals like Lt Col Brittingham regain their voice and agency through AI. By combining advanced voice synthesis with human-centered design, the program ensures that every person can preserve the sound of who they are. Thomas’s journey, from commanding aircraft across the world to communicating again in his own voice, shows what this technology makes possible. When so much is taken away, being able to speak again, even through an artificial voice, gives something profoundly human back. This Veterans Day, we honor Lt Col Brittingham and all who have served, and recommit to building technology that gives them their voices back. It’s not just about speech. It’s about memory, identity, and the ability to stay connected to the people who matter most.]]></description>
      <pubDate>Tue, 11 Nov 2025 16:25:55 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/honoring-veterans-and-their-voices-lt-col-thomas-brittinghams-story</guid>
    </item>
    <item>
      <title>Deutsche Telekom and ElevenLabs announce strategic partnership to power AI-driven podcasting in Magenta App</title>
      <link>https://elevenlabs.io/blog/deutsche-telekom-magenta-ai</link>
      <description><![CDATA[We are partnering with Deutsche Telekom to integrate human-like AI voices into Magenta AI, giving users a new way to engage with content. ElevenLabs’ Gen FM technology will be embedded directly into Magenta AI, enabling users to convert news articles into immersive, high-quality podcasts in seconds. Users will also be able to generate custom podcast content based on pre-set prompts, such as“The Most Streamed Songs and Shows of 2025” This collaboration marks the beginning of a broader initiative between Deutsche Telekom and ElevenLabs, where AI-powered voice technology will enhance multiple touch points of the customer journey. The first phase focuses on podcast generation, with future plans to expand voice integration across additional DT services to deliver personalized, engaging and unique experiences to customers. Looking ahead As part of this partnership, Deutsche Telekom has also invested in ElevenLabs’ Series C funding round, reinforcing a shared vision to bring AI-powered audio experiences to millions of users. With this innovation, Magenta AI users will have the power to create, customize, and interact with unique audio content directly from their smartphones. Mati, Co-founder and CEO at ElevenLabs said:“Deutsche Telekom's long-standing leadership in telecommunications and voice innovation makes them the ideal partner to bring our AI voice technology to millions. Together, we're building on their rich heritage while defining the next generation of audio experiences.” Jon, Chief Product Officer at Deutsche Telekom said:“Not long from now, speech will become the standard for how we interact with technology. We always hoped for this, and now the technology that will enable this has caught up. At Deutsche Telekom we will always partner with the best in any domain...and in voice, the best is ElevenLabs. We're so convinced, we're also now investors. Stay tuned for how Telekom customers will start experiencing this new modality when they interact with our products.”]]></description>
      <pubDate>Wed, 29 Oct 2025 16:01:13 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/deutsche-telekom-magenta-ai</guid>
    </item>
    <item>
      <title>Introducing Agent Workflows</title>
      <link>https://elevenlabs.io/blog/introducing-agent-workflows</link>
      <description><![CDATA[Our agents platform now offers Workflows - a visual editor for designing conversation flows. Instead of building all business logic in a single agent, Agent Workflows let you handle complex scenarios by routing to specialized Subagents and, when needed, transferring to human operators. You map the flow, declare decision points, and control handoffs to Subagents or humans - making behavior explicit, auditable, and testable. This moves beyond a single large prompt so you can decompose tasks, apply guardrails, and orchestrate the right action at the right time. Scope context and tools with Subagents Subagents each have their own system prompt, tools, and scoped knowledge base. You choose which Subagent handles a task, what data it can access, and when to hand off to another agent or a human. This reduces prompt bloat, limits access to sensitive systems, and improves response quality with narrower context. Enforce security and business policy Workflows connect agents to your internal systems with scoped credentials and access. You can embed business rules - validations, approvals, thresholds, and escalation paths - so conversations follow the same policies your teams use today. Optimize for cost, latency, and accuracy With Agent Workflows, you can pick the ideal LLM for each step. Use lightweight models for classification and routing, and higher-accuracy models for complex reasoning. Because prompts and knowledge bases are scoped per Subagent, you reduce token usage and latency while improving precision. An example workflow Intake and classify the request with a lightweight model. Route billing questions to a billing Subagent with scoped tools and data and route technical issues to a support Subagent that can run diagnostics. Escalate to a human when confidence drops below a threshold or when approval is required. Return to the parent agent to summarize the outcome for the user. Start building Agent Workflows put you in control of how conversations are designed, routed, and supervised. Build structured, secure, and scalable agents with ElevenLabs Agents. To learn moreread the documentationor get started with setting upan Agent Workflow today.]]></description>
      <pubDate>Thu, 16 Oct 2025 15:57:02 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/introducing-agent-workflows</guid>
    </item>
    <item>
      <title>ElevenLabs scales UK and US presence</title>
      <link>https://elevenlabs.io/blog/elevenlabs-scales-uk-and-us-presence</link>
      <description><![CDATA[London, New York, San Francisco – September 15, 2025 – ElevenLabs, a leading AI audio research and deployment company, today announced continued expansion of its UK and US operations, underscoring its commitment to regional innovation ecosystems and long-term economic growth. Over the past year, its UK headcount grew from 18 to 68 and US headcount from 10 to 61, while the company’s European workforce expanded from 25 to 91. With offices in New York, San Francisco, Warsaw, Bangalore, Tokyo, and London, ElevenLabs is investing in local talent hubs and building the infrastructure needed to deliver real-time AI audio solutions for enterprises worldwide. As part of the UK AI ecosystem, ElevenLabs has worked closely with NVIDIA in the UK and globally. NVIDIA’s support has helped the company build faster and ship stronger products. ElevenLabs leverages NVIDIA Blackwell GPUs and accelerated software to build performant, scalable products, and collaborates with NVIDIA on developing new technologies. In August 2024, ElevenLabs launched an initiative to support people living with aphasia by providing free licenses to ALS (Amyotrophic Lateral Sclerosis) and MND (Motor Neuron Disease) patients. Since launch, the company has partnered with 268 non-profits and together created 3,472 voices. This program reflects ElevenLabs’ commitment not only to innovation, but also to broadening access and empowering individuals to participate fully in society and the economy. ElevenLabs technology is used by businesses across every sector for a wide range of use cases - from customer support and scheduling to education and entertainment - and at companies like Cisco, Epic Games, Adobe, Aston Martin F1, Synthesia and NVIDIA. This month, ElevenLabs announced a $100M Tender Offer at a $6.6B valuation, double their Series C valuation from just nine months ago. “We are building for the long term with the aim of creating a generational company. Continuous liquidity opportunities will help our whole team align on that goal.” said Mati Staniszewski, CEO and co-founder. For media inquiries or partnership opportunities, please contactpress@elevenlabs.io]]></description>
      <pubDate>Thu, 16 Oct 2025 15:49:52 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/elevenlabs-scales-uk-and-us-presence</guid>
    </item>
    <item>
      <title>Introducing Eleven v3 (alpha)</title>
      <link>https://elevenlabs.io/blog/eleven-v3</link>
      <description><![CDATA[We're pleased to revealEleven v3 (alpha)— the most expressive Text to Speech model. This research preview brings unprecedented control and realism to speech generation with: 70+ languages Multi-speaker dialogue Audio tagslike [excited], [whispers], and [sighs] Eleven v3 (alpha) requires moreprompt engineeringthan previous models — but the generations are breathtaking. If you’re working on videos, audiobooks, or media tools — this unlocks a new level of expressiveness. For real-time and conversational use cases, we recommend staying with v2.5 Turbo or Flash for now. A real-time version of v3 is in development. Eleven v3 is available today on our website and in theAPI. Why we built v3 Since launching Multilingual v2, we’ve seen voice AI adopted in professional film, game development, education, and accessibility. But the consistent limitation wasn’t sound quality — it wasexpressiveness. More exaggerated emotions, conversational interruptions, and believable back-and-forth were difficult to achieve. Eleven v3 addresses this gap. It was built from the ground up to deliver voices that sigh, whisper, laugh, and react — producing speech that feels genuinely responsive and alive. What’s new in Eleven v3 (alpha) Hear v3 for yourself Using audio tags Audio tags live inline with your script and are formatted with lowercase square brackets. You can see more about audio tags in ourprompting guide for v3 in the docs. Professional Voice Clones (PVCs) are currently not fully optimized for Eleven v3, resulting in potentially lower clone quality compared to earlier models. During this research preview stage it would be best to find an Instant Voice Clone (IVC) or designed voice for your project if you need to use v3 features. PVC optimization for v3 is coming in the near future. For example, you could prompt: “[whispers] Something’s coming… [sighs] I can feel it.” Or for more expressive control, you can combine multiple tags: Crafting multi-speaker dialogue Eleven v3 is supported in our existing Text to Speech endpoint. Additionally, we introduce a newText to Dialogue API endpoint. Provide a structured array of JSON objects — each representing a speaker turn — and the model generates a cohesive, overlapping audio file: The endpoint automatically manages speaker transitions, emotional changes, and interruptions. Learn morehere. v3 is our most expressive model Pricing and availability To enable v3: Use theModel Pickerand selectEleven v3 (alpha) API access and support in Studio are coming soon. For early access, pleasecontact sales. When not to use v3 Eleven v3 (alpha) requires more prompt engineering than our previous models. When it works the output is breathtaking but the reliability and higher latency means it’s not suitable for real-time and conversational use cases. For these, we recommend Eleven v2.5 Turbo/Flash. For more, refer to the fullv3 documentationand FAQ. Try it today Log in toElevenLabs UI Select v3 (alpha)in the model dropdown Paste your script — use tags or dialogue Generate audio We’re excited to see how you bring v3 to life across new use cases — from immersive storytelling to cinematic production pipelines. How does the Eleven v3 80% discount work? How were the samples in the video and website generated? How does dialogue generation work? Is this available over API? What audio tags are supported? What languages does it support?]]></description>
      <pubDate>Thu, 16 Oct 2025 15:13:17 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/eleven-v3</guid>
    </item>
    <item>
      <title>On track to help 1 million people regain their voice</title>
      <link>https://elevenlabs.io/blog/impact-program-v2</link>
      <description><![CDATA[We build AI to help people communicate. Through ourImpact Program, we provide free access to those who need it most. Last year, we started by supporting ALS patients. Now, we’re expanding to include people affected by Multiple System Atrophy (MSA) and mouth cancers. We’ve partnered withMSA Trust,Mission MSA, and theMouth Cancer Foundationto reach more people who lose their voice due to illness. These organizations work directly with patients, offering support, advocacy, and resources. How it works MSA Trust & Mission MSA: verified MSA patients get free lifetime access to ElevenLabs’ AI voice tools to create and use digital voice replicas. Mouth Cancer Foundation: patients in the UK diagnosed with oral and head and neck cancers can apply for a free Pro plan, letting them clone their voice before speech loss. Losing the ability to speak is deeply isolating. AI voice technology gives people a way to keep their voice, making communication feel familiar and natural. That’s why we’re committed to helping 1 million people through the Impact Program. If your non-profit could benefit from AI advancements,reach out to us.]]></description>
      <pubDate>Thu, 16 Oct 2025 14:33:16 GMT</pubDate>
      <guid isPermaLink="true">https://elevenlabs.io/blog/impact-program-v2</guid>
    </item>
  </channel>
</rss>
