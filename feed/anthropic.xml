<?xml version="1.0" ?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>Anthropic News</title>
    <link>https://www.anthropic.com/news</link>
    <description>Latest news from Anthropic</description>
    <language>en-US</language>
    <lastBuildDate>Wed, 03 Dec 2025 21:26:04 GMT</lastBuildDate>
    <generator>rfeed v1.1.1</generator>
    <docs>https://github.com/svpino/rfeed/blob/master/README.md</docs>
    <item>
      <title>Anthropic acquires Bun as Claude Code reaches $1B milestone</title>
      <link>https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone</link>
      <description>Claude is the world’s smartest and most capable AI model for developers, startups, and enterprises. Claude Code represents a new era of agentic coding, fundamentally changing how teams build software. In November, Claude Code achieved a significant milestone: just six months after becoming available to the public, it reached $1 billion in run-rate revenue. And today we’re announcing that Anthropic is acquiringBun—a breakthrough JavaScript runtime—to further accelerate Claude Code.  Bun is redefining speed and performance for modern software engineering and development. Founded by Jarred Sumner in 2021, Bun is dramatically faster than the leading competition. As an all-in-one toolkit—combining runtime, package manager, bundler, and test runner—it's become essential infrastructure for AI-led software engineering, helping developers build and test applications at unprecedented velocity.  Bun has improved the JavaScript and TypeScript developer experience by optimizing for reliability, speed, and delight. For those using Claude Code, this acquisition means faster performance, improved stability, and new capabilities. Together, we’ll keep making Bun the best JavaScript runtime for all developers, while building even better workflows into Claude Code.  Since becoming generally available in May 2025, Claude Code has grown from its origins as an internal engineering experiment into a critical tool for many of the world’s category-leading enterprises, including Netflix, Spotify, KPMG, L’Oreal, and Salesforce—and Bun has been key in helping scale its infrastructure throughout that evolution. We’ve been a close partner of Bun for many months. Our collaboration has been central to the rapid execution of the Claude Code team, and it directly drove the recent launch of Claude Code’snative installer. We know the Bun team is building from the same vantage point that we do at Anthropic, with a focus on rethinking the developer experience and building innovative, useful products.  &quot;Bun represents exactly the kind of technical excellence we want to bring into Anthropic,&quot; said Mike Krieger, Chief Product Officer of Anthropic. &quot;Jarred and his team rethought the entire JavaScript toolchain from first principles while remaining focused on real use cases. Claude Code reached $1 billion in run-rate revenue in only 6 months, and bringing the Bun team into Anthropic means we can build the infrastructure to compound that momentum and keep pace with the exponential growth in AI adoption.&quot;  As developers increasingly build with AI, the underlying infrastructure matters more than ever—and Bun has emerged as an essential tool. Bun gets more than 7 million monthly downloads, has earned over 82,000 stars on GitHub, and has been adopted by companies like Midjourney and Lovable to increase speed and productivity.  The decision to acquire Bun is in line with our strategic, disciplined approach to acquisitions: we will continue to pursue opportunities that bolster our technical excellence, reinforce our strength as the leader in enterprise AI, and most importantly, align with our principles and mission.  Bun will be instrumental in helping us build the infrastructure for the next generation of software. Together, we will continue to make Claude the platform of choice for coders and anyone who relies on AI for important work. Bun will remain open source and MIT-licensed, and we will continue to invest in making it the runtime, bundler, package manager, and test runner of choice for JavaScript and TypeScript developers. If you’re interested in joining Anthropic’s engineering team, visit ourcareers page. Anthropic launches Claude for Nonprofits to help organizations maximize their impact, featuring free AI training and discounted rates. The best model in the world for coding, agents, and computer use, with meaningful improvements to everyday tasks like slides and spreadsheets. Claude Opus 4.5 delivers frontier performance and dramatically improved token efficiency.</description>
      <author>Anthropic</author>
      <pubDate>Wed, 03 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone</guid>
    </item>
    <item>
      <title>Claude for Nonprofits</title>
      <link>https://www.anthropic.com/news/claude-for-nonprofits</link>
      <description>Anthropic launches Claude for Nonprofits to help organizations maximize their impact, featuring free AI training and discounted rates for nonprofits.</description>
      <author>Anthropic</author>
      <pubDate>Tue, 02 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.anthropic.com/news/claude-for-nonprofits</guid>
    </item>
    <item>
      <title>Introducing Claude Opus 4.5</title>
      <link>https://www.anthropic.com/news/claude-opus-4-5</link>
      <description>The best model in the world for coding, agents, and computer use, with meaningful improvements to everyday tasks like slides and spreadsheets. Claude Opus 4.5 delivers frontier performance and dramatically improved token efficiency.</description>
      <author>Anthropic</author>
      <pubDate>Mon, 24 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.anthropic.com/news/claude-opus-4-5</guid>
    </item>
    <item>
      <title>Claude now available in Microsoft Foundry and Microsoft 365 Copilot</title>
      <link>https://www.anthropic.com/news/claude-in-microsoft-foundry</link>
      <description>Claude Sonnet 4.5, Haiku 4.5, and Opus 4.1 models are now available in public preview in Microsoft Foundry, where Azure customers can build production applications and enterprise agents.</description>
      <author>Anthropic</author>
      <pubDate>Tue, 18 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.anthropic.com/news/claude-in-microsoft-foundry</guid>
    </item>
    <item>
      <title>Microsoft, NVIDIA, and Anthropic announce strategic partnerships</title>
      <link>https://www.anthropic.com/news/microsoft-nvidia-anthropic-announce-strategic-partnerships</link>
      <description>Today Microsoft, NVIDIA, and Anthropic announced new strategic partnerships. Anthropic is scaling its rapidly-growing Claude AI model on Microsoft Azure, powered by NVIDIA, which will broaden access to Claude and provide Azure enterprise customers with expanded model choice and new capabilities. Anthropic has committed to purchase $30 billion of Azure compute capacity and to contract additional compute capacity up to one gigawatt.  For the first time, NVIDIA and Anthropic are establishing a deep technology partnership to support Anthropic’s future growth. Anthropic and NVIDIA will collaborate on design and engineering, with the goal of optimizing Anthropic models for the best possible performance, efficiency, and TCO, and optimizing future NVIDIA architectures for Anthropic workloads. Anthropic’s compute commitment will initially be up to one gigawatt of compute capacity with NVIDIA Grace Blackwell and Vera Rubin systems.  Microsoft and Anthropic are also expanding their existing partnership to provide broader access to Claude for businesses. Customers of Microsoft Foundry will be able to access Anthropic's frontier Claude models including Claude Sonnet 4.5, Claude Opus 4.1, and Claude Haiku 4.5. This partnership will make Claude the only frontier model available on all three of the world's most prominent cloud services. Azure customers will gain expanded choice in models and access to Claude-specific capabilities.  Microsoft has also committed to continuing access for Claude across Microsoft’s Copilot family, including GitHub Copilot, Microsoft 365 Copilot, and Copilot Studio.  As part of the partnership, NVIDIA and Microsoft are committing to invest up to $10 billion and up to $5 billion respectively in Anthropic.  Anthropic co-founder and CEO Dario Amodei, Microsoft Chairman and CEO Satya Nadella, and NVIDIA founder and CEO Jensen Huang gathered to discuss the new partnerships: Amazon remains Anthropic’s primary cloud provider and training partner. Anthropic launches Claude for Nonprofits to help organizations maximize their impact, featuring free AI training and discounted rates. The best model in the world for coding, agents, and computer use, with meaningful improvements to everyday tasks like slides and spreadsheets. Claude Opus 4.5 delivers frontier performance and dramatically improved token efficiency.</description>
      <author>Anthropic</author>
      <pubDate>Tue, 18 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.anthropic.com/news/microsoft-nvidia-anthropic-announce-strategic-partnerships</guid>
    </item>
    <item>
      <title>Anthropic partners with Rwandan Government and ALX to bring AI education to hundreds of thousands of learners across Africa</title>
      <link>https://www.anthropic.com/news/rwandan-government-partnership-ai-education</link>
      <description>Anthropic is announcing a new partnership with the Government of Rwanda and African tech training provider ALX to bring Chidi—a learning companion built on Claude—to hundreds of thousands of learners across Africa. Rwanda's ICT &amp; Innovation and Education ministries are deploying Chidi within their national education system, while ALX will bring the tool to students across the continent through their technology training programs. With this initiative, university graduates and young professionals in countries across Africa will be able to use Chidi to learn new skills, like data analytics or cloud computing. And teachers in Rwanda can use it to plan lessons and help them support their students. This partnership represents one of the largest AI for education deployments on the continent, uniting ALX's commitment to empowering African talent, Anthropic's vision for accessible and responsible AI, and Rwanda's Vision 2050 to build an AI-ready workforce and accelerate digital transformation across Rwanda. Through this initiative, the Rwandan government will bring AI tools directly into the national education system. The government will enable AI training for up to 2,000 teachers, as well as a group of civil servants across the country, who will learn to integrate AI into their classroom practice. This training will give them hands-on experience using Claude to support how they teach, plan lessons, and improve their productivity day-to-day. Graduates of the Rwanda pilot will receive a year of access to Claude tools, such as Claude Pro for individuals and Claude Code for developer teams in government, while exploring Claude for Education with university educators, ensuring that this new literacy in AI continues to shape classrooms and the workplace long after the program ends. The Rwandan government sees this initiative as central to their Vision 2050 strategy. As Rwandans begin learning how to use AI, they will help advance the government's goal of building a knowledge economy—launching startups that solve local challenges, joining global companies that need their skills, and creating innovations that reshape industries. “Rwanda’s Vision 2050 places youth and technology at the core of national progress, and our goal is to build a workforce equipped for the opportunities of the 21st century,” said Paula Ingabire, Minister of ICT &amp; Innovation in Rwanda. “This collaboration allows us to explore innovative AI tools that could enhance learning, support educators, strengthen developer capabilities, and provide new forms of digital assistance across selected institutions. These areas remain under review, and by beginning capacity building for civil servants, we ensure our workforce gains the foundational skills to engage with emerging technologies responsibly.” &quot;Rwanda's comprehensive approach to embracing and integrating AI—training teachers, involving policymakers, and building a dedicated working group—creates the foundation for responsible AI deployment,” said Elizabeth Kelly, Head of Beneficial Deployments at Anthropic. “By working with the government and ALX, we're learning how to ensure AI serves local educational needs while reaching students at scale.&quot; Beyond Rwanda, ALX is deploying Chidi across its technology training programs throughout Africa. As one of the continent's largest technology training providers, ALX reaches over 200,000 students and young professionals. Through this partnership, all of their students will access Claude through Chidi, which will serve as a &quot;Socratic mentor&quot;—guiding learners through thoughtful questions, rather than providing direct answers. This approach helps students develop independent problem-solving skills while learning to work effectively with AI tools. Early results demonstrate Chidi's potential impact: since the tool was rolled out on November 4, learners have engaged in over 1,100 conversations and nearly 4,000 learning sessions, with nine out of ten users reporting positive experiences. Chidi is helping students work through complex coding challenges, understand data science concepts, and develop their problem-solving skills. &quot;This is not just about bringing technology to Africa; it's about co-creating the future of learning to unlock the continent's full potential,&quot; said Fred Swaniker, Founder and CEO of ALX. &quot;Chidi transforms how our students build their capabilities, their confidence, and ultimately their careers. As they master AI-powered learning today, they become the architects of Africa's technology-driven future tomorrow.&quot; Today’s announcement represents a new milestone in Anthropic's commitment to ensuring AI works for the public good by reaching students globally. It builds upon our focus on education partnerships that reshape how students and educators interact with AI worldwide. InIceland, we recently launched one of the world's first comprehensive national AI education pilots with the Ministry of Education and Children, giving teachers across the nation access to Claude to transform lesson preparation and student support. TheLondon School of Economicshas provided all students with access to Claude for Education, helping them develop critical thinking skills. And our expanded presence inIndia, where we're opening an office in Bengaluru, focuses on supporting the country's rapidly growing developer and startup ecosystem. These partnerships demonstrate a consistent approach to working closely with governments, educational institutions, and technology companies to ensure AI expands opportunity and serves the communities where it's deployed. We look forward to learning from these deployments, sharing what we've learned with the wider community, and continuing to support educators and learners as they shape AI's role in building our future. Anthropic launches Claude for Nonprofits to help organizations maximize their impact, featuring free AI training and discounted rates. The best model in the world for coding, agents, and computer use, with meaningful improvements to everyday tasks like slides and spreadsheets. Claude Opus 4.5 delivers frontier performance and dramatically improved token efficiency.</description>
      <author>Anthropic</author>
      <pubDate>Tue, 18 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.anthropic.com/news/rwandan-government-partnership-ai-education</guid>
    </item>
    <item>
      <title>Disrupting the first reported AI-orchestrated cyber espionage campaign</title>
      <link>https://www.anthropic.com/news/disrupting-AI-espionage</link>
      <description>A report describing an a highly sophisticated AI-led cyberattack</description>
      <author>Anthropic</author>
      <pubDate>Thu, 13 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.anthropic.com/news/disrupting-AI-espionage</guid>
    </item>
    <item>
      <title>The state of Maryland partners with Anthropic to better serve residents</title>
      <link>https://www.anthropic.com/news/maryland-partnership</link>
      <description>The state of Maryland hasannouncedit will use Anthropic's advanced AI models to improve government operations and better serve its more than six million residents. Under the new partnership, the state will deploy Claude across multiple state agencies to address several priorities: The partnership builds on Maryland’s existing use of Claude to improve its services. In June, Maryland launched a bilingual Claude-powered chatbot, simplifying information access for more than 600,000 Marylanders receiving SUN Bucks benefits, while reducing call center volume. Anthropic’s co-founder and CEO Dario Amodei met Maryland Governor Wes Moore this summer to discuss the immense potential for AI to help state governments address issues like getting benefits to those who need them. Our teams, alongside the Rockefeller Foundation and Percepta, have since worked to develop programs that meet Maryland’s needs and can serve as a model for other states across the country. Anthropic’s commitment to responsible AI deployment, including rigorous safety testing, makes Claude uniquely suited for sensitive government applications like these. Anthropic is pleased to help Maryland translate itsAI governance principlesinto tangible new initiatives that make public services more efficient, accessible, and responsive. Other public sector organizations interested in using Claude cancontact our public sector teamto learn more and get started. Anthropic launches Claude for Nonprofits to help organizations maximize their impact, featuring free AI training and discounted rates. The best model in the world for coding, agents, and computer use, with meaningful improvements to everyday tasks like slides and spreadsheets. Claude Opus 4.5 delivers frontier performance and dramatically improved token efficiency.</description>
      <author>Anthropic</author>
      <pubDate>Thu, 13 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.anthropic.com/news/maryland-partnership</guid>
    </item>
    <item>
      <title>Measuring political bias in Claude</title>
      <link>https://www.anthropic.com/news/political-even-handedness</link>
      <description>We want Claude to be seen as fair and trustworthy by people across the political spectrum, and to be unbiased and even-handed in its approach to political topics. In this post, we share how we train and evaluate Claude for political even-handedness. We also report the results of a new, automated, open-source evaluation for political neutrality that we’ve run on Claude and a selection of models from other developers. We’re open-sourcing this methodology because we believe shared standards for measuring political bias will benefit the entire AI industry. When it comes to politics, people usually want to have honest, productive discussions—whether that’s with other people, or with AI models. They want to feel that their views are respected, and that they aren’t being patronized or pressured to hold a particular opinion. If AI models unfairly advantage certain views—perhaps by overtly or subtly arguing more persuasively for one side, or by refusing to engage with some arguments altogether—they fail to respect the user’s independence, and they fail at the task of assisting users to form their own judgments. On our own platforms, we want Claude to take an even-handed approach when it comes to politics:1 One concrete way that we try to influence Claude to adhere to these principles is to use our system prompt—the set of overarching instructions that the model sees before the start of any conversation onClaude.ai. We regularly update Claude’s system prompt; the most recent update includes instructions for it to adhere to the behaviors in the list above. This is not a foolproof method: Claude may still produce responses inconsistent with the descriptions in the list above, but we’ve found that the system prompt can make a substantial difference to Claude’s responses. The exact language in the system prompt can be read in fullhere. Another way to engender even-handedness in Claude is through character training, where we use reinforcement learning to reward the model for producing responses that are closer to a set of pre-defined “traits”. Below are some examples of character traits on which we have trained models since early 2024 that relate to political even-handedness: This is an experimental process; we regularly revise and develop the character traits we use in Claude’s training but we're sharing these to give a sense of our longstanding commitment to even-handedness in our models. The above sections described our aspirations for Claude’s behavior, and the practical ways we attempt to meet those aspirations. But how do we measure this in Claude? We’ve been reporting assessments of political bias on each of our models since the release ofClaude Sonnet 3.7in February 2025. We use a “Paired Prompts” method, detailed below, which assesses whether a given model responds differently to requests on the same topic but from opposing political perspectives. We’ve now created an automated version of this evaluation, allowing us to test Claude’s responses across thousands of prompts covering hundreds of political stances, in a way that would be prohibitively labor-intensive with the previous manual version. Paired Prompts method The Paired Prompts method works by prompting a given AI model with requests for responses on the same politically-contentious topic, but from two opposing ideological perspectives. For example: The model’s responses to both of the prompts are then rated according to three criteria designed to detect different manifestations of political bias—some obvious, some more subtle: In this case, instead of human raters, we used Claude Sonnet 4.5 as an automated grader to score responses quickly and consistently. As an additional validity check, we ran tests on a subsample of prompts using different Claude models as graders, and using OpenAI’s GPT-5 as the grader. All grader prompts we used are available in the open-source repository accompanying this blog post. Models and evaluation setWe tested our most capable models, Claude Sonnet 4.5 and Claude Opus 4.1. These were both configured to have “extended thinking” mode off (that is, they were set to their default mode). These models included our latestClaude.aisystem prompt.  We also compared our models to a selection of those from other providers. The comparator models were:GPT-5(OpenAI) in low reasoning mode without system prompt;Gemini 2.5 Pro(Google DeepMind) with lowest thinking configuration without system prompt;Grok 4(xAI) with thinking on and with itssystem prompt; andLlama 4Maverick (Meta) with itssystem prompt.  We tested models in a setup that was as directly comparable as possible, including system prompts where publicly available. However, although we aimed to make fair comparisons, it was not possible to keep all factors constant given differences in model types and offerings. Differences in how models are configured might affect the results. We’ve also found that system prompts can appreciably influence model even-handedness. We tested the models using 1,350 pairs of prompts across 9 task types and 150 topics. We included prompts of the following categories in our evaluation: reasoning (argue that…), formal writing (write a persuasive essay…), narratives (write a story…), analytical question (what research backs up…), analysis (evaluate the evidence for…), opinion (would you support…), and humor (tell me a funny story…). Our evaluation set not only covers arguments for and against political positions but also ways in which users with different political leanings might ask Claude models for help. Even-handedness Claude Opus 4.1 and Claude Sonnet 4.5 had scores of 95% and 94%, respectively, on the even-handedness measure. Gemini 2.5 Pro (97%) and Grok 4 (96%) had nominally higher scores, but the differences were very small, indicating similar levels of even-handedness across these four models. GPT-5 (89%) and particularly Llama 4 (66%) showed lower levels of even-handedness in this analysis. Results are illustrated in the figure below. Opposing perspectives and refusals Although even-handedness is the primary metric in this evaluation, we also measured opposing perspectives and refusals, which capture different manifestations of bias. Both sets of results are shown in the figures below. A higher percentage of responses including opposing perspectives indicates that a model more frequently considers counterarguments. Results showed that Opus 4.1 (46%), Claude Sonnet 4.5 (35%), Grok 4 (34%), and Llama 4 (31%) were the most frequent to acknowledge opposing viewpoints. Conversely, a lower refusal rate in these contexts indicates a greater willingness to engage. Claude models show consistently low refusal rates, with Opus 4.1 slightly higher than Sonnet 4.5 (5% versus 3%). Grok 4 showed near-zero refusals, whereas Llama 4 had the highest refusal rate among all models tested (9%). Tests using other models as graders As noted above, we conducted a validity check where we ran similar analyses using models other than Claude Sonnet 4.5 as the grader. We considered two ways of testing grader reliability: per-sample agreement, and agreement of overall results. Per-sample agreement captures the probability that two grader models will agree that a pair of outputs are even-handed, present opposing perspectives, or compliant (that is, avoid refusals). As grader models using the same grader rubric, Claude Sonnet 4.5 agreed with GPT-5 92% of the time, and Claude Opus 4.1 94% of the time for even-handedness in the per-sample agreement analysis. Note that in a similar pairwise evaluation with human graders, we observed only an 85% agreement, indicating that models (even from different providers) were substantially more consistent than human raters. For the analysis of overall agreement, we took the even-handedness, opposing views, and refusal scores given to the models by the different graders and correlated them together. We found very strong correlations between the ratings of Claude Sonnet 4.5 and Claude Opus 4.1:r&gt; 0.99 for even-handedness;r= 0.89 for opposing views; andr= 0.91 for refusals. In the comparison between the ratings from Claude Sonnet 4.5 and GPT-5, we found correlations ofr= 0.86 for even-handedness;r= 0.76 for opposing views; andr= 0.82 for refusals. Thus, despite some variance, we found that results for the different forms of bias were not strongly dependent on which model was used as the grader. Our evaluation of political bias had a number of limitations: There is no agreed-upon definition of political bias, and no consensus on how to measure it. Ideal behavior for AI models isn’t always clear. Nevertheless, in this post we have described our attempts to train and evaluate Claude on its even-handedness, and we’re open-sourcing our evaluation to encourage further research, critique, and collaboration. A shared standard for measuring political bias will benefit the entire AI industry and its customers. We look forward to working with colleagues across the industry to try to create one. You can read the implementation details and download the dataset and grader prompts to run our Paired Prompts analysis atthis GitHub link. Using OpenAI’s GPT-5 grader, we ran tests on a subsample of prompts for additional validity of the automated Claude graders. The results are shown in the Appendix,available here. 1. Note that API users aren’t required to follow these standards, and can configure Claude to reflect their own values and perspectives (as long as their use complies with ourUsage Policy).  November 24, 2025 Anthropic launches Claude for Nonprofits to help organizations maximize their impact, featuring free AI training and discounted rates. The best model in the world for coding, agents, and computer use, with meaningful improvements to everyday tasks like slides and spreadsheets. Claude Opus 4.5 delivers frontier performance and dramatically improved token efficiency.</description>
      <author>Anthropic</author>
      <pubDate>Thu, 13 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.anthropic.com/news/political-even-handedness</guid>
    </item>
    <item>
      <title>Anthropic invests $50 billion in American AI infrastructure</title>
      <link>https://www.anthropic.com/news/anthropic-invests-50-billion-in-american-ai-infrastructure</link>
      <description>Today, we are announcing a $50 billion investment in American computing infrastructure, building data centers withFluidstackin Texas and New York, with more sites to come. These facilities are custom built for Anthropic with a focus on maximizing efficiency for our workloads, enabling continued research and development at the frontier.  The project will create approximately 800 permanent jobs and 2,400 construction jobs, with sites coming online throughout 2026. It will help advance the goals in the Trump administration’sAI Action Planto maintain American AI leadership and strengthen domestic technology infrastructure. We are proud to create good American jobs and bolster American competitiveness.  “We’re getting closer to AI that can accelerate scientific discovery and help solve complex problems in ways that weren’t possible before. Realizing that potential requires infrastructure that can support continued development at the frontier,” said Dario Amodei, CEO and co-founder of Anthropic. “These sites will help us build more capable AI systems that can drive those breakthroughs, while creating American jobs.&quot; Anthropic's trajectory is driven by our talent-dense technical team, our focus on safety, and our frontier research, including pioneering alignment and interpretability work. Every day more businesses, developers, and power users are trusting Claude to help them solve their most challenging problems. Anthropic serves more than 300,000 business customers, and our number of large accounts—customers that each represent over $100,000 in run-rate revenue—has grown nearly sevenfold in the past year. We selected Fluidstack as our partner for its ability to move with exceptional agility, enabling rapid delivery of gigawatts of power. “Fluidstack was built for this moment,” said Gary Wu, co-founder and CEO of Fluidstack. &quot;We're proud to partner with frontier AI leaders like Anthropic to accelerate and deploy the infrastructure necessary to realize their vision.&quot; The scale of this investment is necessary to meet the growing demand for Claude from hundreds of thousands of businesses while keeping our research at the frontier. We’ll continue to prioritize cost-effective, capital-efficient approaches to achieving this scale as our growth continues. Anthropic launches Claude for Nonprofits to help organizations maximize their impact, featuring free AI training and discounted rates. The best model in the world for coding, agents, and computer use, with meaningful improvements to everyday tasks like slides and spreadsheets. Claude Opus 4.5 delivers frontier performance and dramatically improved token efficiency.</description>
      <author>Anthropic</author>
      <pubDate>Wed, 12 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.anthropic.com/news/anthropic-invests-50-billion-in-american-ai-infrastructure</guid>
    </item>
    <item>
      <title>Introducing Claude Haiku 4.5</title>
      <link>https://www.anthropic.com/news/claude-haiku-4-5</link>
      <description>Claude Haiku 4.5 matches state-of-the-art coding capabilities from months ago while delivering unprecedented speed and cost-efficiency for complex tasks.</description>
      <author>Anthropic</author>
      <pubDate>Wed, 15 Oct 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.anthropic.com/news/claude-haiku-4-5</guid>
    </item>
  </channel>
</rss>
