<?xml version="1.0" ?>
<?xml-stylesheet type="text/xsl" href="style.xsl"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>Amazon AI News</title>
    <link>https://www.aboutamazon.com/artificial-intelligence-ai-news</link>
    <description><![CDATA[Latest news about AI at Amazon]]></description>
    <language>en-US</language>
    <lastBuildDate>Wed, 28 Jan 2026 09:47:16 GMT</lastBuildDate>
    <generator>rfeed v1.1.1</generator>
    <docs>https://github.com/svpino/rfeed/blob/master/README.md</docs>
    <item>
      <title>How 3 AI innovations are creating a better experience for candidates in Amazon’s hiring process</title>
      <link>https://www.aboutamazon.com/news/workplace/artificial-intelligence-resume-jobs-hiring-amazon</link>
      <description><![CDATA[Key takeaways Amazon uses AI in thehiring processto transform technical assessments, enable real-time interview transcriptions, and intelligently match candidates to roles based on skills and experience. With AI interview transcriptions, 83% of candidates report more engaging conversations. Candidates who are identified with AI job matching technology and reach the interview stage are 24% more likely to receive a positive outcome after their initial interview loop. At Amazon, innovation is woven into everything we do, including how we create great experiences for candidates interested in joining our teams. As generative artificial intelligence (Gen AI) continues to transform how we work and support our teams around the world, we have dedicated teams focused on reimagining our hiring process to better reflect how work gets done at Amazon. This approach allows candidates to showcase their best work in more creative, authentic ways, and further enhances our human-centered hiring, where technology reduces administrative tasks and augments human judgment. As part of that approach, we design our systems to focus on skills, preferences, experience, and qualifications, which allows candidates to spend time sharing what makes them unique. We continuously test our systems to ensure they align with Amazon’s Leadership Principles and uphold our commitment to fairness and security as we build teams that reflect the global customers we serve. Here are some examples of how we’re using AI to weave Amazon’s spirit of innovation and customer obsession into the hiring journey: 1. Building technical assessments that reflect real-world AI use The day-to-day experience of software development engineers (SDEs) has evolved significantly, with AI-assisted coding becoming an essential component of modern development environments. Our SDEs use Gen AI tools like Amazon Q , Cline, and Kiro to help with tasks like writing and documenting code, debugging, refactoring code, and assisting with testing . Gen AI is a key part of a SDE’s work, which is why we’ve reimagined our technical assessments to better reflect how SDEs are actually working. This new experience allows candidates to work with an interactive AI assistant on a real coding platform to mirror the kind of problem-solving our developers do every day, while still allowing candidates to demonstrate their distinct skills. "This new approach gives candidates a more authentic glimpse into how Amazon engineers work," said Girish Bajaj, vice president of Core Tech, Prime Video Studios. "It's helping us identify great builders while giving them a chance to experience what it’s like to build and invent at Amazon." Candidates find these assessments more relevant and engaging, with 87% of candidates reporting that the coding questions effectively relate to the role they're pursuing. 2. Making interviews more authentic with AI-powered transcription Historically, our employee interviewers have taken detailed notes during candidate interviews to support our data-driven evaluations. However, the process has often involved splitting attention between in-depth note-taking and facilitating authentic conversations with candidates. We’re exploring how AI can improve the quality and depth of candidate interviews with a new pilot that integrates recording and transcription capabilities directly into Amazon’s interview system. The system generates accurate and real-time transcripts, allowing interviewers to be fully present and focus on meaningful conversations with candidates. How to write your resume using generative AI from Amazon We require explicit consent from candidates before any interview recording begins, and we clearly explain what will be recorded, how the recordings will be used, and how long they'll be retained. Transparency is essential because we want candidates to feel comfortable and fully informed throughout their experience. The results speak for themselves: 83% of candidates report more engaging interactions with their interviewers following the rollout of this tool. "We set out to build features that enhance how we listen to, engage with, and evaluate every candidate,” said Troy Winters, vice president of Global Talent Acquisition. “We’re excited about the feedback and results we’re seeing so far and look forward to making these tools available to more candidates in 2026 and beyond.” 3. Using machine learning to better match candidates to roles Finding the right job match can be daunting—both for candidates searching through open roles and for recruiters evaluating applications. Our teams have developed technology that goes beyond keyword matching to intelligently recommend roles based on candidates' skills, experiences, and preferences. Whether someone is actively exploring opportunities at Amazon or their original application's role has been filled, the system proactively suggests other suitable positions—giving candidates another chance to be considered without having to start their search over from scratch. Everything you need to prepare for your in-person Amazon interview We've also built technology that evaluates how well candidates fit specific roles during the initial screening process. This assessment helps identify candidates who are potentially bar-raising for the position. Early results have been encouraging: When we use this matching technology, candidates that move to the interview stage are 24% more likely to receive a positive outcome after their initial interview loop compared to those evaluated without it. Together, these capabilities create a smoother path to matching talented individuals with roles where they can make an impact from day one. Amazon’s hiring commitment As we continue to evolve our candidate and hiring processes, one thing remains constant: Our commitment to building innovative teams that invent and deliver for customers. We maintain transparency with candidates around when and how AI is used in the hiring process because we believe candidates deserve to understand when they're interacting with AI. Additionally, every AI solution we develop undergoes regular and rigorous testing to ensure it meets our robust requirements for fairness, security, and effectiveness, helping us to drive the right outcomes. We're continuing to explore ways AI can enhance the hiring process, including helping hiring managers create clear and effective job descriptions, providing recruiters with additional insights and tools, streamlining the application process, and more—all while maintaining the same high standards and customer focus that have always made Amazon a great place to work. Next, learn more about what it’s like to work at Amazon and explore open positions .]]></description>
      <pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/workplace/artificial-intelligence-resume-jobs-hiring-amazon</guid>
    </item>
    <item>
      <title>Amazon One Medical introduces agentic Health AI assistant for simpler, personalized, and more actionable health care</title>
      <link>https://www.aboutamazon.com/news/retail/one-medical-ai-health-assistant</link>
      <description><![CDATA[Key takeaways Amazon One Medical's Health AI assistant provides 24/7 personalized health guidance based on your medical records. The assistant explains lab results, books appointments, and manages medications with HIPAA-compliant security. Clinical safeguards ensure members connect with providers when medical expertise is needed. Amazon One Medical launched its Health AI assistant in the One Medical app today. The agentic assistant is an AI-forward feature that makes getting health care even simpler, more highly personalized, and more actionable by answering health questions, booking appointments, and managing medications. Amazon One Medical introduces Pay-per-visit healthcare for kids 2 to 11 Co-developed with One Medical's clinical leadership, the Health AI assistant provides 24/7 personalized health guidance grounded in each patient's unique medical history. And when clinical expertise is needed, the assistant seamlessly connects patients to their care team via messaging or by booking a same or next day appointment. What does Amazon One Medical's Health AI assistant do? Available now to Amazon One Medical members in the One Medical app, Health AI helps patients take charge of their health with personalized insights drawn from their complete medical records, lab results, and current medications—all protected with Health Insurance Portability and Accountability Act (HIPAA)-compliant privacy and security safeguards. Unlike generic health information tools, Health AI understands your medical context without requiring you to manually upload your personal information from multiple health care providers and services. It delivers tailored guidance that considers your past health care concerns, test results, vaccinations and current medications. Health AI in the One Medical app can: Answer general and complex health questions by explaining your lab results, considering your unique health history, and explaining what this information means for you. Provide 24/7 health guidance on symptoms, conditions, potential treatments, and wellness questions. Help you choose the right care option based on your specific situation. This includes a virtual visit, an in-person appointment, or urgent care. Streamline your ongoing care tasks, including helping you book appointments with your One Medical provider, or renew medications, which you can choose to fill with Amazon Pharmacy. “The U.S. health care experience is fragmented, with each provider seeing only parts of your health puzzle,” said Neil Lindsay, senior vice president of Amazon Health Services. “Health AI in the One Medical app brings together all the pieces of your personal health information to give you a more complete picture—helping you understand your health, and supporting you in getting the care you need to get and stay well. Health AI makes getting health care easier and more convenient, so patients can focus on what matters most: their health.” How does Health AI work with your One Medical provider? Health AI is designed to complement—not replace—the trusted relationship between patients and their health care providers. One Medical’s clinical leadership has been deeply involved in every stage of development, embedding multiple patient safety guardrails and clinical protocols, including for emergency and sensitive clinical situations, throughout the experience. Amazon One Medical review: How accessible primary care supported my cancer journey Health AI recognizes when symptoms, situations, or specific queries require or benefit from human clinical judgment and provides options for members to seamlessly connect with their One Medical provider and care team through messaging, an immediate video call, or an in-person appointment. For example, if a member reports concerning symptoms or has specific clinical criteria that warrant in-person evaluation, Health AI will recommend the appropriate level of care and even make a virtual or in-person appointment, often for the same or next day, or in minutes when needed. “Even as AI capabilities expand, the patient-clinician relationship—built over time and rooted in shared humanity—remains crucially important and irreplaceable,” said Dr. Andrew Diamond, chief medical officer at One Medical. “Our Health AI enhances this relationship by helping members understand their health information and manage their routine health tasks, coaching them to stick to their health program, and quickly connecting them to their trusted providers when they need the care and expertise of a human clinician.” How does Health AI protect patient privacy and security? Amazon Health Services, which includes One Medical and Amazon Pharmacy, has a strong track record of protecting customers’ health information with HIPAA-compliant privacy and security practices. The Health AI assistant maintains these same rigorous standards. Here’s how: Conversations with the Health AI assistant are not automatically added to your medical record. Health data is protected with strict administrative, physical, and technical safeguards—including encryption technology and strict controls over who can access your records. Amazon does not sell members’ personal data, including protected health information. Amazon Pharmacy announces updates to simplify medication management for millions of US customers “We’re committed to developing responsible, reliable AI that makes our members’ lives better,” said Prakash Bulusu, vice president of Health Stores & Technology at Amazon Health Services. “Health AI in the One Medical app excels at connecting the dots across a member’s complete health picture while maintaining rigorous safety standards—empowering informed decisions 24/7 with providers always in the lead.” You have full control. Members who don’t wish to use the Health AI assistant can access the standard One Medical app experience by simply tapping “Home” on the bottom navigation bar in the app. Continuously improving on behalf of our members and patients A Health AI assistant has been available to select One Medical members in beta since early 2025. One Medical has been and will continue to actively collect feedback from members and clinicians—continuously improving the accuracy, helpfulness, and capabilities of the experience—with new features planned to further enhance the membership experience. The Health AI assistant, which is powered by models on Amazon Bedrock, is now live for all One Medical members in the One Medical app. While a One Medical membership is not required for scheduled in-person or remote appointments, One Medical membership can be added as a Prime benefit for $9 per month or $99 per year for Amazon Prime members or purchased at One Medical . To learn more, visit Amazon Health Services . Frequently Asked Questions]]></description>
      <pubDate>Tue, 20 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/retail/one-medical-ai-health-assistant</guid>
    </item>
    <item>
      <title>AWS is committed to customer choice and flexibility, accelerated by AI</title>
      <link>https://www.aboutamazon.com/news/policy-news-views/aws-customer-choice-multicloud-ai-tools</link>
      <description><![CDATA[Key takeaways AWS offers multicloud tools, supports open standards, and waives data-transfer fees when switching providers. AI enhances customer choice by enabling easier data transport between IT providers. Competition is thriving, with prices falling and new cloud providers emerging globally. At AWS , customer obsession is the foundation of everything we do. We empower our customers to choose the IT services that work best for them and their diverse needs, whether that means AWS’s own services or other IT providers. This commitment to customer freedom is embedded in AWS’s principles. Not only do we offer a range of services, but we help customers mix and match the services they want, reduce fees and technical obstacles to interoperability, and allow customers to move their data around. Just as AWS pioneered cloud services that made it far easier for customers to freely move between IT providers, we continue that tradition today—not because we are required to, but because our customers demand it. Amid recent regulatory developments, we welcome the opportunity to contribute to the ongoing public dialogue on how to ensure innovation and competition thrive in this sector—one that AI is revolutionizing by the day. Latest news about AWS at Amazon How are cloud and AI promoting competition? AWS’s commitment to customer choice exists within an IT industry that is rapidly evolving. When AWS launched in 2006, virtually all organizations ran their IT “on premises” in their own offices or data centers. This required significant upfront investments and made switching expensive, as it often involved replacing hardware and software entirely. Today, more than 85% of IT services remain on premises, according to one leading analyst. But now customers have far more choices: They can choose from well-established cloud providers like AWS, Microsoft, Google, and Oracle. Strong European cloud providers have emerged, such as OVH Cloud, IONOS, Scaleway, and SAP, along with EU telecom providers like Deutsche Telekom. Chinese cloud providers like Alibaba, Huawei, Tencent, and Baidu continue strengthening their offerings. And over the last several years, the massive AI boom has spurred new cloud providers around the world, with entrants like CoreWeave, Lambda Labs, Vultr, Nebius, IREN, Fluidstack, Nscale, and Crusoe. Many other IT providers, such as Dell and HPE, are expanding their AI offerings. The growth opportunity for these and many other new cloud providers is attracting billions of dollars in infrastructure investments worldwide. This competition is working for customers: as cloud computing has grown, prices have fallen, with AWS alone reducing prices at least 161 times since its launch. Independent researchers found that AWS’s quality-adjusted prices fell over an eight-year period by an average of 7% annually for compute, 11% for databases, and 17% for storage products. Researchers also found that the global price index for on-demand general-purpose compute offerings has decreased 39% between 2016 and 2023. This sustained competition and declining prices are occurring even as prices across other sectors of the global economy continue to rise. AWS enables customer choice AWS has been at the forefront of developing solutions customers can use to build and deploy applications in any environment, and we continue to lead in facilitating customer choice in the age of AI. Over the next few years, we expect to see billions of AI agents working alongside humans to augment their capabilities, accelerate innovation, and improve productivity across every industry. There will be thousands of companies making and deploying AI applications, services, and agents, and this period of change will be as transformative as the advent of the internet. To facilitate customer choice and flexibility in this new era, AWS is developing and adopting groundbreaking tools for customers building AI agents and applications. Here are a few recent examples, including a wave of innovations announced in December 2025 at our annual conference, AWS re:Invent : Enabling customers to work with multiple cloud providers.AWS Interconnect - multicloudis a new capability that simplifies multicloud connectivity between AWS and other cloud providers. AWS Interconnect makes it even easier for customers to connect their systems on AWS with those on other cloud providers. To simplify global connectivity and support wider adoption, AWS Interconnect has published API specifications so that other cloud providers and partners can use the same standards and help improve them. This is the first purpose-built product of its kind; it is starting in preview with Google Cloud as the first launch partner and then with Microsoft Azure later in 2026. Adopting open communication standards for AI agents.We adopted open standards from Anthropic (called “MCP”), helping AI agents connect to applications, and Google (called “A2A,” or agent-to-agent), helping AI agents connect to each other. By supporting multiple standards, we ensure developers can choose the best standard for their agentic applications. This supports our customers’ ability to work with any cloud provider and makes it easier for different systems to work together—like common languages that let different computer systems communicate, even if built by other companies. Providing broad access to AI frameworks, models, and tools.We’ve designed our toolkits for building AI applications and AI agents to give customers options and flexibility. OurAmazon Bedrocktools for building AI applications empower AWS customers to choose from more than 100 differentfoundational AI modelsfrom dozens of different companies and easily connect their applications to these models. AWS customers can also useAmazon Bedrock AgentCoreto build AI agents using any model or tool they choose (even those that don’t currently run on Amazon Bedrock) and then easily run those agents on a different cloud provider if they wish. Providing open-source tools that enable customers and competitors to develop AWS-compatible technologies.AWS provides software development kits (SDKs)—tools that speed development by providing ready-made building blocks instead of requiring developers to write from scratch—publicly available under open-source licenses, allowing anyone to write interoperable applications to work with AWS APIs. As an example, Amazon S3 (one of our core storage offerings) offers open APIs and SDKs for customers. This allows competitors and open-source projects to make their storage solutions S3 compatible and ensures customers can use familiar tools while retaining the choice of different IT providers.Strands Agents, AWS-developed open-source AI SDKs, further simplify the development process for AI agents by allowing them to easily communicate with each other in just a few lines of code. AWS re:Invent News Switching providers has never been easier Changing IT providers has always required time, effort, and cost, but moving between cloud and other IT services has never been cheaper or easier than it is today. AWS has long had a policy allowing customers to move 100 gigabytes of data per month free to the internet—a benefit that covered over 90% of AWS customers. In 2024, we went a step further and waived data-transfer charges for all customers who want to move their data away from AWS. Meanwhile, AI is bringing unprecedented changes and innovation to the sector—including how IT customers move their work around. AI is creating demand for new features that drive competition and reducing the complexity of managing IT solutions across different environments. Customers can now point an AI tool at code written for one cloud provider's services and have it rewrite that code for another's—quickly and efficiently. For example, customers can use AI tools like Kiro (an AWS AI-powered development assistant), AWS Transform , Claude, ChatGPT, or other AI-related services to help rewrite their software to work with different providers. If an IT provider can't offer a specific solution, agentic AI will allow customers to more easily move all or some of their work to another location by automating the process. Against these transformative AI changes, AWS Interconnect also increases customer flexibility by creating high-speed connections between AWS and other cloud providers. These market-driven developments demonstrate the sector’s remarkable capacity for innovation in addressing customer demand. Our commitment to customers Moving forward, AWS will continue to deliver cloud solutions that work for businesses and other organizations worldwide. We welcome thoughtful dialogue with stakeholders globally about how to best serve customers in this rapidly evolving sector. Our commitment remains unchanged: empowering customer choice, fostering flexibility, and competing vigorously to earn customer trust every single day.]]></description>
      <pubDate>Mon, 19 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/policy-news-views/aws-customer-choice-multicloud-ai-tools</guid>
    </item>
    <item>
      <title>How Amazon leaders use AI: Life hacks from top executives</title>
      <link>https://www.aboutamazon.com/news/innovation-at-amazon/amazon-leaders-ai-productivity-life-hacks</link>
      <description><![CDATA[Artificial intelligence is transforming how people work and live, and Amazon’s leaders are no exception. From using Rufus to automate shopping and track price drops, to leveraging Alexa+ to bring handwritten family recipes to life in the kitchen, executives across Amazon are finding creative ways to integrate AI into their daily routines. These aren’t futuristic experiments—they’re practical tools that help busy professionals manage family calendars, discover new books, code with their kids, and stay connected across time zones. Here’s how five Amazon leaders are using AI to simplify tasks, boost productivity, and make more time for what matters most. Amazon’s next-gen AI assistant for shopping is now even smarter, more capable, and more helpful Amazon’s next-gen AI assistant for shopping is now even smarter, more capable, and more helpful Alexa+ now redefines music intelligence in the Amazon Music app New Kindle feature offers instant spoiler-free answers to questions about your books Alexa+ expands to Samsung TVs, BMW cars, and more in 2026]]></description>
      <pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/innovation-at-amazon/amazon-leaders-ai-productivity-life-hacks</guid>
    </item>
    <item>
      <title>5 things to know about Peter DeSantis, Amazon's new leader for AGI, chips, and quantum computing</title>
      <link>https://www.aboutamazon.com/news/innovation-at-amazon/peter-desantis-amazon-artificial-general-intelligence</link>
      <description><![CDATA[Key takeaways DeSantis has spent 27 years at Amazon, leading transformative technologies from EC2's launch to AWS Infrastructure. His new organization unites AI models, custom silicon, and quantum computing—technologies he sees as naturally reinforcing each other. Amazon's combination of world-class compute resources and real-world applications attracts scientists who want their work to ship at massive scale. When Peter DeSantis joined Amazon in 1998, the company was known primarily as an online bookstore. Over the next 27 years, he would help build some of the most transformative technologies in computing history—from leading Amazon EC2’s launch in 2006 to spearheading the 2015 acquisition of Annapurna Labs , which builds Amazon's custom silicon. Now, as Senior Vice President overseeing a new organization that spans the most expansive AI models, custom silicon, and quantum computing, DeSantis is bringing together some of the most compelling emerging technologies of today. His sweeping portfolio includes the teams building Amazon Nova foundation models, developing Graviton and Trainium chips , and advancing quantum computing solutions —technologies that, in his view, will increasingly reinforce and accelerate each other. The organization is so new that it doesn't have an official name yet (but DeSantis and his teams are working on it). With a track record of solving problems "at the edge of what's technically possible" while delivering technologies that operate reliably at massive scale, DeSantis combines unusual technical depth with a relentless focus on customer needs. As these foundational technologies mature and interweave, his leadership will help shape how Amazon—and the broader technology industry—approaches the next generation of computing. Here are 5 things to know about the leader guiding Amazon's most ambitious long-term technology bets—in his own words. 1. DeSantis sees custom chips, AI models, and quantum computing as reinforcing technologies All three of them are big, long-term bets for the company, and addressing them requires a similar approach, which is to blend our short-term urgency for delivery and roadmap planning with a long-term vision of where these technologies need to go in order to best serve our business and our customers. There are also more tangible ways that these technologies will reinforce each other. I think the most obvious one is the foundational model. My belief—and largely the industry's belief—is that these AI models are going to get bigger and more capable and more profoundly impact what we can do with them and how they change our lives. But to do that, we have to invest a large amount of capital and compute to build these models. One of the ways that we can give ourselves an advantage in how we build these models is by using our deep investments in chips to deliver both performance and cost efficiency that will allow us to differentiate our model development. A city in the palm of your hand: Exploring the intricate world of an Amazon Web Services chip The science that's happening inside of our foundational model teams—knowing where those models are going to go because of where the science is going—is going to influence our chips roadmaps. And chips take many years to build. Getting these two groups correctly working with each other, which, in a very Amazon way, will be loosely coupled, not tightly coupled, so that they are helpful to each other but not slowing each other down—it has a lot of potential. Quantum is, of the three, the longest-term thing that we're working on. It's going to be many years before we see the impact of quantum computing on the world, but I have very high conviction we will see it in our not-so-distant future. Ultimately, we are building a quantum chip . And now there's a lot of science that's happening in terms of how we use that chip in very, very different ways to build a very, very different kind of computer. As we get closer and closer to the point where we're ready to build that, scale that chip up and bring it to customers' hands, the things we've learned in our Annapurna chips business are going to be very complementary to that investment. It'll help us move even faster, scale even faster, and hopefully get to the very significant societal and technology goodness that's going to come with having a quantum computer. 2. He's most excited about getting Graviton 5, Trainium3, and Nova Forge into customers' hands I'm excited about a ton of things in the chips business, which I'm most familiar with because I've been involved in it since we got started over a decade ago. We just released Graviton 5 at re:Invent , which is by far our highest-performing general purpose processor ever. It will deliver the things that our customers have been most excited about with Graviton, which is differentiated performance, differentiated cost, and it will deliver that to almost every imaginable workload. Whereas if you go back a couple generations with Graviton, there was a subset of workloads that couldn't take advantage of it. Graviton 5 has truly gotten Graviton to the point where any workload that you want to run in the cloud probably runs best on Graviton. And the customer enthusiasm for Graviton has been huge, and we just released it, so the excitement is there. Now we have to bring it in volume. That's been an exciting part of getting the year started. Frontier agents, Trainium chips, and Amazon Nova: key announcements from AWS re:Invent 2025 Similarly, Trainium3 was just released and is one of the most exciting AI accelerators in the market. We're talking to a large number of customers that are excited about trying it, and we're excited to get it into their hands, get feedback from them, and hopefully get them running in meaningful ways on it. I spent a bunch of time at re:Invent this year with our customers on how they're thinking about Nova and particularly some of the new capabilities we launched. I would personally say Nova Forge, which is our capability that allows you to take our Nova models and take your data and your business expertise and produce what we call a Novella—a variant of that Nova model that's been deeply customized for your use case—is resonating with customers. I just got done talking to that team, and it's important that we get that in customers' hands. 3. He plans to deepen Nova integration across retail, Alexa, ads, and operations Nova is such an important part of our strategy in all of our core businesses—whether it's retail, or Alexa , or ads , or even operations —and each of these businesses has fundamentally different needs. A model that works great for shopping doesn't automatically work for Alexa. A model optimized for ads has different requirements than one built for fulfillment centers. So the real challenge isn't just building a great foundation model. It's figuring out how to make one model flexible enough that each business can shape it to their specific problems without losing the core intelligence underneath. That's harder than it sounds. We're still early in understanding what that looks like at scale. We've seen promising signals with teams taking Nova and customizing it for their use cases, which led to the recent launch of Nova Forge —allowing any business to build its own frontier model. But it's still early days. We're learning that we need to think differently about what comes next. I'm very much looking forward to having deeper conversations with our teams—learning how it's going today and where it can be improved as we look ahead. The honest answer is we're figuring this out together. My job is to listen, learn, and make sure we're building the right capabilities to support them. I expect that will involve conversations with my peers, but also much deeper conversations with their teams. 4. DeSantis says Amazon attracts missionaries who want to build transformative technology that ships Amazon is the best place for missionaries who want to build for customers. We’re uniquely long-term focused as a company. If we are convicted about something, we will see it through to success. The best example I know is AWS itself. When I first joined AWS, there was a lot of skepticism across the company about our investment in this new business. There was concern it would distract us and a belief that it would never be meaningful for Amazon. That seems silly now, but that’s really what a lot of people thought—internally and externally. Our leadership and team stayed convicted, and we all see how that turned out. We have similar conviction in chips, AI foundational models, and quantum computing. We also have some really unique assets to build with at Amazon. Our scientists have direct access to world-class compute resources—including GPUs and custom Trainium chips—AWS's global infrastructure, and real-world applications spanning Alexa, retail, logistics, and enterprise services. It’s really hard to find any of these anywhere else, but here we’re blessed with all these tailwinds to our investments. Introducing Alexa.com, a completely new way to interact with Alexa+ That combination attracts missionaries who want to build transformative technology that actually ships and makes a real difference in customers' lives. It's not just about publishing papers or winning benchmarks—it's about seeing your work in the hands of customers at massive scale. 5. After 27 years, he says Amazon still operates like the startup he joined One of the things that keeps me here is that, in a lot of the most important ways, the company hasn't changed. We're still focused on customers. We're still focused on building cool things. We are still in many, many ways like the startup that I joined 27 years ago. We're obviously much bigger, and so there's a lot more going on, which is fun. We've always been a company where there's been a ton of ground-up innovation that happens all over the place. Even when we were much smaller, you were often surprised that somebody was working on something that you had never heard about. Even with my relatively broad vantage point on what's going on in the company, I stumble into all sorts of things every day that I didn't know we were doing—which is cool. Learn more about how Amazon is transforming customers' lives with generative AI and agentic AI innovations .]]></description>
      <pubDate>Tue, 06 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/innovation-at-amazon/peter-desantis-amazon-artificial-general-intelligence</guid>
    </item>
    <item>
      <title>CES 2026: Key announcements from Amazon</title>
      <link>https://www.aboutamazon.com/news/devices/amazon-ces-2026-fire-tv-ring-alexa-plus</link>
      <description><![CDATA[The Consumer Electronics Show (CES) 2026 has kicked off, and Amazon is showcasing a vision for AI that focuses on making customers’ lives easier. From a Ring camera that catches something you might have missed to Alexa+ surfacing information before you ask for it, Amazon's latest innovations demonstrate ambient AI: products and experiences that are there when you need them and disappear into the background, always ready, when you don’t. Expedia, Yelp, Angi, and Square to build new agentic experiences for Alexa+ At this year's event in Las Vegas, Amazon is introducing new products across entertainment, smart home, security, and more. A redesigned Fire TV user interface promises to get customers to what they want to watch faster. Alexa+ is expanding beyond voice to the web and extending its capabilities with integrations across more devices. Ring is rolling out sweeping new security solutions. And Bee, the newest addition to Amazon’s Devices & Services, is serving up wearable AI with features designed to understand daily habits and offer proactive assistance. Here's a look at what Amazon is announcing this year: Ring launches new AI-powered features and devices, including Fire Watch Ring is announcing new features and devices to help make your neighborhood safer and give you peace of mind, wherever you are. One of these features is Fire Watch, a powerful new feature in the Neighbors section of the Ring app that delivers earlier warnings and real-time information during fast-moving fire events, enabling Ring camera owners to share snapshots while cameras analyze video for visual signs of smoke or fire. The feature is made possible through Ring's work with Watch Duty. Ring is also introducing the Ring Appstore, a new experience inside the Ring app that gives customers more ways to use their existing Ring cameras through third-party apps built by trusted developers. Alexa+ can now answer your Ring doorbell and talk to visitors Additionally, with Ring Sensors, a new lineup of smart security devices built on Amazon Sidewalk, Ring is delivering always-on protection without Wi-Fi range limits, hubs, or base stations, with three seamless layers—Security, Safety, and Control—that work together to protect your home, prevent damage, and simplify everyday routines. Read more about Ring's announcements . Amazon debuts cleaner and faster Fire TV experience, new Amazon Ember Artline lifestyle TV, and redesigned mobile app Amazon is overhauling the Fire TV experience with a redesigned interface that's up to 30% faster in some cases and better organized around content types like movies, TV shows, and sports. The update includes dedicated homes for each category, letting customers browse titles across all their subscriptions in one place. We are also launching our first lifestyle TV, the Amazon Ember Artline, a beautiful 4K QLED TV with a matte display, access to over 2,000 pieces of free art, and AI-powered recommendations that match artwork to your room's décor. Ten easily adjustable frame colors let you customize the look. And a redesigned Fire TV mobile app now lets you browse content, manage watchlists, and pick what you’ll watch next. Read more about our Fire TV news . Alexa+ expands to the web with Alexa.com, bringing AI assistant capabilities across voice, mobile, and browser Amazon is rolling out Alexa.com to all Alexa+ Early Access customers, bringing the full power of its AI assistant directly to the browsers. Since launching nine months ago, Alexa+ has scaled to tens of millions of customers with users engaging twice as much in conversations across a wide breadth of topics and tasks, making three times more purchases, and requesting recipes five times more frequently. Alexa.com combines deep information with real-world actions—from managing calendars and controlling smart homes to planning meals and making reservations. The web experience offers seamless integration across devices with persistent context, allowing customers to access Alexa wherever they are. Combined with the redesigned Alexa mobile app, which features an agent-forward design, Alexa+ is now accessible across every surface—whether you're at your desk, on the go, or at home. We’re excited about the potential that new modalities will add to Alexa+, and there’s much more to come with the capabilities and experiences we have planned. Read more about Alexa.com . New Alexa+ integrations with BMW, Samsung, Bosch, Oura, and more We’re announcing exciting new Alexa+ integrations that add to the tens of thousands of devices and services Alexa+ already works with. Alexa+ is available in even more places across the devices and services customers use every day. In 2026, we are adding the next generation of Alexa Custom Assistant, powered by Alexa+, to select BMW models, including the latest BMW iX3. Samsung is adding Alexa+ to their smart televisions, marking the first time Alexa+ is buit-in on a third-party device. Bosch is enabling voice-directed commands in its Bosch 800 series of fully automatic coffee makers. HERE Technologies and TomTom integrated Alexa Custom Assistant (ACA) into their mapping and location services for intelligent in-vehicle navigation. And Oura is rolling out early access to its Alexa+ integration, enabling customers to keep track of and act on their health information. All these new integrations give customers even more ways to use Alexa+ both at home, and on the go. Read more about our latest Alexa+ integrations . Since joining Amazon, the Bee team is evolving the wearable into the personal AI companion they’ve always envisioned—building new features and devices that have the potential to reach customers everywhere The team has shipped several major updates since joining Amazon, each one bringing this vision closer to reality: Actions connect Bee to your email and calendar, turning conversations into outcomes. When you mention needing to send an email or schedule a meeting, Bee can draft the email, create the invite, and handle it for you. Daily Insights surface patterns you'd never catch yourself: trends in how you're feeling, shifts in your relationships, themes that recur across weeks, and recommended personalized goals to help you act on what matters. Voice Notes enable you to capture any thought in an instant. Press the button, speak your mind, and it's there waiting for you. Templates will deliver intelligent summaries tailored to your specific needs and the setting you’re in. Whether it’s organizing lecture content into study plans for students or a salesperson recapping a client meeting into actionable next steps, Bee automatically formats the summary in the structure that works best for that moment. Read more about Bee’s journey at Amazon . Interested in more Amazon innovations? Visit our Devices page to see what else is new in the world of Ring, Blink, Kindle, Alexa+, and more.]]></description>
      <pubDate>Mon, 05 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/amazon-ces-2026-fire-tv-ring-alexa-plus</guid>
    </item>
    <item>
      <title>Alexa+ expands to Samsung TVs, BMW cars, and more in 2026</title>
      <link>https://www.aboutamazon.com/news/devices/alexa-plus-samsung-bmw-bosch-oura-integrations</link>
      <description><![CDATA[Key takeaways At CES, we announced new Alexa+ capabilities to keep customers connected in and outside their homes. Samsung will be the first third-party manufacturer to build in Alexa+, bringing voice-controlled entertainment and smart home management to their smart TVs. Amazon is also partnering with BMW, Bosch, and others, adding to the tens of thousands of devices and services Alexa+ already works with today. Whether at home, in the car, or on the go, Alexa+ is there when and where customers need it—ready to help with the tasks they care about most. Check out the six new Alexa+ integrations coming in 2026. Alexa+ in TVs Samsung is adding Alexa+ to their smart televisions, marking the first time Alexa+ is built into a non-Amazon device. Starting later this month, Samsung TV owners can speak to Alexa on their TVs to get to the content they want fast or get things done around the home. Using natural voice conversations, our shared customers can discover new series and movies quickly, easily manage smart home devices, play music from their televisions, and more. For example, say: “Alexa, it's showtime. What's new?” to find new releases or “Alexa, it feels too cold” to automatically adjust the thermostat. Early access to Alexa+ will be available for select 2021 to 2025 Samsung TV models with Alexa built-in. Introducing Alexa.com, a completely new way to interact with Alexa+ Alexa+ in your smart home Bosch will launch new capabilities with Alexa+ in 2026 so customers can talk to Alexa to control their coffee machine. Starting with the Bosch 800 Series fully automatic espresso machine, making coffee at home will feel just like talking to a barista. Customers will be able to have a natural conversation with Alexa to make and personalize their favorite coffee, lattes, cortados, and more. Alexa+ in the car BMW is showcasing its new BMW iX3 model, a cutting-edge electric SUV with the latest technology, including the next generation of BMW Intelligent Personal Assistant, powered by Alexa+. At the core of this innovation is Alexa Custom Assistant (ACA), a comprehensive service that enables automakers to create their own intelligent AI assistants powered by Alexa+ agentic capabilities. The new in-vehicle technology offers intuitive and sophisticated interactions between passengers and the vehicle in a natural dialogue—including the operation of vehicle functions as well as access to information and knowledge beyond the vehicle. Customers can have actual conversations with their car using natural language—no memorizing commands, no rigid phrase structures. They can say "Hey BMW, I am feeling a bit chilly could you warm it up in here" and have the car heat up. Customers can connect to dozens of services like music streaming and navigation, all in one cohesive experience. Expedia, Yelp, Angi, and Square to build new agentic experiences for Alexa+ HERE Technologies and TomTom also integrated Alexa Custom Assistant into their mapping and location technology. The result is an AI-powered in-vehicle navigation experience that enables customers to speak naturally to plan a trip, add or remove stops, find upcoming electrical vehicle charging spots, and more. This next generation of ACA debuted for the first time with BMW Group in their new BMW car iX3, and it is now available to automakers and location technology providers. Alexa+ in your daily health and wellness routine Soon, Alexa+ will help customers proactively manage their health and wellness journey each day. For example: As you’re getting ready in the morning, Alexa can give you a rundown of your sleep and recovery, and ways to achieve your wellness goals. In the evening, Alexa can use your optimal sleep time to remind you that it’s time to wind down and adjust temperature, lights, music and more to get you ready for a good night's sleep. At CES, we are giving customers a sneak peek of the Early Access experience with Oura. Integrations with Withings, Wyze, and additional partners are coming soon. Learn more and sign up for Alexa+ Health & Wellness .]]></description>
      <pubDate>Mon, 05 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/alexa-plus-samsung-bmw-bosch-oura-integrations</guid>
    </item>
    <item>
      <title>Amazon’s new Fire TV user interface gets you to what you want to watch—even faster</title>
      <link>https://www.aboutamazon.com/news/devices/new-fire-tv-upgrades-features-2026</link>
      <description><![CDATA[Key takeaways Fire TV's new user interface is faster and more streamlined, with dedicated homes for each content type. Amazon Ember Artline is a lifestyle TV with a matte screen and access to more than 2,000 pieces of free art. Generative AI-powered Alexa+ offers personalized recommendations and lets you jump to specific scenes in movies. Our mission at Fire TV is getting customers to what they want to watch—fast. We know that can be hard with so much content to choose from. It would take 100 years just to stream the free content on Fire TV. So, last year, we launched Alexa+ , our world-class entertainment expert, on Fire TV, to help customers get smarter, more personalized recommendations through natural conversation. Because customers are talking to Alexa+ more than 2.5 times more often than they were with the original Alexa, we knew it was time to upgrade other key parts of the Fire TV experience. So, to kick off 2026, we’re upgrading how customers browse for content with a new, redesigned user interface (UI), launching a transformed Fire TV mobile app, and introducing our first-ever lifestyle TV, the Amazon Ember Artline. A new Fire TV design that’s clean and fast We've redesigned the Fire TV UI to be cleaner, faster, and better organized—helping customers spend less time searching and more time watching. We’ve seen recent research from Gracenote that customers in the U.S. spend 12 minutes on average searching for what to watch, up from 10.5 minutes in 2023. We designed the new Fire TV experience to help cut down on that time. Now it’s faster and easier to find movies, TV shows, sports, news, and live content across all your subscriptions. That means when you browse movies, for example, you’ll see titles from all the apps you use. The new UI has a more modern design with improved layouts, rounded corners, redesigned color gradients, updated typography, and more optimized spacing. The update isn’t just aesthetic: The team rebuilt the underlying code to make the experience faster. In some cases, we’re seeing up to 20–30% gains in speed when using the new UI. All of these improvements will be available to customers with a free software update. With the redesign, we’re also increasing the number of apps you can pin to your home screen from six to 20. But the Fire TV experience is much more than just an app launcher. Now you can press the Menu button on your remote to quickly get to Games, Art & Photos, and the Ambient Experience. And with Amazon Photos on Fire TV, it’s easy to connect your personal photos so they show up beautifully on the biggest screen in your home. Jump right to the movie scene you describe with the launch of Fire TV's new Alexa+ feature We’ve also added a shortcut panel you can access by long-pressing the Home button on your remote. It gives you quick access to the most-used controls on Fire TV, including audio and display settings, your connected Ring cameras, and smart home device management. Of course, Alexa+, our generative AI-powered agent, is available in every part of the Fire TV experience. Just tell Alexa what you’re in the mood to watch, who you’re with, or examples of actors or directors you like. Alexa will help you find something great to watch. You can also ask Alexa to add the title you see on screen to your watchlist, get stats from the game you’re watching, create an AI-generated background screensaver, see photos from your last family vacation, turn down the lights, or jump straight to an iconic movie scene. The Fire TV mobile app gets a glow up Millions of customers use our Fire TV mobile app as a backup remote, but we knew it could do more. The redesigned app adds the ability to browse content, manage your watchlist, and play titles on your TV—all with a look and feel that matches the new Fire TV design. Now you can use your phone as a second screen to discover what to watch next or add a friend's show recommendation to your watchlist when you’re away from home. The Fire TV mobile app will be available for free to download. Innovating on behalf of customers Customers around the world have purchased over 300 million Fire TV devices, including our streaming media players; TVs made by partners like Hisense, Panasonic, TCL, and Xiaomi; and Amazon TVs like the latest Fire TV 2-Series, 4-Series, and Omni QLED Series. With our Amazon smart TVs, our goal has always been to push the boundaries of what the biggest screen in our homes can do. Over the years, we’ve launched innovations like the Ambient Experience so our TVs could display your photos and art whenever someone walks into the room and then power down when you leave the room to save energy. Customers have loved these features, so it was naturally time to elevate our hardware and build a TV worthy of the Ambient Experience. We’ve also had so much momentum with our line of Amazon smart TVs that we decided now was the time to give them their own name: Amazon Ember. And it was only fitting to launch this new name with our first-ever lifestyle TV, the Amazon Ember Artline. The Amazon Ember Artline—a lifestyle TV designed for any room The all-new Amazon Ember Artline is a beautiful 4K QLED TV featuring support for Dolby Vision, HDR10+, Wi-Fi 6, and a thin 1.5-inch design. It has a matte screen designed to make your art and photos look great and to reduce glare in any lighting condition. The Artline is more than a stunning display—it brings AI innovation to the lifestyle TV category. The Amazon Ember Artline comes with far-field microphones so you can naturally talk with Alexa+, and Omnisense technology that automatically turns the Ambient Experience on and off when people enter or leave the room. It includes seamless integration with Amazon Photos, more than 2,000 pieces of free art, and the all-new Fire TV UI so you can get to what you want to watch—fast. We know that finding the right piece of art to fit in a specific room can be challenging. So, we’ve built an all-new, AI-powered feature that lets you take up to four photos of the room where you plan to hang the Amazon Ember Artline and quickly get personalized recommendations on the best works of art to display that match your style and décor. With Amazon Photos connected, you can also ask Alexa+ to help create slideshows of your photos by saying things like, “Alexa, create a slideshow of our family trip to Colorado” or “Alexa, show photos from our wedding.” And customers will have the choice to pick one of 10 easily adjustable, magnetic frames to best fit your style. Colors include Walnut, Ash, Teak, Black Oak, Matte White, Midnight Blue, Fig, Pale Gold, Graphite, and Silver. Availability The new Fire TV UI and mobile app will launch starting in February on the Fire TV Stick 4K Plus, Fire TV Stick 4K Max (2 nd Gen), and Fire TV Omni Mini-LED Series in the U.S. Later this spring, we’ll expand the new UI design to more countries and more devices, including the latest generation Fire TV 4K streaming media players and TVs like the Fire TV 2-Series, Fire TV 4-Series, Fire TV Omni QLED Series; TVs made by partners like Hisense, Insignia, Panasonic, and TCL; and at launch on the all-new Amazon Ember Artline. Starting today, customers can sign up to receive an email when the Amazon Ember Artline goes on sale later this spring in the U.S., Canada, Germany, and the UK. The Amazon Ember Artline will be available from 55”–65” starting at $899, including your choice of one of the 10 adjustable color frames. Find the Fire TV that’s right for you—from us or our partners . *Separate subscriptions required to access certain content featured in visuals]]></description>
      <pubDate>Sun, 04 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/new-fire-tv-upgrades-features-2026</guid>
    </item>
    <item>
      <title>Introducing Alexa.com, a completely new way to interact with Alexa+</title>
      <link>https://www.aboutamazon.com/news/devices/alexa-plus-web-ai-assistant</link>
      <description><![CDATA[Key takeaways Alexa.com rolls out to all Alexa+ Early Access customers, bringing the power of Alexa+ to your browser. Alexa.com combines information with real-world actions. It offers seamless integration across devices for cooking, shopping, home control, entertainment, and more. Alexa+ has evolved rapidly since it launched nine months ago . We've integrated with tens of thousands of services and devices, scaled to tens of millions of customers, and have seen people transform the way they use their AI assistant: twice the conversations, three times the purchases, five times the recipe requests. What we've learned is simple: customers want Alexa wherever they are. Today, we're expanding on that vision by rolling out Alexa.com to all Alexa+ Early Access customers. Expedia, Yelp, Angi, and Square to build new agentic experiences for Alexa+ With over 600 million Alexa-enabled devices purchased worldwide, Alexa is already deeply integrated into daily life. But people are finding incredible value in how AI can help in every aspect of their day, and to truly serve as a personal assistant, Alexa+ needs to be available wherever they are—at home, on their phone, and now on the web. Alexa.com brings the full power of Alexa+ right to your browser. You can use Alexa.com to get quick answers, explore complex topics, create content, plan trip itineraries, and get help with homework. But Alexa+ doesn't just provide information, it’s designed to take action. It can help you complete countless tasks: managing your to-do list, updating your family calendar, controlling your smart home, making reservations, and so much more. It also provides persistent context and continuity, allowing you to access Alexa on whichever device or interface best serves the task at hand, with all previous chats, preferences, and personalization seamlessly carrying over. Here are just a few examples of how this comes to life: Meal planning made effortless:Get help handling meal planning end-to-end. Ask Alexa for a full week’s menu and watch as Alexa instantly generates a week of breakfast, lunch, and dinner options with your preferences taken into account like focusing on protein, avoiding sugar or processed foods, and making sure lunches are packable for school. You can ask Alexa to add every item you need to your Amazon Fresh or Whole Foods cart, ready to order, turning hours of work into minutes. Help with life admin:Upload documents, emails, and images to Alexa.com to get help keeping everything organized. Alexa+ can extract the key details from documents, add appointments and information to your calendar, and recall specific details on demand, whether it's remembering when the dog was last vaccinated, tracking the kids' soccer schedules, or keeping tabs on upcoming social events. Easily glance at your Echo Show to see what's coming up today, or pull up your schedule on the go and easily make edits from anywhere. Seamless smart home access:Your smart home controls are in the same window, right next to your chat with Alexa. You can instantly switch from chatting to checking who’s at the front door, turning on the lights, adjusting your thermostat, unlocking the door for a family member, or checking your security cameras while you're away, all without touching a phone or saying a word. Recipe discovery to the dinner table:Alexa+ can remove much of the work that goes into getting dinner on the table. Stumble across a recipe you like? Simply drop the recipe link into Alexa.com, ask Alexa to customize it to your family’s dietary restrictions, and add it to your recipe library. Customers can convert the full recipe into ingredients and have them added to your shopping list with a single request. When you’re ready to cook, have Alexa pull up the recipe on your Echo Show, guide you through each step, and set timers, all while keeping your hands free. Entertainment discovery:Start your movie night planning on Alexa.com, explore themed movie marathons, discover hidden gems, or get personalized recommendations based on what you've loved before. Once you find the perfect pick, Alexa can recall the suggestions on your Fire TV so you can start streaming instantly, reducing the endless scrolling or family debates about what to watch. Quick access to favorite features:A navigation sidebar keeps your most-used Alexa features just one click away—no need to open a different window or switch to another app. Access recent chats to pick up where you left off, jump to smart home controls to adjust your thermostat, check your calendar for upcoming appointments, review your shopping lists, or browse files you've shared with Alexa. It's designed to let you seamlessly move between tasks without losing your place. This is a new interaction model and adds a powerful way to use and collaborate with Alexa+. Combined with the redesigned Alexa mobile app, which will feature an agent-forward design, Alexa+ will be accessible across every surface—whether you're at your desk, on the go, or at home. We’re excited about the potential that new modalities will add to Alexa+, and there’s much more to come with the capabilities and experiences we have planned. To get started, customers with Early Access to Alexa+ can visit alexa.com while logged into their Amazon account and start chatting.]]></description>
      <pubDate>Sun, 04 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/alexa-plus-web-ai-assistant</guid>
    </item>
    <item>
      <title>Building Bee at Amazon: How the wearable AI device is evolving</title>
      <link>https://www.aboutamazon.com/news/devices/bee-amazon-wearable-ai-device-new-features</link>
      <description><![CDATA[Key takeaways Bee learns from conversations, emails, and other information you choose to share to provide personalized insights and suggested actions. After joining Amazon last year, Bee shipped several major features, including Voice Notes, which lets you capture any thought in an instant. The wearable device processes conversations in real-time without storing audio for privacy, delivering ambient AI wherever customers are. Think about all the conversations that happen throughout the day. A meeting where you promised to follow up on an action item or an idea you had during your morning walk that you meant to explore. These are the small moments that make up our lives: our relationships, our intentions, who we are, what we care about. But they're easy to lose track of. They fade in the middle of busy days, forgotten before we can act on them. That's where Bee comes in. It works in the background of your everyday life—in conversations, on the go, in the moments that matter. Amazon’s next-gen AI assistant for shopping is now even smarter, more capable, and more helpful Bee is the wearable AI that understands you. As you wear it throughout the day, it captures your conversations, understands your commitments, and builds a picture of your life that grows richer over time. A single press of the button starts and stops capturing, with a green LED to indicate when the device is recording. There's no setup, no training, no manual input. Bee learns from your daily patterns continuously to provide personalized insights that can empower you throughout your daily life. What we’ve learned Many customers first discovered Bee as a tool to make work and school life easier, to record and manage meetings, lectures, and conversations without frantically taking notes or getting distracted. But we began seeing something unexpected: customers were relying on Bee outside their professional lives, and it unlocked something they didn't know they needed. They started asking questions they'd never been able to ask before. “How can I be a more effective communicator?”, “What commitments have I made that I've lost track of?”, “How am I actually spending my time?” Bee surfaces insights across months of conversations, emails, calendar data, and health metrics from HealthKit—things that would otherwise go unnoticed. It becomes a mirror, one that helps you see patterns you've been living. The way you tend to respond when you're stressed. The commitments you make on Mondays that disappear by Fridays. The gap between how you think you spend your time and how you actually do. Accelerating with Amazon The goal has always been bigger than a single device. We're building toward a future where AI understands and helps you everywhere: at home, on the go, across every surface throughout your day. When we started Bee, we never imagined we'd end up at Amazon. But the more we built, the clearer it became that achieving our wearable AI vision requires a partner with the right scale and deep expertise to bring our wearable AI vision to life. Now at Amazon, we are excited to evolve Bee into the personal AI companion we've always envisioned—building new features and devices that have the potential to reach customers everywhere. We're continuing to move fast. Since joining Amazon, we've shipped several major updates, each bringing this vision closer to reality: Actionsconnect Bee to your email and calendar, turning conversations into outcomes. When you mention needing to send an email or schedule a meeting, Bee can draft the email, create the invite, and handle it for you. Actions is AI that understands your life to make it easier. Daily Insightssurfaces patterns you'd never catch yourself: trends in how you're feeling, shifts in your relationships, themes that recur across weeks and recommends personalized goals to help you act on what matters. Customers tell us this is where Bee feels most personal, like a coach who actually knows their life. Voice Notesenables you to capture any thought in an instant. Press the button, speak your mind, and it's there waiting for you. The fleeting ideas that usually disappear, the reminders you scribble down, the sudden clarity that hits in the middle of a walk. They all become part of Bee's understanding of you, easily accessible whenever you need them. Templateswill deliver intelligent summaries tailored to your specific needs and the setting you’re in. Whether it’s organizing lecture content into study plans for students or a salesperson recapping a client meeting into actionable next steps. Bee automatically formats the summary in the structure that works best for that moment, so you get exactly what you need, when you need it. Getting started with Alexa+: How Alexa+ can keep you and your family organized Privacy has been part of our DNA since Day 1. Bee processes conversations in real-time and no audio is ever stored. Since joining Amazon we have introduced a new layer of privacy, ensuring only customers have access to their transcripts and summaries and no one else—not even Amazon or Bee—can access them unless customers choose to share their data. Customers can also delete their personal data, including transcripts and summaries of conversations, at any time. We’re excited to continue inventing in this space. Building ambient AI Our vision for Bee has always been to deliver AI that understands you, which means integrating into every part of your life: at home, on the go, in the moments that matter wherever they happen. What drew us to Amazon wasn't just the scale, it was the chance to reach customers through the experiences already woven into their lives. We believe that having a shared ambient AI vision made us the perfect fit, with Bee and Alexa serving as natural complements in delivering truly personal and proactive ambient experiences that can serve customers wherever they are. We're continuing to invent rapidly while maintaining our startup spirit, constantly pushing the frontier of personal AI. We couldn't be more excited about this next step in Bee's journey and can’t wait to share more.]]></description>
      <pubDate>Sun, 04 Jan 2026 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/bee-amazon-wearable-ai-device-new-features</guid>
    </item>
    <item>
      <title>Amazon invests to bring AI education to 500,000 students nationwide</title>
      <link>https://www.aboutamazon.com/news/community/amazon-future-engineer-ai-education-students</link>
      <description><![CDATA[Key takeaways Amazon is supporting 18 educational partners across seven U.S. regions—including school districts, charter networks, and individual schools—reaching nearly 500,000 students with AI education. Educators will build custom AI tools to support classroom learning, while students design AI-powered solutions to real-world challenges in their communities. The program expanded from initial plans, with Amazon increasing investment to $800,000 through PlayLab AI partnership. When Amazon launched a fund to help schools participate in the White House Presidential AI Challenge , a national initiative to expand AI education, the initial goal was to support a small cohort of districts ready to take the next step in AI education. Future Ready 2030: Amazon expands skills training goal, invests $2.5 billion to prepare 50 million people for the future of work Interest from education partners quickly exceeded the scope of the pilot, demonstrating strong nationwide demand for expanding AI learning opportunities for students and educators. In response, Amazon more than doubled its initial investment to $800,000, expanding support to 18 educational partners. Through a partnership with education nonprofit, Playlab, districts will receive access to custom AI tools for both students and teachers, along with hands-on training to implement AI education that supports each partner’s unique approach to teaching and learning. "The strong response from school districts showed us how many educators are ready to bring AI into the classroom to help students build skills for the future," said Bettina Stix, Amazon's global director of community impact. "By expanding this program, we're helping nearly half a million students access AI education while supporting teachers as they integrate these tools into daily learning.” This initiative builds on Amazon's broader support for the White House's Pledge to America's Youth. Through this commitment, Amazon will support AI skills training for 4 million U.S. learners and enable AI curricula for 10,000 educators by 2028, including up to $30 million in AWS promotional credits and $1.5 million in cash prizes for student winners of the Presidential AI Challenge. STEM Education programs Amazon supports in the U.S. Meeting educators and students where they are The program gives students and educators hands-on experience using AI in ways that directly supports classroom learning and problem solving, building in the PlayLab environment built intentionally to support learning. Rather than taking a one-size-fits-all approach, the program is designed to adapt to each district’s goals and level of readiness. “Together with Amazon, we’re meeting districts where they are,” said Hilah Barbot, head of strategic partnerships at PlayLab. “It gives educators and students the space to experiment with AI in meaningful ways, building skills that are relevant today while preparing for what’s next.” In Fairfax County Public Schools, the district is scaling participation to reach all high school students. In Washington, DC, Amazon and PlayLab hosted a two-day immersive workshop with 60 middle and high school students from Friendship Charter Schools, where students built and tested AI-powered solutions to real challenges in their communities. Other partners are focusing on educator professional development, student innovation projects, or district-wide AI adoption strategies aligned to local priorities. Amazon to invest up to $50 billion to expand AI and supercomputing infrastructure for US government agencies Building AI skills across communities Through this initiative, Amazon Future Engineer is supporting 18 educational partners across seven U.S. regions, spanning large public school districts, charter networks, individual schools, and a state-level education service center. Participating partners include: Public school districts Fairfax County Public Schools (VA) Alexandria City Public Schools (VA) Bellevue School District (WA) Renton School District (WA) Metro Nashville Public Schools (TN) Evanston Township High School District (IL) District of Columbia Public Schools (DC) Charter networks and schools KIPP DC (DC) Friendship Charter Schools (DC) Distinctive Schools (IL) Intrinsic Schools (IL) KIPP Atlanta (GA) Kingsman Academy (DC) Center City Public Charter School (DC) Washington Leadership Academy (DC) Nashville Classical (TN) Charles R. Drew Charter School (GA) State-level education service center Learning Technology Center of Illinois (IL) Learn more about Amazon Future Engineer and Amazon's commitment to education and skills development.]]></description>
      <pubDate>Sun, 21 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/community/amazon-future-engineer-ai-education-students</guid>
    </item>
    <item>
      <title>Alexa+ can now answer your Ring doorbell and talk to visitors</title>
      <link>https://www.aboutamazon.com/news/devices/alexa-ring-doorbell-ai-greetings</link>
      <description><![CDATA[Key takeaways Alexa+ enables your Ring doorbell to chat naturally with anyone at your door. You can customize how Alexa greets delivery personnel and unexpected visitors. Alexa+ manages your front door and alerts you to events instantly, wherever you are. Amazon is launching Alexa+ Greetings—a feature that transforms your Ring doorbell into an intelligent assistant capable of determining who's at your door, understanding what they need, and responding conversationally, whether you're home, away, or simply don't want to be interrupted. What is Alexa+ Greetings? Alexa+ Greetings combines Ring Video Descriptions * with Alexa's conversational capabilities to create an experience that's intelligent and intuitive. When someone rings your doorbell, Ring's camera determines who’s there based on what they’re wearing, holding, or their actions. For example, it can distinguish a person in a delivery uniform dropping off a package from someone casually stopping by asking to speak with the resident. Alexa uses this visual context, any information the visitor shares, and the instructions it’s been given to help manage interactions on your behalf. Ring introduces its first-ever 4K cameras and AI feature that helps find lost pets How to personalize Alexa+ Greetings In the Ring app, tap “AI Features” from the menu tab and toggle on Alexa+ Greetings. Once enabled, set personalized instructions through any Alexa-enabled device like an Echo, Fire TV, or the Alexa app. Just tell Alexa what you want it to say, such as "If I get any deliveries during the weekend, tell them to leave it by the back door," and it will remember. Alexa+ Greetings also contains some pre-set greetings that handle common scenarios like delivery personnel being asked to place packages out of sight. You can also check your current settings anytime by asking, "What are my greetings instructions?" or "What will you tell my visitors at the door?" Ways to use Alexa+ Greetings Managing deliveries when you're occupied: Alexa can thank drivers, let them know you'll grab the order soon, or direct them to water or snacks you've left out. Tell Alexa beforehand where you want packages placed “through the side gate and on the back porch" or "put it on the bench by the door out of sight," and it will relay those instructions. Alexa can also handle follow-up questions naturally. If the delivery driver asks about a signature or needs clarification on backyard access, Alexa can respond in the moment and pass along important details. Handling interruptions gracefully: Alexa+ Greetings can help handle door-to-door sales interruptions. When someone selling a product or service arrives, Alexa can deliver a message on your behalf. Tell Alexa something like, "If someone comes to the door trying to sell something, politely let them know we're not interested." Alexa can courteously handle the interaction while you carry on with your day, whether you're working from home, in the middle of a call, or simply don't want to be disturbed. Helping Friends and Family When You're Not Available: When friends or family stop by unexpectedly while you're occupied, Alexa can make the interaction feel warm and intentional. Whether you're in the middle of a work call or helping kids with homework, Alexa can greet visitors and say, "I'll let them know you stopped by—would you like to leave a message?" They aren’t left wondering and you have the full context when you follow up. Stay in the know while away: Alexa can manage every visitor interaction and keeps you fully informed. When a neighbor stops by looking for a misdelivered package or a contractor arrives for an estimate, Alexa asks about the purpose of their visit and captures detailed messages. You can review these messages alongside the video footage in your Ring app for complete context about who came by, what they needed, and when to follow up. It's like having a trusted assistant at your front door 24/7. Getting started with Alexa+: How Alexa+ can keep you and your family organized Smarter home management Your doorbell is no longer just a way to know someone's at the door; it's now an intelligent assistant that helps you manage visitors. Alexa's responses are crafted to be helpful without revealing your home status, and doorbell interactions are separate from your smart home controls. You maintain complete control over when and how Alexa responds, ensuring your home stays both welcoming and secure. Alexa+ Greetings is rolling out to Alexa+ Early Access customers today in the U.S. and Canada (English only). It’s available on Ring Wired Doorbell Pro (3 rd Gen) and Ring Wired Doorbell Plus (2 nd Gen) with Ring Premium Plan and Video Descriptions enabled. *Compatible Ring subscription required (sold separately). For customers in Illinois: Smart Video Search is not available on Ring devices due to specific state legislation. Next, discover 50 things to try with Alexa+ .]]></description>
      <pubDate>Wed, 17 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/alexa-ring-doorbell-ai-greetings</guid>
    </item>
    <item>
      <title>Andy Jassy makes Amazon leadership announcement</title>
      <link>https://www.aboutamazon.com/news/company-news/andy-jassy-peter-desantis-amazon-leadership-update</link>
      <description><![CDATA[The message below was shared with Amazon employees earlier today. At Amazon, we often start new businesses in parts of the company where there’s an initial customer need, and as they grow and get momentum, we assess where they’re best situated to maximize potential for customers and Amazon over the long term. I believe we are at this inflection point with several of our new technologies that will power a significant amount of our future customer experiences. I’ve asked Peter DeSantis to lead a new organization that drives our most expansive AI models (e.g. Nova—and the team we’ve called “AGI”), silicon development (e.g. Graviton, Trainium, Nitro), and quantum computing. I cannot think of a better leader for this organization than Peter. Peter has been at Amazon for over 27 years, and led some of the most transformative technologies in computing history. Peter was the leader of Amazon EC2 when we launched this revolutionary service in 2006, and built out that excellent team over many years. Under his leadership, we launched Block Storage, File Storage, Load Balancing, Networking, and Monitoring services that AWS customers continue to rely on to run their infrastructure. In 2015, Peter spearheaded the acquisition of Annapurna Labs, our outstanding team that builds our custom silicon, and continues to manage that team. In 2016, we asked Peter to lead our AWS Infrastructure team, who’s responsible for all of our data centers, networking, hardware, and associated supply chain. To give you an idea of scale, our infrastructure stretches across 38 geographic regions and 120 Availability Zones around the world. In 2021, Peter moved to lead all of our AWS Utility Computing services (e.g., compute, storage, database, analytics, various AI services, messaging, etc.), the combination of which is widely recognized as the industry leader and standard-setter in the cloud. Peter combines unusual technical depth with a track record of solving problems at the edge of what’s technically possible—and delivering technologies that operate reliably at massive scale. Peter embodies our leadership principles. His ability to invent, think big but be neck-deep in the details, insist on the highest standards, learn and be curious, focus on what matters to customers, and be right much of the time are among the many traits that make him so effective. With our Nova 2 models just launched at re:Invent, our custom silicon growing rapidly, and the advantages of optimizing across models, chips, and cloud software and infrastructure, we wanted to free Peter up to focus his energy, invention cycles, and leadership on these new areas. Peter will report directly to me. As part of this organizational change, Pieter Abbeel will lead our frontier model research team (the team that builds the base model) in AGI. Pieter is one of the world's leading AI researchers, and co-founder of Covariant, which pioneered the first commercial foundation model for robotics. His deep expertise in generative AI and reinforcement learning makes him well-suited to advance Amazon's AI research as we push the boundaries of what's possible for customers. Pieter will also continue his ongoing work with our Robotics team. Peter will share the rest of the organizational design shortly. Peter’s very strong leaders in AWS Utility Computing will continue to lead what they’ve been leading, with a few additional responsibilities. Matt Garman will share the new AWS structure in a follow-up note. Finally, I want to recognize Rohit Prasad, who has decided to leave Amazon at the end of this year. Rohit joined Amazon in 2013, during the early days of Alexa, to help us build a conversational AI that could make customers' lives easier. Rohit helped Alexa grow from an ambitious idea into a service that now touches hundreds of millions of customers' lives every day. For the past two years, Rohit has led the creation of Amazon Nova and our AGI organization, building twelve state-of-the-art foundation models with industry-leading price-performance that are now being used by tens of thousands of companies across almost all industries and use cases. Rohit has built a strong team, differentiated technology, growing customer momentum, and a culture of ambitious invention. He’s been missionary, passionate, and selfless, and I'm grateful for his leadership, his technical vision, and everything he's built here. Thank you, Rohit. The path ahead is full of opportunity. With the foundation that's been built, the traction we’re seeing, and Peter's leadership bringing unified focus to these technologies, we're well-positioned to lead and deliver meaningful capabilities for our customers. I'm excited about what this team will build and how these foundational technologies will help shape Amazon's future. Andy]]></description>
      <pubDate>Tue, 16 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/company-news/andy-jassy-peter-desantis-amazon-leadership-update</guid>
    </item>
    <item>
      <title>New Kindle feature offers instant spoiler-free answers to questions about your books</title>
      <link>https://www.aboutamazon.com/news/books-and-authors/kindle-recaps-feature-ebook-series-refreshers</link>
      <description><![CDATA[Key takeaways Ask this Book lets you ask questions about the book you’re reading and receive spoiler-free answers. The feature answers questions about the plot, characters, and other relevant details. Ask this Book is available on the Kindle iOS app for U.S. customers and will come to Kindle devices and Android OS next year. Amazon is making it easier for you to stay immersed in your books with Ask this Book, a new feature available to U.S. customers on the Kindle iOS app. Highlight any passage in a book you’ve bought or borrowed, and Ask this Book allows you to ask questions about what you’re reading, right on the page. The feature is currently enabled for thousands of English-language best-selling Kindle books and only reveals information up to your current reading position. Kindle buying guide: Find out which device is right for you How can Ask this Book enhance your reading? This feature serves as your expert reading assistant, instantly answering questions about plot details, character relationships, and thematic elements without disrupting your reading flow. All responses provide immediate, contextual, spoiler-free information. Where is this feature available? Ask this Book is currently available for thousands of English-language books on the Kindle iOS app in the U.S. The feature will be enabled on Kindle devices and Android OS next year. How can I get started? Find Ask this Book in the in-book menu or simply highlight any passage as you read. From there, tap one of the suggested questions or type your own to get instant answers. You can also keep the conversation going with follow-up questions. What else launched recently for Kindle readers? For fans of book series, recalling plots and characters after a long reading break or a wait between new releases can be a challenge. Kindle’s “Recaps” feature works much like the “Previously on…” segment before a TV show. Available on both Kindle devices and the Kindle app for iOS in the U.S., Recaps makes it easier for you to dive into the next book in your favorite series by providing a quick refresher on storylines and character arcs in Kindle books you own or have borrowed. Amazon introduces Kindle Translate, an AI-powered translation service for authors to reach global readers To access a full book recap for supported Kindle books in series, look for the “View Recaps” button in the series page in your Kindle Library. On Kindle devices, you can select “View Recaps” from the three-dot menu within the series grouping, while on the Kindle iOS app, this same option appears when you press and hold the series grouping. Next, check out the redesigned Kindle Scribe lineup with first-ever color Scribe .]]></description>
      <pubDate>Wed, 10 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/books-and-authors/kindle-recaps-feature-ebook-series-refreshers</guid>
    </item>
    <item>
      <title>Amazon unveils redesigned Kindle Scribe lineup with first-ever color Scribe</title>
      <link>https://www.aboutamazon.com/news/devices/new-amazon-kindle-scribe-color</link>
      <description><![CDATA[Key takeaways Amazon introduces an all-new Kindle Scribe lineup, completely reimagined from the ground up for productivity. Kindle Scribe Colorsoft offers a color writing experience that’s fast, fluid, and easy on the eyes. Kindle Scribe and Kindle Scribe Colorsoft are available now, with the Kindle Scribe without a front light coming in 2026. Today, we’re thrilled to reveal our new Kindle Scribe lineup, reimagined for productivity: Our next-generation Kindle Scribe with and without a front light, and the first-ever color Kindle Scribe. A new paper-like design that’s thinner, lighter, and faster The new Kindle Scribe has a beautiful new design that’s just like paper—it’s ultra-thin at 5.4mm, ultra-light at 400g, and 40% faster for writing and page turns. The larger 11-inch glare-free display mirrors the proportions of a sheet of paper and feels just like you’re writing on one—it’s the perfect size for reviewing full-sized documents, feels natural for notetaking, and is easy to take with you wherever you go. Our new lineup is packed with innovation: A new front light system with miniaturized LEDs that fit tightly against the display to create a narrower bezel and uniform lighting. A new texture-molded glass to improve the friction when the pen glides across the screen—unlike tablets that often feel slippery or glassy. A rearchitected display stack to shrink the parallax to virtually nothing, so it feels like writing directly on the page. A new quad-core chip, more memory, and our latest Oxide display technology to make everything feel snappier. Answers to all your questions about the Kindle Unlimited reading membership A color writing experience that’s easy on the eyes Kindle Scribe Colorsoft features the same new design and provides a fluid color writing experience. To create colors that are soft and don’t hurt your eyes like an LCD display, we used our custom-built Colorsoft display technology, which has a color filter and light guide with nitride LEDs to enhance color without washing out the details. To deliver an incredible color writing experience, we developed a new rendering engine, which enhances the color and ensures writing is fast, fluid, and totally natural. Plus, Kindle Scribe Colorsoft provides weeks of battery life and doesn’t have any distracting apps or notifications to pull you away from your thoughts. All-new productivity features including an AI-powered notebook Our new lineup offers a powerful AI-powered notebook and redesigned software and tools that help you be more productive. All-new Home: From our all-new Home, we’ve added Quick Notes so you can easily jot something down whenever inspiration strikes. You can also open recently opened and added books, documents, and notebooks. Access all your docs: With support for Google Drive and Microsoft OneDrive, it’s easy to import documents for mark-up and export annotated PDFs. AI-powered search: Search your notes naturally across your notebooks and you’ll get simple AI summaries. You can also dig deeper with follow-up questions. Send to Alexa+: Early next year, you’ll be able to send your notes and documents from Kindle Scribe to Alexa+ and have a conversation about them. Share notebooks with OneNote: Export your notes as converted text or as an embedded image to OneNote so you can keep them all in one place and keep editing from your laptop. Color pens and highlights: Write, draw, and annotate in one of 10 pen colors or highlight in one of 5 highlighter colors. Shading: Artists and creators can create smooth gradients and subtle tones with our new shader tool, giving you even more control over the depth and richness of your art. Workspace: Organize your documents, notebooks, books, and more in the same folder. New Kindle feature offers instant spoiler-free answers to questions about your books Everything our customers love about Kindle Kindle Scribe is a notebook and a Kindle all in one with access to the world's best e-book store. It includes a 3-month subscription to Kindle Unlimited, as well as our latest reading features. We’re adding new AI-powered reading features that preserve the magic of reading on Kindle. Story So Far lets you catch up on the book you’re reading—but only up to where you’ve read without any spoilers. For our endlessly curious readers, Ask this Book will let you highlight any passage of text while reading a book and get spoiler-free answers to questions about things like a character’s motive or the significance of a scene. These features will be available for thousands of Kindle books in the U.S. You’ll be able to access these features on books you’ve purchased or borrowed on the Kindle iOS app later this year and on Kindle devices early next year. How Amazon tests Kindle devices and more in this innovation lab Pricing and availability All of our devices come with a new pen that feels amazing in your hands, seamlessly attaches to Kindle Scribe so you never lose it, and still never needs to be charged. We're also introducing a range of new folio covers, crafted in plant-based and premium leather, and an all-new executive notebook-style folio. Kindle Scribe is available starting at $499.99 and Kindle Scribe Colorsoft is available starting at $629.99. Kindle Scribe without a front light will be available next year for $429.99. All three products will be available in the UK and Germany next year. Next, learn about Kindle Scribe’s Gen AI features that make organizing and sharing your notes a snap.]]></description>
      <pubDate>Tue, 09 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/devices/new-amazon-kindle-scribe-color</guid>
    </item>
    <item>
      <title>Frontier agents, Trainium chips, and Amazon Nova: key announcements from AWS re:Invent 2025</title>
      <link>https://www.aboutamazon.com/news/aws/aws-re-invent-2025-ai-news-updates</link>
      <description><![CDATA[Last updated: December 4, 2025 AWS unveiled a wave of innovations at re:Invent 2025, including Graviton5 —the company's most powerful and efficient CPU. Other announcements include frontier agents that can work autonomously for days, an expansion of the Amazon Nova model family , the availability of Trainium3 UltraServers , and AWS AI Factories for implementing AI infrastructure in customers' existing data centers. re:Invent 2025 wrapped up with a special closing keynote by Amazon CTO Werner Vogels . See the key announcements from the event below and watch re:Invent 2025 keynotes . AWS introduces Graviton5—the company's most powerful and efficient CPU As cloud workloads grow in complexity, organizations face a persistent challenge: delivering faster performance, lower costs, and meeting sustainability commitments without trade-offs. AWS is introducing Graviton5 processors —the company's most advanced custom chip for a broad set of cloud workloads. New Graviton5-based Amazon EC2 M9g instances deliver up to 25% higher performance than the previous generation, with 192 cores per chip and 5x larger cache. For the third year in a row, more than half of new CPU capacity added to AWS is powered by Graviton, with 98% of the top 1,000 EC2 customers—including Adobe, Airbnb, Epic Games, Formula 1, Pinterest, SAP , and Siemens—already benefiting from Graviton's price performance advantages. Learn more . Amazon expands Nova family of models and pioneers “open training” with Nova Forge Amazon is expanding its Nova portfolio with four new models that deliver industry-leading price-performance across reasoning, multimodal processing, conversational AI, code generation, and agentic tasks. Nova Forge pioneers "open training," giving organizations access to pre-trained model checkpoints and the ability to blend proprietary data with Amazon Nova-curated datasets. Nova Act achieves breakthrough 90% reliability for browser-based UI automation workflows built by early customers. Companies like Reddit are using Nova Forge to replace multiple specialized models with a single solution, while Hertz accelerated development velocity by 5x with Nova Act. Learn more . AWS unveils 3 frontier agents, a new class of AI agents that work as an extension of your software development team Frontier agents represent a step-change in what agents can do. They’re autonomous, scalable, and can work for hours or days without intervention. AWS is announcing three frontier agents—Kiro autonomous agent, AWS Security Agent, and AWS DevOps Agent. Kiro autonomous agent acts as a virtual developer for your team, AWS Security Agent is your own security consultant, and AWS DevOps Agent is your on-call operational team. Companies including Commonwealth Bank of Australia, SmugMug, and Wester Governors University that have used one or more of these agents to transform the software development lifecycle. Learn more . Trainium3 UltraServers enable customers to train and deploy AI models faster at lower cost As AI models grow in size and complexity, training cutting-edge models requires infrastructure investments that only a handful of organizations can afford. Amazon EC2 Trn3 UltraServers , powered by AWS's first 3nm AI chip, pack up to 144 Trainium3 chips into a single integrated system, delivering up to 4.4x more compute performance and 4x greater energy efficiency than Trainium2 UltraServers. Customers achieve 3x higher throughput per chip while delivering 4x faster response times, reducing training times from months to weeks. Customers including Anthropic, Karakuri, Metagenomi, NetoAI, Ricoh, and Splash Music are reducing training and inference costs by up to 50% with Trainium, while Decart is achieving 4x faster inference for real-time generative video at half the cost of GPUs, and Amazon Bedrock is already serving production workloads on Trainium3. Learn more . AWS simplifies model customization to help customers build faster, more efficient AI agents Running AI applications at scale remains expensive and resource-intensive, particularly for AI agents that spend significant time on routine tasks that don't require advanced intelligence. AWS is announcing new Amazon Bedrock and Amazon SageMaker AI capabilities that make advanced model customization accessible to any developer. Reinforcement Fine Tuning (RFT) in Amazon Bedrock simplifies the model customization process, delivering 66% accuracy gains on average over base models, with customers like Salesforce demonstrating up to 73% improvement in accuracy over base models. Amazon SageMaker AI now supports serverless model customization capabilities that accelerate workflows from months to days, with customers like Collinear AI cutting experimentation cycles from weeks to days. AWS AI Factories transform customers' existing infrastructure into high-performance AI environments Building high-performance AI infrastructure requires massive capital investments in GPUs, data centers, and power, creating multi-year timelines that divert focus from core business goals. AWS AI Factories provides enterprises and government organizations with dedicated AWS AI infrastructure deployed in their own data centers, combining NVIDIA GPUs, Trainium chips, AWS networking, and AI services like Amazon Bedrock and SageMaker AI. This approach lets organizations leverage existing data center space and power while meeting data sovereignty and regulatory requirements. AWS and NVIDIA are expanding their 15-year collaboration to deliver this infrastructure and already support customers like HUMAIN in Saudi Arabia, which is building an "AI Zone" featuring up to 150,000 AI chips in a purpose-built data center. Learn more . AWS Transform now modernizes legacy code and applications up to 5x faster Most organizations spend 30% of their team's time on tech debt—manual modernization work that takes valuable resources away from innovation. AWS Transform is adding new agentic AI capabilities that help companies modernize any code and application , including custom programming languages and applications specific to their organization. The service can now handle full-stack Windows modernization across .NET apps, SQL Server, and user interface frameworks, and deployment layers, eliminating up to 70% of maintenance and licensing costs. Companies like Air Canada have already used the service to modernize thousands of Lambda functions in just days, achieving an 80% reduction in time and cost compared to manual migration. Learn more . Amazon Bedrock AgentCore helps developers build production-ready AI agents with new policy, evaluation, and memory capabilities Amazon Bedrock AgentCore is launching Policy in preview, allowing teams to set clear boundaries for agent actions using natural language. AgentCore Evaluations simplifies monitoring agent behavior with 13 pre-built evaluators for dimensions like correctness and safety, continuously sampling live interactions to trigger alerts when performance drops. Additionally, AgentCore Memory introduces new episodic functionality that helps agents learn from past experience. Learn more . Simplifying purpose-built AI infrastructure with Amazon Bedrock AgentCore Amazon Bedrock AgentCore is the most advanced platform for building and deploying agents securely at scale. To move agents from prototype to production, companies need infrastructure that is secure, reliable, scalable, and purpose-built for the non-deterministic nature of agents. Agents need a foundation that scales dynamically, supports long-running workloads, and allows them to store and retrieve context instantly and securely. Today, early adopters are diverting significant resources to build this infrastructure from scratch, a labor-intensive and time-consuming process that slows down development cycles. Amazon Bedrock AgentCore addresses these challenges by offering essential, fully managed services. AgentCore supports any framework (like CrewAI, LangGraph, LlamaIndex, Google ADK, OpenAI Agents SDK, and Strands Agents) or model while handling critical agentic AI infrastructure needs. In just five months since preview, organizations including Amazon Devices Operations & Supply Chain, Cohere Health, Cox Automotive, Heroku, Natera, MongoDB, PGA TOUR, Pulumi, Thomson Reuters, Workday, Snorkel, and Swisscom are already using AgentCore to build agents, and developers have downloaded it more than 2 million times. Bedrock AgentCore customer momentum PGA TOUR, a pioneer and innovation leader in sports, has built a multi-agent content generation system to create articles for its digital platforms. The new solution, built on AgentCore, enables the PGA TOUR to provide comprehensive coverage for every player in the field by increasing content writing speed by 1,000% while achieving a 95% reduction in costs. MongoDB, a database platform, leveraged AgentCore to reshape how it designed and operationalized AI within the company. Through AgentCore's implementation, the company eliminated weeks of evaluation cycles and consolidated multiple disparate tools into a single, production-ready solution. By seamlessly integrating MongoDB's AWS infrastructure and utilizing MongoDB Atlas as the embedded Knowledge Base for Amazon Bedrock, its development teams deployed an agent-based application in just eight weeks. This process previously took months of infrastructure work and continuous maintenance. This streamlined approach enabled MongoDB to scale its AI initiatives with greater accuracy, contextual awareness, and consistency, while significantly reducing manual overhead. Swisscom, Switzerland's leading telecoms provider, selected AgentCore to deploy containerized agents with AgentCore Runtime for scalable hosting, AgentCore Identity for seamless authentication across systems, and AgentCore Memory for tracking customer interactions. By standardizing how agents are built, deployed, and integrated, Swisscom now has an enterprise-grade foundation that lets teams focus on business problems instead of infrastructure. With AgentCore and Strands, the company launched their business-to-consumer agent solution in just four weeks, focusing on personalized sales assistance and automated technical support. Learn more . Kiro powers: Access specialized expertise to accelerate software development As developers increase their use of AI agents for a wider range of software development tasks, they want agents that have deep knowledge of the tools they use every day and that are specialized in their workflows, like user interface or application programming interface development. Kiro powers enable developers to give Kiro agents instant expertise in these tools and workflows in a single click. Powers can be comprised of a combination of MCP servers for specialized tool access, steering files with best practices, and hooks to trigger specific actions helping developers equip Kiro agents with workflow-specific knowledge spanning the application lifecycle: design, development, deployment, and observability. By loading only when needed, powers help developers work with efficient token usage, precision, and speed. Developers can build with expertise in their everyday tools using Kiro powers from Datadog, Dynatrace, Figma, Neon, Netlify, Postman, Stripe, Supabase, and AWS—with more to come. Developers can also create and share their own powers with the community. Learn more about Kiro powers and review this documentation . Checkpointless training on SageMaker HyperPod: recover from model training faults in minutes Amazon SageMaker HyperPod simplifies infrastructure management for model training and deployment, reducing costs by up to 40%. As training scales across hundreds or thousands of accelerators, faults like hardware or software failures can occur. Traditional checkpoint-based recovery can take up to an hour, which is expensive, consumes storage, and leaves multi-million-dollar compute clusters idle during recovery. AWS is announcing checkpointless training on SageMaker HyperPod—automatically recovering from infrastructure faults in minutes with zero manual intervention, enabling training cluster efficiency of up to 95% on clusters with thousands of AI accelerators. Checkpointless training continuously preserves model state across the training compute cluster. When faults occur, the system automatically swaps out faulty components and recovers training using a peer-to-peer transfer of model and optimizer states from nearby healthy accelerators—mitigating lengthy downtime so teams can focus on building the best AI model for their use case. Learn more about checkpointless training on SageMaker HyperPod . Strands Agents SDK now in Typescript (preview) AWS is bringing Strands Agents, the open source, model-driven, AI agent framework to TypeScript, one of the world’s most popular programming languages and communities. Developers love TypeScript because it catches errors early and provides powerful tooling while still letting them write familiar, flexible JavaScript. Strands provides full support for key TypeScript features, including type safety, async/await, and modern JavaScript/TypeScript patterns. Originally available in Python with over 3M downloads, AWS is extending Strands Agents to give developers the ability to build their entire agentic stack in TypeScript using the AWS CDK. Head to the Strands Agents Github to join the millions of developers who are building today. Strands adds support for edge devices AWS is announcing the general availability of Edge Device support for Strands Agents. With edge device support, customers can use the Strands Agents SDK to create autonomous AI agents that can run on small-scale devices, unlocking new agentic use cases in automotive, gaming, and robotics. Developers can also implement bi-directional streaming capabilities and run agents using local models like Ollama and Llama.cpp. Head to the Strands Agents Github to join the millions of developers who are building today. Amazon Bedrock’s largest expansion of new models to date AWS added 18 new open weight models to Amazon Bedrock, reinforcing its commitment to offering a broad selection of fully managed models from leading AI providers. With access to top models and the flexibility to swap them without rewriting code, Amazon Bedrock makes it fast and easy for customers to evaluate, test, and adopt new models, so they can find the best option for their use case—all without disrupting production systems. The news includes the launch of two new sets of models, available first in Amazon Bedrock, from Mistral AI. Mistral Large 3 is Mistral AI’s most advanced open weight model optimized for long-context, multimodal, and instruction reliability, and Ministral 3 is a series of models that set a new benchmark for compact, general-purpose, and multimodal AI. The launch also features other popular models, including Google’s Gemma 3, MiniMax’s M2, NVIDIA’s Nemotron, OpenAI’s GPT OSS Safeguard, and more. Additionally, Amazon announced the release of its Nova 2 family of models, providing industry-leading price-performance across reasoning, multimodal processing, and conversational AI. Read more for the latest on Amazon Nova . Learn more about the new models available in Amazon Bedrock . AWS launches new Amazon EC2 instance powered by NVIDIA GPUs AWS is expanding its accelerated computing portfolio with P6e-GB300 UltraServers, featuring NVIDIA GB300 NVL72, the most advanced NVIDIA GPU architecture in Amazon EC2. Offering the highest GPU memory and compute within an UltraServer on AWS, the P6e-GB300 is ideal for AI inference at scale, supporting trillion-parameter models with reasoning capabilities in production. The P6e-GB300 UltraServers are powered by the AWS Nitro System, making them highly performant, secure, and reliable, and can integrate seamlessly with AWS services such as Amazon Elastic Kubernetes Service (EKS). Get started with P6e-GB300 UltraServers, visit Amazon EC2 or contact your AWS sales representative. AWS Lambda Managed Instances: The benefits of serverless without constraints Customers rely on Lambda to build serverless applications because of its simplicity, automatic scaling, and intuitive operational model. But they also need consistent, massive compute and precise control of the infrastructure to use Lambda for use cases like analytics pipelines, financial risk modeling, and multiplayer games. AWS Lambda Managed Instances bridges the gap between serverless simplicity and infrastructure control, allowing customers to run their Lambda functions on the Amazon EC2 instance of their choice. Customers will now have access to the exact compute power they need and immediately benefit from the latest hardware and pricing of EC2. Whether processing video, running complex algorithms, or handling other demanding tasks, developers can set desired utilization levels, and AWS will automatically adjust the fleet size according to demand, while building with the familiar Lambda programming model they use today. With Lambda Managed Instances, developers have ultimate control of their Lambda’s performance characteristics, allowing them to provide the best experiences to their end users. Learn more about AWS Lambda Managed Instances . AWS Lambda durable functions enables reliable multi-step applications and AI workflows Each month, over 1.8 million customers use AWS Lambda to process more than 15 trillion requests. Developers rely on Lambda to quickly build functions to run code, but also want to build multi-step applications that execute reliably over extended periods, like payment processing, customer onboarding, or orchestrating AI workflows. AWS Lambda durable functions empowers customers to create Lambda functions that can preserve their progress despite interruptions and allow them to suspend execution for up to a year. Lambda tracks the progress of the function, ensuring reliable execution through pauses or interruptions, with built-in error handling and automatic failure recovery. Now developers can use Lambda to build reliable, long-running multi-step applications and AI workflows, opening it to an entirely new set of use cases. Learn more about AWS Lambda durable functions . Amazon GuardDuty Extended Threat Detection now supports EC2 and ECS environments Modern cloud environments are dynamic and distributed, often running virtual machine, container, and serverless workloads at scale. Building on existing support for detecting compromised IAM credentials, Amazon S3 buckets, and Amazon EKS, GuardDuty Extended Threat Detection now expands to Amazon EC2 and Amazon ECS, providing broader visibility into sophisticated attack sequences and enabling faster remediation across a customer’s AWS environment. GuardDuty Extended Threat Detection uses AI and machine learning models trained at AWS scale to correlate signals such as anomalous process creation, persistence attempts, reverse-shell activity, and crypto-mining into a single, critical-severity event instead of separate alerts that each trigger a siloed investigation. Each finding includes an incident summary and a timeline of events mapped to MITRE ATT&CK® tactics and remediation recommendations. This end-to-end view surfaces potential compromises along with the associated severity level to help teams accelerate incident response across AWS compute environments. Review the AWS News Blog , Services Page , and Documentation for more information. Amazon S3 Vectors scales to two billion vectors per index Amazon S3 Vectors is now generally available with significant scale and performance improvements, enabling AI systems to store and query vectors natively in Amazon S3 for semantic search and context understanding. Designed to provide the same elasticity, scale, and durability as Amazon S3, S3 Vectors scales up to two billion vectors per index (40x preview capacity), supports up to 20 trillion vectors per bucket, delivers 2-3x faster frequent-query performance, and reduces costs by up to 90% over alternatives—eliminating overhead for customers building AI applications. S3 Vectors brings these capabilities to customer data and integrates with Amazon Bedrock Knowledge Bases and Amazon OpenSearch Service, making it easy to build AI agents, RAG systems, inference pipelines, and semantic search applications that understand context and intent. Customers like BMW Group, MIXI, Precisely, Qlik, and Twilio are using S3 Vectors to accelerate AI search and power recommendation systems at scale—without the complexity or cost of managing a dedicated vector infrastructure. Learn more about S3 Vectors in the AWS News Blog , What’s New Post , PDP , documentation , and demo video . Increased maximum Amazon S3 object size Data volumes have surged in recent years, with Amazon S3 now storing more than 500 trillion objects and hundreds of exabytes of data. As individual objects also grow larger, AWS is increasing the maximum S3 object size 10x from 5TB to 50TB, so customers can store massive data files like high-resolution videos, seismic data, and AI training datasets as single objects in their original form—simplifying workflows while maintaining full access to all S3 storage classes and features. Learn more about increased S3 maximum object size in the What’s New post and documentation . Faster Amazon S3 Batch Operations AWS has accelerated Amazon S3 Batch Operations for large jobs to run up to 10x faster, delivering the speed that customers demand for large-scale data processing and time-sensitive data migrations. With S3 Batch Operations, customers can perform batch workloads such as replicating objects across AWS Regions for backup or disaster recovery, tagging objects for S3 Lifecycle management, and computing object checksums to verify the content of stored datasets, at a scale of up to 20 billion objects in a job. Learn more about S3 Batch Operations in the What’s New post , product overview page , and documentation . Amazon S3 Tables optimize storage costs and enable automatic replication Since launch, Amazon S3 Tables for Apache Iceberg workloads has quickly grown to more than 400,000 tables. S3 Tables has launched over 15 new features and capabilities in the last 12 months, rapidly innovating on S3 native Iceberg support for data lakes. Today, AWS is adding two major capabilities to S3 Tables: support for the Intelligent-Tiering storage class and automatic replication across AWS Regions and accounts. Intelligent-Tiering brings the same automatic cost optimization that has saved S3 customers more than $6 billion. It automatically optimizes table data across three access tiers (Frequent Access, Infrequent Access, and Archive Instant Access) based on access patterns—delivering up to 80% storage cost savings without performance impact or operational overhead. Automatic replication enables distributed teams to query local data for faster performance while maintaining consistency across Regions and accounts. Customers can now automatically replicate tables, eliminating manual updates and complex syncing—simplifying compliance and backup management while keeping complete table structures intact and ready to use. Learn more about these new S3 Tables capabilities in the AWS News Blog , product overview page , and explainer video . Learn more about Intelligent-Tiering for S3 Tables in the What’s New post and documentation and automatic replication for S3 Tables in the What’s New post and documentation . Amazon FSx for NetApp ONTAP data accessible from Amazon S3 AWS is expanding Amazon S3 Access Points to support Amazon FSx for NetApp ONTAP so that customers can access the files they store in FSx as if the data were in S3. Customers can now use the data they store in FSx for NetApp ONTAP with AWS's AI, ML, and analytics services that are built to work with S3 data—such as Amazon Bedrock Knowledge Bases, Amazon SageMaker, and Amazon Athena. With this integration, customers with NetApp ONTAP enterprise data on premises can easily migrate to FSx for NetApp ONTAP and start using that data with all S3 compatible tools and applications for analytics and AI. Learn more about S3 Access Points for FSx for NetApp ONTAP in the AWS News Blog , What’s New Post , PDP , documentation , and explainer video . AWS unifies security, operations, and compliance data in CloudWatch Logs are the lifeblood of any operations team, but with so many sitting across a number of disparate systems, it can be hard to derive accurate and actionable insights. Often, organizations face data duplication, complex ETL pipelines, and extended resolution times as a result. Starting today, Amazon CloudWatch is introducing a new unified data store for operational, security, and compliance data. CloudWatch now simplifies log data ingestion with automated collection from AWS and third-party sources like CrowdStrike, Microsoft Office 365, and SentinelOne, and stores it in S3 Tables, so it’s fast and easy to use logs to investigate issues, find root causes, flag anomalies, and unlock new insights from applications. Learn more about the updates at Amazon CloudWatch . AWS eliminates local storage provisioning for EMR Serverless AWS is introducing Amazon EMR Serverless, which eliminates local storage provisioning for Apache Spark workloads, reducing data processing costs by up to 20%. Customers will no longer need to configure local disk type and size for each application or manage storage capacity for jobs, as the service automatically scales to handle shuffle operations. By automatically managing storage resources, EMR Serverless dynamically adjusts based on workload requirements, helping prevent job failures and performance bottlenecks from disk constraints while ensuring more reliable execution of Apache Spark jobs for data-intensive applications. Learn more about Amazon EMR Serverless AWS announces Database Savings Plans Customers can now reduce their database costs by up to 35% with Database Savings Plans—a new flexible pricing model that applies when they commit to a consistent amount of usage over a one-year term. Customers can purchase Database Savings Plans through the AWS Cost Management Console with savings automatically applied to eligible database workloads. SmugMug and Vanguard are among the first customers using Database Savings Plans, benefiting from these cost savings. Learn more about Database Savings Plans on the AWS Database Blog . Keeping AWS the best place to run commercial databases AWS now supports 4x more storage for Amazon RDS for SQL Server and RDS for Oracle—increasing capacity from 64 TiB to 256 TiB with a 4x improvement in IOPS and I/O bandwidth. Both io2 and GP3 storage volumes can be used together to optimize price performance for larger workloads. With RDS for SQL Server Optimize CPUs, customers can reduce their costs by up to 55%. For high-performance computing applications, customers can boost performance, with organizations like iCIMS, UST Health Proof, and Ivy Mobility Solutions LTD eager to take advantage of the technology. AWS also offers RDS for SQL Server Developer Edition, giving development teams access to every feature in SQL Server Enterprise Edition without licensing fees. Learn more about Amazon RDS for SQL Server, RDS for Oracle, Optimize CPUs, and Developer Edition on the AWS Database Blog . Building apps at the speed of ideas with AWS databases, Vercel Marketplace, and v0 Coming soon, AWS databases, including Amazon Aurora and Amazon DynamoDB, will be available as native integrations on Vercel Marketplace and v0. Developers can connect to Aurora PostgreSQL, Aurora DSQL, or DynamoDB in seconds from their Vercel dashboard or in v0 prompts, accelerating the velocity in building new applications. From ideation to production, customers benefit from the security, reliability, scalability, and operational excellence of AWS database services. AWS Security Hub, now generally available, delivers near real-time threat correlation Organizations managing multiple security tools often need to correlate signals across different services, which can create operational complexity. To solve this, AWS Security Hub, now generally available, is providing near-real-time risk analytics that automatically correlate security signals from Amazon GuardDuty , Amazon Inspector , AWS Security Hub CSPM , and Amazon Macie to unify cloud security operations for customers. In addition, Security Hub now provides advanced trends and historical insights through enhanced visualizations, helping organizations understand changes in their security posture over time. These insights help organizations identify potential attack paths, understand how threats, vulnerabilities, and misconfigurations could chain together, and quickly surface and prioritize active risks in their cloud environment. Visit the Security Hub News Blog , Security Hub Page and Security Hub Documentation for more information. AWS debuts AI-powered support with 2x faster response times at entry tier to boost reliability and speed innovation Customers and partners can now access new and enhanced AWS Support offerings with three experience-driven tiers: Business Support+, Enterprise Support, and Unified Operations. Combining the speed of AI with AWS engineer expertise, AWS Support now provides faster response times compared to any previous offering. Additionally, customers previewing AWS DevOps Agent can engage with AWS Support with one-click when needed, giving AWS experts immediate context of the situation for a faster resolution. The result for AWS customers: less time spent fixing issues, giving them more time to innovate. Business Support+delivers AI-powered assistance that understands the context of customer operations, with 24/7 access to AWS experts. For critical production issues, support engineers engage within 30 minutes to accelerate recovery. Enterprise Supportprovides designated Technical Account Managers (TAMs) who blend generative AI insights with human judgment to provide strategic operational guidance to customers on resiliency, cost, and efficiency. It also includes AWS Security Incident Response at no additional cost, which customers can activate to automate security alert investigation and triage. Unified Operations, the premier support plan, is for customers with the largest and most complex workloads—offering a global team of designated experts who deliver architecture reviews, guided testing, proactive optimization, and personalized responses within five-minutes for critical incidents. Business Support+, Enterprise Support, and Unified Operations are available in all commercial AWS Regions. Read the AWS Support Blog or visit the AWS Support product page to learn more. Amazon Connect launches agentic AI capabilities for seamless customer experiences Amazon Connect delivers natural voice interactions with advanced speech models Amazon Connect has helped businesses deliver automated voice experiences using neural text-to-speech in more than 30 languages and automated speech recognition in more than 25 languages. Amazon Connect is introducing agentic self-service capabilities that enable AI agents to understand, reason, and act across voice and messaging channels—automating routine and complex tasks through a blend of deterministic and agentic experiences that companies can deploy reliably and safely at scale. With advanced speech models from Nova Sonic , these agents deliver natural, human-like conversations, responding with the right pace, tone, and understanding across multiple languages and accents. For customers who already use third-party automated speech recognition (ASR) and text-to-speech (TTS) solutions, Connect now supports Deepgram and ElevenLabs. Customers can now resolve complex issues through intuitive self-service, reducing wait times while enjoying natural, conversational experiences. Agentic assistance creates true collaboration between humans and AI For years, Amazon Connect has provided AI-powered assistance that analyzes customer interactions to proactively deliver customer service representatives the information and the tools they need in real-time. Amazon Connect is taking this further with agentic assistance that creates true collaboration between humans and AI. While customer service representatives talk with customers, Amazon Connect analyzes conversation context and customer sentiment—not only suggesting next steps, but also actively completing tasks such as preparing documentation and handling routine processes. Customer service representatives can now focus on building relationships and handling complex situations while AI manages the background complexity, enabling them to serve more customers effectively. AI-powered recommendations create deeper customer engagement Amazon Connect has helped businesses personalize customer interactions through unified customer profiles that sync data from disparate applications. Now, Amazon Connect is introducing AI-powered product recommendations that turn customer conversations into opportunities for deeper engagement. By combining real-time clickstream data with rich customer history, AI agents and customer service representatives can deliver interactions with highly personalized product suggestions at exactly the right moment. Instead of waiting for customers to ask, businesses can also anticipate needs based on real-time behavior, increasing satisfaction while creating new revenue opportunities. AI agent observability, testing, and performance evaluations As businesses deploy more AI agents, understanding how they make decisions has become critical for maintaining quality and compliance. Amazon Connect is introducing AI agent observability that provides complete transparency—showing you what the AI understood, which tools it used, and how it reached its decisions. This visibility helps you optimize performance, ensure compliance, and build confidence in your AI-powered experiences. Amazon Connect enables businesses to test workflows before going live and evaluate both AI and customer service representative performance with automated assessment, custom criteria, and aggregated insights. Businesses can now confidently deploy AI agents at scale, knowing they have full visibility and control over every customer interaction. Learn more about Amazon Connect and the new capabilities. Understand how customers are benefitting from Amazon Connect today. AWS Interconnect - multicloud preview begins with Google AWS Interconnect - multicloud is designed to remove the complexity of traditional multicloud networking by enabling customers to quickly configure connections with dedicated bandwidth between AWS and other service providers, beginning with Google Cloud. Together, AWS and Google Cloud are introducing a new open specification for network interoperability. This jointly engineered multicloud networking solution uses both AWS Interconnect - multicloud and Google Cloud’s Cross-Cloud Interconnect , enabling customers to establish private, high-bandwidth connectivity between the two providers with increased speed and simplicity. Previously, customers connecting different cloud workloads faced a choice: use public connectivity with no bandwidth guarantees or build complex private connectivity. AWS Interconnect - multicloud simplifies connectivity by providing a fully managed, cloud-to-cloud experience that is provisioned quickly through the AWS Management Console or API. To further accelerate adoption, an open API package has been published on GitHub , making it easy for other service providers to adopt this new open specification for connecting private networks. By using pre-built capacity pools, organizations can create connections and adjust their bandwidth as needed. Built-in resiliency, streamlined support, and infrastructure that is fully managed by the service providers enable customers to remove the overhead of managing physical devices or virtual routing objects from their multicloud networks. Learn more about what is available today . TwelveLabs launches world's most powerful video understanding model on Amazon Bedrock TwelveLabs has launched Marengo 3.0, a breakthrough video foundation model now available through Amazon Bedrock. Unlike traditional models that analyze video frame-by-frame, Marengo 3.0 understands video as a complete, dynamic system—connecting dialogue, gestures, movement, and emotion across time to deliver truly human-like comprehension at AI scale. Marengo 3.0 addresses a critical business challenge: 90% of digitized data is video, but most of it remains unusable because it's too time-consuming for humans to analyze and previous AI models couldn't grasp everything happening on screen. Marengo 3.0 changes that by compressing audio, text, movement, visuals, and context into something that can be searched, navigated, and understood at enterprise scale. The model delivers immediate business value with a 50% reduction in storage costs and 2x faster indexing performance. It offers industry-first capabilities including team and player tracking for sports, composed multimodal queries that combine image and text, and support for four-hour videos across 36 languages. "Video represents 90% of digitized data, but that data has been largely unusable," said Jae Lee, CEO of TwelveLabs. "Marengo 3.0 shatters the limits of what is possible." AWS is the first cloud provider to offer Marengo 3.0, making it easy for enterprises to deploy the model securely within their existing AWS environment through Amazon Bedrock's fully managed service. Learn more about Marengo 3.0, on TwelveLabs Amazon Bedrock . Trane Technologies and AWS accelerate building decarbonization for Amazon Grocery Trane Technologies and AWS are using advanced AI to dramatically improve energy efficiency across three pilot Amazon Grocery fulfillment sites in North America , achieving energy reductions of nearly 15%—more than double initial targets. Through BrainBox AI , a Trane Technologies company, the partnership is transforming how Amazon Grocery’s fulfillment facilities consume energy. The AI-powered technology autonomously optimizes heating, ventilation, and air conditioning systems, helping Amazon advance its commitment to reach net-zero carbon by 2040 under The Climate Pledge. "At Trane Technologies, sustainability is at the core of everything we do. This strategic collaboration demonstrates how sustainable solutions can drive strong returns while benefiting the planet," said Riaz Raihan, SVP and chief digital officer of Trane Technologies. "Together, we’re not only transforming these fulfillment centers but also driving meaningful progress towards Amazon’s business objectives and bold sustainability goals.” The results have exceeded expectations, with pilot sites achieving energy-use reductions of nearly 15%. Following the success of these initiatives, deployment is planned for the remaining Amazon Grocery fulfillment and distribution centers across more than 30 sites in the U.S. Furthermore, plans to pilot in grocery stores will begin in 2026. “At Amazon, we’re continually looking for data-driven, scalable solutions to reduce our carbon footprint while maintaining operational excellence,” said Christina Minardi, vice president of Worldwide Grocery Stores Real Estate and Store Development at Amazon. “By working with Trane Technologies and the BrainBox AI team, we’re turning our buildings into intelligent systems that learn and adapt, helping us meet both our sustainability and performance goals in real time.” AWS powers Sony's enterprise AI and engagement platforms Sony is leveraging AWS's AI services for two key initiatives: an internal enterprise platform that helps Sony employees work more efficiently, and the Sony Engagement Platform that aims to deepen connections between fans and creators. The Engagement Platform will connect Sony's diverse portfolio of businesses—from electronics to PlayStation games to music, movies, and anime—making it easier for fans to discover and enjoy content across all of Sony's offerings. Behind the scenes, Sony Data Ocean, running on AWS, helps Sony understand what fans enjoy and delivers more personalized experiences by processing up to 760 terabytes of data from more than 500 different sources across Sony's businesses. The platform will extend core functions of the PlayStation infrastructure such as accounts, payments, data capabilities, and security to create seamless experiences across Sony's entertainment services. Meanwhile, Sony's internal enterprise AI platform, powered by Amazon Bedrock AgentCore , helps 57,000 Sony employees worldwide work smarter. The system handles 150,000 AI requests every day—helping teams draft content, answer questions, spot trends, and brainstorm new ideas—and is expected to grow 300 times larger in the coming years. WRITER and AWS bring enterprise-grade security and flexibility to AI agents WRITER, a leader in enterprise AI, is making it easier for companies to build and manage AI agents securely at scale. Through a new integration with Amazon Bedrock, WRITER customers can now access a wide variety of leading AI models directly within WRITER's platform—alongside WRITER's own Palmyra family of models—all under unified governance and security controls. The integration gives enterprises the flexibility to choose the best models for their needs while maintaining the security and compliance standards they require. Companies like Vanguard, Mars, and AstraZeneca can now deploy Amazon Bedrock models within WRITER's prebuilt or custom agents, with Amazon Bedrock Guardrails and WRITER’s observability tools connecting seamlessly to WRITER's AI Studio. WRITER also unveiled a new agent supervision suite that acts as a control center for enterprise AI. The suite gives IT teams full visibility into how agents are being used, with capabilities including detailed monitoring of user and agent behaviors, centralized approval workflows before deployment, and integration with existing security platforms. These controls help organizations scale AI confidently without sacrificing oversight. "The biggest barrier to scaling agents in the enterprise isn't the technology—it's trust," said WRITER CEO May Habib. "By expanding our supervision capabilities and deepening our relationship with AWS, we're delivering the first true control center for enterprise AI." Learn more . Adobe and AWS team up to reshape creativity and marketing in the AI era Adobe and AWS are transforming how people create and connect with audiences through artificial intelligence. Announced onstage at AWS re:Invent by Adobe CEO Shantanu Narayen, this collaboration leverages AWS's cloud infrastructure and services—from generative AI model training to AI agent deployment—to help Adobe deliver cutting-edge AI tools to creators, marketers, and businesses worldwide. AWS is the engine behind Adobe's most innovative features. Adobe Express uses AWS AI capabilities for conversational editing that makes design intuitive. Adobe Acrobat Studio taps Amazon Bedrock to bring personalized AI assistants to PDFs. And Adobe Firefly—Adobe's commercially safe generative AI—trains its text-to-image and text-to-video models on AWS's advanced EC2 P5 and P6 instances, enabling creators to bring ideas to life instantly. For marketers, AWS enables Adobe to orchestrate personalized customer experiences at an unprecedented scale. Adobe Experience Platform allows brands to unify real-time data and deliver standout experiences across every channel. Adobe GenStudio for Performance Marketing now activates display ads directly with Amazon Ads, dramatically shortening campaign launch times. Adobe and Amazon are also collaborating on AI agent adoption and multi-agent collaboration, with Adobe exploring AWS's newest capabilities like Amazon Bedrock AgentCore to accelerate autonomous agentic capabilities. By combining Adobe's creative expertise with AWS's AI and cloud infrastructure, this partnership makes professional-grade AI tools accessible to everyone—helping individuals and businesses stand out in today's digital economy. Learn more . Dartmouth becomes the first Ivy League institution to deploy AI campuswide with AWS and Anthropic The partnership with AWS and Anthropic will give Dartmouth students, faculty, and staff secure and reliable access to a suite of advanced AI tools designed to support innovation in teaching, learning, and research. This includes access to Amazon Bedrock , AWS's cloud infrastructure, and Anthropic's Claude for Education AI model. "We look forward to empowering Dartmouth, in partnership with Anthropic, as they continue to approach AI ethically, strategically, and securely to provide transformational student experiences and operational excellence," said Kim Majerus, vice president of Global Education and U.S. State and Local Government at AWS. Dartmouth will use Amazon Bedrock to build custom AI applications for campus operations and student services, with AWS's Digital Innovation Team providing direct support using their working backwards methodology. Comprehensive training and support will ensure community members can take advantage of the tools that best meet their needs. “This is more than a collaboration,” said President Sian Leah Beilock. “It’s the next chapter in a story that began at Dartmouth 70 years ago. This collaboration will ensure that the institution where the term AI was first introduced to the world will also demonstrate how to use it wisely in pursuit of knowledge.” “Dartmouth has always understood that technology is most powerful when it's paired with human wisdom and critical thinking—and that's exactly how we built Claude," said Daniela Amodei, president and co-founder of Anthropic. Bonterra and AWS launch mobile-friendly giving hub to simplify nonprofit donations Bonterra has unveiled The Giving Hub —a mobile-friendly platform that combines cash and in-kind donations in one seamless experience. Built on AWS and powered by Amazon Business Donation Driver APIs, this innovative solution transforms how donors support their favorite causes. The Giving Hub addresses a critical challenge facing nonprofits: meeting donor expectations for simple, transparent giving while managing diverse donation types. By integrating Bonterra's GiveGab solution with Amazon Business technology and AWS cloud infrastructure, the platform enables donors to discover organizations, browse nonprofit wish lists, and make cash contributions—all through a single, branded interface. "Nonprofits are under tremendous pressure during the holidays, and donors increasingly expect giving to be simple, transparent, and meaningful," said Ben Cohen, chief revenue officer at Bonterra. "This partnership is removing long-standing barriers in the giving process and unlocking new ways for donors to make an impact." For nonprofits, the platform streamlines operations by enabling custom wish list creation, facilitating cash donations, tracking in-kind contributions, and simplifying fulfillment processes. This builds on Bonterra and AWS's partnership to develop AI-powered, cloud-native solutions for the social good sector, including Bonterra Que—the first fully agentic AI platform built specifically for nonprofits, foundations, and CSR teams. Lyft brings agentic AI to drivers Lyft is partnering with AWS to reimagine rideshare through customer-first AI. Working with the AWS Generative AI Innovation Center and Anthropic, the company built an “intent agent” to support its more than 1 million drivers. The agent, powered by Anthropic’s Claude and Amazon Bedrock, speaks in Spanish or English and uses contextual, backend data to take meaningful action for drivers. For example, if a driver messages, “My earnings aren't showing up," the agent already knows they just completed three rides, sees their payment history, and works to resolve the issue. Lyft has seen an 87% reduction in average resolution time for customer and driver support requests, with more than half resolved in less than three minutes. "The future of customer service has fundamentally shifted through AI," said Ameena Gill, vice president of Safety and Customer Care at Lyft. Nissan accelerates software-defined vehicle innovation with AWS Nissan Motor Co. is rolling out its new Nissan Scalable Open Software Platform, powered by AWS . This cloud-based foundation is completely transforming how Nissan develops its software-defined vehicles (SDVs). The platform brings together software creation, data management, and vehicle operations in one seamless system—running on AWS technology. The results speak for themselves: testing that's 75% faster than before and a unified environment where more than 5,000 developers across the globe can collaborate effortlessly. Teams can now update vehicle features more quickly and work together across international boundaries like never before. "Software development for SDVs is an extremely important strategy for Nissan," said Kazuma Sugimoto, general manager at Nissan. "The Nissan Scalable Open Software Platform is key technology that enables us to rapidly deliver innovative value to customers." Looking ahead, Nissan isn't slowing down. The company is planning to integrate more AI capabilities, including an advanced version of their ProPILOT system for complex driving environments by 2027. Visa collaborates with AWS to deliver secure agentic payments Visa and AWS have teamed up to enable AI agents to transact securely and autonomously on behalf of users. By combining Visa's global payment infrastructure with AWS's AI and cloud capabilities, the companies aim to simplify commerce and unlock faster innovation for developers while delivering seamless experiences for consumers and businesses worldwide. The companies will also publish open blueprints on the Amazon Bedrock AgentCore public repository to help developers create intelligent agentic workflows for retail shopping, travel booking, and payment reconciliation. These blueprints will enable AI agents to handle complex, multi-step transactions—from product discovery and price comparison to secure checkout and order tracking. "Visa Intelligent Commerce is designed to be the trust layer for the agent economy," said Rubail Birwadker, SVP and global head of Growth at Visa. "With AWS's scalable cloud capabilities and Visa's global payment network, Visa Intelligent Commerce enables AI agents to transact securely and contextually at scale." The collaboration brings together industry partners including Expedia Group, Intuit, lastminute.com, Eurostars Hotel Company, and others to review blueprint designs spanning travel, retail, and B2B payments. For example, users could instruct an AI agent to "Buy me basketball game tickets if the price drops below $150," and the agent would execute those tasks on behalf of the user. BlackRock teams with AWS to deliver Aladdin on secure, scalable, performant cloud infrastructure BlackRock is offering Aladdin—BlackRock's industry-recognized investment management technology platform—on AWS . Aladdin on AWS enables clients to leverage advanced risk modeling, enterprise-grade analytics, and smart investment decision-making capabilities while benefiting from AWS's proven track record running mission-critical financial services workloads for over 20 years. "By expanding Aladdin to AWS, we are giving clients more choice in where and how they deploy their technology ecosystem," said Sudhir Nair, senior managing director and global head of Aladdin at BlackRock. "With Aladdin running on AWS, clients gain access to secure, scalable, and resilient infrastructure for advanced risk modeling, enterprise-grade analytics, and smart investment decision-making while maintaining the highest security and resiliency standards," said Scott Mullins, managing director of Worldwide Financial Services at AWS. General availability for Aladdin Enterprise clients hosted in the United States is expected in the second half of 2026. Deepgram brings advanced speech AI capabilities to AWS Deepgram is delivering streaming speech-to-text, text-to-speech, and voice agent capabilities to Amazon SageMaker AI and integrating its enterprise-grade speech technology with Amazon Connect and Amazon Lex. Together, these integrations enable customers to build and deploy voice-powered applications with sub-second latency while maintaining the security and compliance benefits of their AWS environment. Deepgram clients now have the option to deploy real-time speech capabilities across AWS services—from contact centers to custom voice applications—providing choice in their technology environment without compromising the performance and reliability that make Deepgram a trusted solution for enterprise voice AI. "By bringing our streaming speech models directly into SageMaker, enterprises can deploy speech-to-text, text-to-speech, and voice agent capabilities with sub-second latency, all within their AWS environment," said Scott Stephenson, CEO at Deepgram. "Integrating Deepgram's advanced speech technology with Amazon Connect enables organizations to build voice interactions that understand context and respond with appropriate pace and tone, transforming automated interactions into opportunities for deeper customer relationships," said Pasquale DeMaio, VP of Amazon Connect at AWS. Deepgram is an AWS Generative AI Competency Partner with a multi-year Strategic Collaboration Agreement. Early adopters are already leveraging these integrations to power real-time speech processing for enterprise platforms. Learn more about Deepgram as an AWS Partner . Discover more news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Wed, 03 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-re-invent-2025-ai-news-updates</guid>
    </item>
    <item>
      <title>AWS introduces Graviton5: the company’s most powerful and efficient CPU</title>
      <link>https://www.aboutamazon.com/news/aws/aws-graviton-5-cpu-amazon-ec2</link>
      <description><![CDATA[Key takeaways New AWS Graviton5-based Amazon EC2 M9g instances deliver up to 25% higher performance than the previous generation. With 192 cores per chip and 5x larger cache, customers can scale up workloads and improve application performance while reducing infrastructure cost. For the third year in a row, more than half of new CPU capacity added to AWS is powered by Graviton, and 98% of the top 1,000 EC2 customers, including Adobe, Airbnb, Atlassian, Epic Games, Formula 1, Pinterest, SAP, Siemens, Snowflake, and Synopsys, have already benefited from Graviton's price performance advantages. As cloud workloads continue to grow in complexity and scale, organizations face a persistent challenge: how to simultaneously deliver faster performance, lower costs, and meet sustainability commitments. Traditional approaches often force trade-offs, leaving you to choose between speed and efficiency. To address this need, today we are introducing Graviton5 processors—AWS's most advanced custom chip to date for a broad set of cloud workloads. Graviton5 delivers up to 25% better compute performance than the previous generation while maintaining leading energy efficiency, enabling you to run applications faster, reduce costs, and meet sustainability goals. Graviton5 delivers measurable business impact Graviton5-based EC2 M9g instances enable you to process information more efficiently with the highest CPU core density available in Amazon EC2—192 cores in a single package. This efficient design reduces the distance data must travel between cores, cutting inter-core communication latency by up to 33% while increasing bandwidth. Demanding workloads like real-time gaming, high-performance databases, big data analytics, application servers, and Electronic Design Automation (EDA) can now scale up with faster data exchange between processing cores. The chip includes a 5x larger L3 cache—a high-speed memory buffer that keeps frequently accessed data close to the processor. Each Graviton5 core has access to 2.6x more L3 cache than Graviton4, which translates to fewer delays waiting for data and faster application response times. Memory performance has also improved, with Graviton5 providing faster memory speeds, enabling you to process larger datasets and run memory-intensive applications more efficiently. Network and storage bandwidth have also increased, with up to 15% higher network bandwidth and 20% higher Amazon Elastic Block Store (EBS) bandwidth on average across instance sizes, and up to twice the network bandwidth for the largest instances—resulting in faster data transfers, quicker backups, and improved performance for distributed applications. Graviton5 also delivers better performance while being more energy efficient, helping you meet sustainability targets without compromising capability. These innovations are possible because of end-to-end ownership from chip design through server architecture. Graviton5 adopts the latest 3nm technology, optimizes the design for AWS use cases, and allows for system-level optimizations such as bare-die cooling. Graviton5 advances security without compromise Built on the AWS Nitro System—the security and performance foundation trusted by the world's most privacy-conscious organizations across government, healthcare, and financial services—Graviton5 instances leverage sixth-generation Nitro Cards to offload virtualization, storage, and networking functions to dedicated hardware. This architecture delivers virtually all the server's compute and memory resources directly to your workloads while implementing a zero-operator access design that fundamentally prevents any other system or person from logging into EC2 servers, reading instance memory, or accessing customer data. Graviton5 introduces the Nitro Isolation Engine as an enhancement to the Nitro System, harnessing formal verification to provide mathematical certainty that your workloads are isolated from each other and AWS operators. Nitro Isolation Engine’s minimal, formally verified codebase uses mathematical proofs to ensure it behaves exactly as defined, pioneering a new standard for mathematically proven cloud security. We will engage with customers to provide access to the Nitro Isolation Engine implementation so they can evaluate it and the resulting proofs. Proven customer performance across industries Adobe is using Graviton to transform broadcasts into personalized viewing experiences for millions of users, leveraging the improved compute performance to process video streams in real-time. Epic Games relies on Graviton to bring competitive gaming experiences to millions of players daily, where the reduced latency and increased bandwidth ensure smooth gameplay even during peak demand. Formula 1 uses Graviton to help fans keep up with drivers traveling at 350 km/h, processing telemetry data and delivering real-time insights to viewers around the world. Pinterest hosts more than 500 million monthly active users on Graviton-based infrastructure, benefiting from the price performance advantages to serve personalized content at scale. Airbnb was born in 2007 when two hosts welcomed three guests to their San Francisco home and has since grown to over 5 million hosts who have welcomed over 2 billion guest arrivals in almost every country across the globe. “AWS Graviton5-based Amazon EC2 instances are some of the fastest EC2 instances we have ever tested,” said Denis Sheahan a principal performance engineer at Airbnb. “In our performance tests, conducted using Airbnb's production search workloads, we are seeing improvements of up to 25% over other system architectures of the same generation, and up to 20% compared to prior generation Graviton4 instances. We are especially impressed with P95 latency for our critical workloads, helping to provide a consistent experience for Airbnb guests and hosts.” A recognized leader in software development, work management, and enterprise service management software, Atlassian enables enterprises to connect their business and technology teams with an AI-powered system of work that unlocks productivity at scale. “Atlassian has migrated more than 3,000 EC2 instances for Jira and Confluence to AWS Graviton4-based EC2 instances,” said Paulo Almeida, principal site reliability engineer at Atlassian. “In our testing of Jira on AWS Graviton5-based M9g instances, we observed 30% higher performance and 20% lower latency compared to the prior generation, and we look forward to AWS Graviton5 general availability.” Siemens Digital Industries Software helps organizations of all sizes digitally transform using software, hardware, and services from the Siemens Xcelerator business platform. Siemens Calibre Design Solutions delivers a complete integrated circuit verification and design for manufacturing optimization EDA platform. “The future of semiconductor physical verification lies in cloud-enabled, high-performance computing,” said Juan Rey, senior vice president and general manager at Siemens Digital Industries Software. “Our collaboration with AWS positions Calibre at the forefront of this transformation. We're excited to announce support for Calibre on Arm-based AWS Graviton processors, which deliver 20% performance improvements and more than 30% compute cost reductions on AWS Graviton4 compared with other AWS instances. Early AWS Graviton5 testing shows an additional 30% performance boost, unlocking faster verification and time-to-market for our customers.” For over 50 years, organizations have trusted SAP to bring out their best by uniting business-critical operations spanning finance, procurement, HR, supply chain, and customer experience. “We've been working closely with AWS on running SAP HANA Cloud on AWS Graviton since 2023 and have seen significant performance improvements with each new Graviton generation,” said Stefan Bäuerle, senior vice president and head of SAP HANA & Persistency at SAP. “With AWS Graviton5-based Amazon EC2 M9g instances, we've observed a stunning 35% to 60% increase in the performance of our OLTP queries on SAP HANA Cloud—a phenomenal advancement in a single generation.” Synopsys is the leader in engineering solutions from silicon to systems, enabling customers to rapidly innovate AI-powered products. “For over a decade since the inception of Annapurna Labs, Synopsys and AWS have collaborated to enable Amazon's custom silicon development,” said Sanjay Bali, senior vice president in strategy and product management at Synopsys. “Synopsys EDA tools such as VCS, PrimeTime, Fusion Compiler, and IC Validator support on AWS Graviton have been critical to the design of Graviton as well as Nitro and Trainium chips. Today, Synopsys and AWS are expanding Graviton support to accelerate our customers' semiconductor innovation. Compared to Graviton4, early results on Graviton5 show up to 35% runtime improvements for Fusion Compiler and PrimeTime. In addition, our joint partner, Arm, is observing up to 40% faster runtimes for Synopsys VCS on Graviton5 relative to previous generations.” Graviton5-based M9g instances designed for general purpose workloads are available in preview now. C9g instances for compute-intensive workloads and R9g instances for memory-intensive workloads are planned for 2026. For more details on AWS Graviton5 and the new M9g instances, visit: AWS Graviton productpage Gravitondocumentation Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Wed, 03 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-graviton-5-cpu-amazon-ec2</guid>
    </item>
    <item>
      <title>AWS simplifies model customization to help customers build faster, more efficient AI agents</title>
      <link>https://www.aboutamazon.com/news/aws/amazon-sagemaker-ai-amazon-bedrock-aws-ai-agents</link>
      <description><![CDATA[Key takeaways New Amazon Bedrock and Amazon SageMaker AI capabilities give customers access to advanced techniques for model customization. Reinforcement Fine Tuning in Amazon Bedrock makes it easier to tailor models to unique cases and improve accuracy. Amazon SageMaker AI cuts advanced model customization workflows from months to days, accelerating AI development and bringing new solutions to market faster. Efficiency has emerged as a critical challenge for organizations deploying AI. While building AI applications has become easier, running them at scale remains expensive and resource-intensive. This challenge is particularly acute for AI agents , which can have higher inference demands as they reason through problems, leverage a variety of tools, and coordinate across multiple systems. Most companies opt for the largest, most capable models to power their agents, but a significant amount of an agent’s time is spent doing routine tasks, like checking calendars and searching documents, that don't require advanced intelligence. The result? Unnecessary costs, slower responses, and wasted resources. The solution lies in customization: tailoring smaller, specialized models to handle the work agents do most often to deliver faster, more accurate responses at lower costs. But until now, advanced customization techniques like reinforcement learning required deep machine learning expertise, extensive infrastructure, and months of development time. Today, we announced new Amazon Bedrock and Amazon SageMaker AI capabilities that make advanced model customization accessible to developers at any organization. Reinforcement Fine Tuning (RFT) in Amazon Bedrock and serverless model customization in Amazon SageMaker AI with reinforcement learning simplify the process of creating efficient AI that's fast, cost-effective, and more accurate compared to base models. By making these techniques more accessible for our customers’ developers, we’re making it easier for organizations of all sizes to build custom agents for any business need. RFT made easy for everyday developers with Amazon Bedrock Difficult customization techniques present a roadblock for building custom, efficient models. Reinforcement learning, for example, trains a model using feedback from either humans or another model. Good behavior gets reinforced, while bad behavior gets corrected. It’s particularly good for reasoning and complex workflows because it rewards good processes, not just good answers. However, reinforcement learning requires a complex training pipeline, massive compute, and access to expensive human feedback or a powerful AI model to evaluate every response. RFT on Amazon Bedrock simplifies the model customization process, opening the technique to any developer at any organization. Amazon Bedrock is a fully managed AI platform giving customers access to high-performing foundation models from leading AI companies, along with capabilities to build agents and generative AI applications with features for security, privacy, and responsible AI. RFT on Amazon Bedrock delivers 66% accuracy gains on average over base models, helping you get better results with smaller, faster, more cost-effective models instead of relying on larger, expensive ones. The process is simple. Developers select their base model, point it at their invocation logs (in other words, the AI’s history), or upload a dataset. Then, they choose a reward function—AI-based, rule-based, or a ready-to-use template. Automated workflows in Amazon Bedrock handle the fine-tuning process end-to-end. No PhD in machine learning required—only a clear sense of what good results look like for the business. At launch, RFT in Amazon Bedrock will support the Amazon Nova 2 Lite model. Compatibility with additional models is coming soon. Customers like Salesforce and Weni by VTEX have seen increased accuracy and efficiency using RFT in Amazon Bedrock. Phil Mui, SVP of Software Engineering, Agentforce at Salesforce, said, “AWS’s benchmarking with Amazon Bedrock’s Reinforcement Fine Tuning shows promising results, demonstrating up to 73% improvement over base model in accuracy for our specific business requirements. We anticipate leveraging RFT to enhance and extend what we already achieve with supervised fine-tuning, enabling us to deliver even more precise and customized AI solutions for our customers. This approach complements our existing AI development workflow while maintaining Salesforce’s high standards for quality and safety.” Amazon SageMaker AI accelerates model customization from months to days Teams that need more control over the AI workflow can turn to Amazon SageMaker AI. AI developers choose SageMaker AI for customization because it gives them full control to build, train, and deploy the most capable models at scale. Since launching in 2017, SageMaker AI has made the AI development workflow faster and more efficient. However, as organizations look to use more advanced customization techniques, they want more seamless experiences that remove roadblocks that take months of work—like infrastructure management and generating synthetic data—so they can focus on developing better outcomes for customers. That’s why SageMaker AI now supports new serverless model customization capabilities, making model customization possible in just days. There are two experiences to choose from: an agentic experience, launching in preview, that uses an agent to guide developers through the model customization process, or a self-guided approach for those who like to be in the driver's seat. With the agentic experience, developers describe what they need in natural language and then the agent walks through the entire customization process, from generating synthetic data to evaluation. Developers who want granular control and flexibility can choose the self-guided experience. This eliminates infrastructure management while providing the right tooling to select a customization technique and the ability to tweak the parameters. With either option, developers can access advanced customization techniques like Reinforcement Learning from AI feedback, Reinforcement Learning with Verifiable Rewards, Supervised Fine-Tuning, and Direct Preference Optimization. The new SageMaker AI capabilities will work with Amazon Nova and popular open weight models like Llama, Qwen, DeepSeek, and GPT-OSS, giving customers a wide range of options to match the right model to their use case. Collinear AI, Robin AI, Vody, and Eloquent AI are just a few of the customers that have started simplifying model customization with SageMaker AI’s new capabilities. For example, Collinear AI, an AI improvement platform built for enterprise genAI, saved weeks using SageMaker AI. Soumyadeep Bakshi, co-founder, Collinear AI, said, “Fine-tuning AI models is critical to creating high-fidelity simulations, and it used to require stitching together different systems for training, evaluation, and deployment. Now with Amazon SageMaker AI's new serverless model customization capability, we have a unified way that empowers us to cut our experimentation cycles from weeks to days. This end-to-end serverless tooling helps us focus on what matters: building better training data and simulations for our customers, not maintaining infrastructure or juggling disparate platforms.” For more details about these capabilities, visit: AWS News blog: RFT in Amazon Bedrock RFT in Amazon Bedrock product page AWS News blog: SageMaker AI serverless model customization SageMaker AI model customization product page Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Tue, 02 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/amazon-sagemaker-ai-amazon-bedrock-aws-ai-agents</guid>
    </item>
    <item>
      <title>Trainium3 UltraServers now available: Enabling customers to train and deploy AI models faster at lower cost</title>
      <link>https://www.aboutamazon.com/news/aws/trainium-3-ultraserver-faster-ai-training-lower-cost</link>
      <description><![CDATA[Key takeaways Trainium3 UltraServers deliver high performance for AI workloads with up to 4.4x more compute performance, 4x greater energy efficiency, and almost 4x more memory bandwidth than Trainium2 UltraServers—enabling faster AI development with lower operational costs. Trn3 UltraServers scale up to 144 Trainium3 chips, delivering up to 362 FP8 PFLOPs with 4x lower latency to train larger models faster and serve inference at scale. Customers including Anthropic, Karakuri, Metagenomi, NetoAI, Ricoh, and Splash Music are reducing training and inference costs by up to 50% withTrainium, while Decart is achieving 4x faster inference for real-time generative video at half the cost of GPUs, and Amazon Bedrock is already serving production workloads on Trainium3. As AI models grow in size and complexity, they are pushing the limits of compute and networking infrastructure, with customers seeking to reduce training times and inference latency—the time between when an AI system receives an input and generates the corresponding output. Training cutting-edge models now requires infrastructure investments that only a handful of organizations can afford, while serving AI applications at scale demands compute resources that can quickly spiral out of control. Even with the fastest accelerated instances available today, simply increasing cluster size fails to yield faster training time due to parallelization constraints, while real-time inference demands push single-instance architectures beyond their capabilities. To help customers overcome these constraints, today we announced the general availability of Amazon EC2 Trn3 UltraServers. Powered by the new Trainium3 chip built on 3nm technology, Trn3 UltraServers enable organizations of all sizes to train larger AI models faster and serve more users at lower cost—democratizing access to the compute power needed for tomorrow's most ambitious AI projects. Trainium3 UltraServers: Purpose-built for next-generation AI workloads Trn3 UltraServers pack up to 144 Trainium3 chips into a single integrated system, delivering up to 4.4x more compute performance than Trainium2 UltraServers. This allows you to tackle AI projects that were previously impractical or too expensive by training models faster, cutting time from months to weeks, serving more inference requests from users simultaneously, and reducing both time-to-market and operational costs. In testing Trn3 UltraServers using OpenAI's open weight model GPT-OSS, customers can achieve 3x higher throughput per chip while delivering 4x faster response times than Trn2 UltraServers. This means businesses can scale their AI applications to handle peak demand with less infrastructure footprint, directly improving user experience while reducing the cost per inference request. These improvements stem from Trainium3's purpose-built chip. The chip achieves breakthrough performance through advanced design innovations, optimized interconnects that accelerate data movement between chips, and enhanced memory systems that eliminate bottlenecks when processing large AI models. Beyond raw performance, Trainium3 delivers substantial energy savings—40% better energy efficiency compared to previous generations. This efficiency matters at scale, enabling us to offer more cost-effective AI infrastructure while reducing environmental impact across our data centers. Advanced networking infrastructure engineered for scale AWS engineered the Trn3 UltraServer as a vertically integrated system—from the chip architecture to the software stack. At the heart of this integration is networking infrastructure designed to eliminate the communication bottlenecks that typically limit distributed AI computing. The new NeuronSwitch-v1 delivers 2x more bandwidth within each UltraServer, while enhanced Neuron Fabric networking reduces communication delays between chips to just under 10 microseconds. Tomorrow's AI workloads—including agentic systems, mixture-of-experts (MoEs), and reinforcement learning applications—require massive amounts of data to flow seamlessly between processors. This AWS-engineered network enables you to build AI applications with near-instantaneous responses that were previously impossible, unlocking new use cases like real-time decision systems that process and act on data instantly, and fluid conversational AI that responds naturally without lag. For customers who need to scale, EC2 UltraClusters 3.0 can connect thousands of UltraServers containing up to 1 million Trainium chips—10x the previous generation—giving you the infrastructure to train the next generation of foundation models. This scale enables projects that simply weren't possible before, from training multimodal models on trillion-token datasets to running real-time inference for millions of concurrent users. Customers already seeing results at frontier scale Customers are already seeing significant value from Trainium, with companies like Anthropic, Karakuri, Metagenomi, NetoAI, Ricoh, and Splash Music reducing their training costs by up to 50% compared to alternatives. Amazon Bedrock, AWS's managed service for foundation models, is already serving production workloads on Trainium3, demonstrating the chip's readiness for enterprise-scale deployment. Pioneering AI companies including Decart, an AI lab specializing in efficient, optimized generative AI video and image models that power real-time interactive experiences, are leveraging Trainium3's capabilities for demanding workloads like real-time generative video, achieving 4x faster frame generation at half the cost of GPUs. This makes compute-intensive applications practical at scale—enabling entirely new categories of interactive content, from personalized live experiences to large-scale simulations. With Project Rainier , AWS collaborated with Anthropic to connect more than 500,000 Trainium2 chips into the world's largest AI compute cluster—five times larger than the infrastructure used to train Anthropic's previous generation of models. Trainium3 builds on this proven foundation, extending the UltraCluster architecture to deliver even greater performance for the next generation of large-scale AI compute clusters and frontier models. Looking ahead to the next generation of Trainium We are already working on Trainium4, which is being designed to bring significant performance improvements across all dimensions, including at least 6x the processing performance (FP4), 3x the FP8 performance, and 4x more memory bandwidth to support the next generation of frontier training and inference. Combined with continued hardware and software optimizations, you can expect performance gains that scale well beyond baseline improvements. The 3x FP8 performance improvement in Trainium4 represents a foundational leap—you can train AI models at least three times faster or run at least three times more inference requests, with additional gains realized through ongoing software enhancements and workload-specific optimizations. FP8 is the industry-standard precision format that balances model accuracy with computational efficiency for modern AI workloads. To deliver even greater scale-up performance, Trainium4 is being designed to support NVIDIA NVLink Fusion high-speed chip interconnect technology. This integration will enable Trainium4, Graviton, and Elastic Fabric Adapter (EFA) to work together seamlessly within common MGX racks, providing you with a cost-effective, rack-scale AI infrastructure that supports both GPU and Trainium servers. The result is a flexible, high-performance platform optimized for demanding AI model training and inference workloads. Amazon EC2 Trn3 UltraServers are now generally available. Learn more and get started today. Additional resources: AWS AI Blog Documentation See howcustomers are using Trainium Get startedwith Trainium Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/trainium-3-ultraserver-faster-ai-training-lower-cost</guid>
    </item>
    <item>
      <title>New Amazon Bedrock AgentCore capabilities power the next wave of agentic AI development</title>
      <link>https://www.aboutamazon.com/news/aws/aws-amazon-bedrock-agent-core-ai-agents</link>
      <description><![CDATA[Key takeaways Policy in Amazon Bedrock AgentCore actively blocks unauthorized agent actions through real-time, deterministic controls that operate outside of the agent code. AgentCore Evaluations helps developers continuously inspect the quality of an agent based on its behavior. AgentCore Memory introduces episodic functionality that helps agents learn from experiences, improving decision-making. Organizations of all sizes and regulatory requirements—including Amazon Devices Operations & Supply Chain, Archera.ai, Cohere Health, Cox Automotive, Druva, Heroku, Natera, NTT Data, MongoDB, PGA TOUR, Pulumi, Thomson Reuters, Workday, Snorkel.ai, Swisscom, and S&P Global Market Intelligence—trust AgentCore to accelerate their AI agents into production. Today, we announced new innovations in Amazon Bedrock AgentCore , the most advanced platform for building and deploying agents securely at scale. Policy in AgentCore allows teams to set boundaries on what agents can do with tools, and AgentCore Evaluations help teams understand how their agents will perform in the real world. Additionally, AWS launched an enhanced memory capability that enables agents to learn from experience and improve over time, providing more tailored insights to customers. Develop enterprise AI agents that know their power and their limits While the ability for agents to reason and act autonomously makes them powerful, organizations must establish robust controls to prevent unauthorized data access, inappropriate interactions, and system-level mistakes that could impact business operations. Even with careful prompting, agents make real-world mistakes that can have serious consequences. Today, we are launching Policy in Amazon Bedrock AgentCore, which helps organizations set clear boundaries for agent actions. Using natural language, teams can now give agents boundaries by defining which tools and data they can access, what actions they can perform, and under what conditions. These tools could be APIs, Lambda functions, MCP servers, or popular third-party services like Salesforce and Slack. To ensure agents stay fast and responsive, Policy is integrated into AgentCore Gateway to instantly check agent actions against policies in milliseconds. This ensures agents stay within defined boundaries while operating autonomously. The natural language-based policy authoring provides a more accessible and user-friendly way for customers to create fine-grained policies by allowing them to describe rules in natural language instead of writing formal policy code. For example, a simple policy like “Block all refunds from customers when the reimbursement amount is greater than $1,000” can be implemented and enforced consistently, following Amazon's “trust, but verify” principle. This will allow agents to operate autonomously while maintaining appropriate oversight. Druva is a leading provider of data security solutions. "Typically, customers can spend hours manually checking logs across dozens of systems when data backups fail,” said David Gildea, vice president of product AI at Druva. “However, with our AI agents , they can get instant analysis and step-by-step remediation for data recovery. We are excited to get started with Policy in AgentCore as it will help our customers set clear boundaries for agent access to internal tools and data like backup systems, security logs, and monitoring dashboards. With appropriate policies in place, our developers can innovate confidently, knowing agents will stay within defined compliance boundaries. This enables us to expand our agent platform while maintaining the strict security standards our enterprise customers expect." Gain complete visibility into AI agent behavior and results Unlike traditional software metrics, evaluating AI agent quality requires complex data science pipelines, subjective assessments, and continuous real-time monitoring, a challenge that compounds with each agent update or model change. AgentCore Evaluations simplifies complicated processes and eliminates complex infrastructure management with 13 pre-built evaluators for common quality dimensions such as correctness, helpfulness, tool selection accuracy, safety, goal success rate, and context relevance. Additionally, developers have the flexibility to write their own custom evaluators using their preferred LLMs and prompts. Previously, this required months of data science work to build just the evaluation systems. The new service continuously samples live agent interactions to analyze agent behavior for pre-identified criteria like correctness, helpfulness, and safety. Development teams can set up alerts for proactive quality monitoring, using evaluations both during testing and in production. For example, if a customer service agent's satisfaction scores drop by 10% over eight hours, the system triggers immediate alerts, enabling swift response before customer experience is impacted. Natera is a leader in genetic testing and diagnostics. “At Natera, we're transforming oncology patient care through AI agents,” said Mirko Buholzer, software engineering lead, Natera. “Our teams are currently undertaking a substantial effort to uphold consistent quality and performance across our AI agents while meeting strict health care compliance standards. AgentCore Evaluations will play a key role in this work by continuously monitoring our agents' performance by using essential metrics such as accuracy, helpfulness, and patient satisfaction. We expect this real-time quality intelligence to help us quickly identify and address issues preemptively. With AgentCore Evaluations, we aim to confidently deploy reliable agents that maintain our high standards and support the delivery of transformative patient care at scale.” Build agents that get smarter with every interaction Most AI agents today lack critical memory capabilities because "memory" is often limited to a short-term context window that is reset with each new interaction, preventing them from learning from past successes or failures in production environments. AgentCore Memory provides this critical feature, allowing an agent to build a coherent understanding of users over time. Today, AgentCore Memory is making a new episodic functionality generally available that allows agents to learn from past experiences and apply those insights to future interactions. Through structured episodes that capture context, reasoning, actions, and outcomes, another agent automatically analyzes patterns to improve decision-making. When agents encounter similar tasks, they can quickly access relevant historical data, reducing processing time and eliminating the need for extensive custom instructions. For example, an agent books airport transportation 45 minutes before the flight when you are traveling alone. Three months later, when you are traveling to the same destination—with kids this time—it automatically schedules pickup two hours early, remembering previous family trip challenges. This targeted learning approach helps agents make more consistent decisions based on actual performance data rather than relying on predetermined guidelines. S&P Global Market Intelligence provides insights and leading data and technology solutions to institutional investors, banks, and corporations. “We recently developed Astra, an internal general-purpose agentic workflow platform, but faced challenges orchestrating complex multi-agent workflows across our distributed organization,” said Helene Astier, head of Technology, MI Enterprise Technology and Sustainability, at S&P Global Market Intelligence. “As hundreds of specialized agents emerged, managing state and maintaining consistent context became increasingly difficult, highlighting the need for a unified memory layer. Amazon Bedrock AgentCore Memory provided the solution through seamless, centralized state checkpointing across our multi-agent orchestration stack. With the new episodic memory functionality, our agents will learn from prior analyses to generate more intelligent insights. Previously, deploying agents onto the Astra platform took weeks. Now, with AgentCore we can create and deploy an agent or MCP server within minutes.” Today’s innovations give you purpose-built agent infrastructure that lets you focus on innovation rather than building AI foundations. For more details on the new Amazon Bedrock AgentCore innovations, visit: AgentCore News Blog AgentCore webpage Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-amazon-bedrock-agent-core-ai-agents</guid>
    </item>
    <item>
      <title>AWS unveils frontier agents, a new class of AI agents that work as an extension of your software development team</title>
      <link>https://www.aboutamazon.com/news/aws/amazon-ai-frontier-agents-autonomous-kiro</link>
      <description><![CDATA[Key takeaways Frontier agents represent a new class of AI agents that are autonomous, scalable, and work for hours or days without constant intervention. Kiro autonomous agent is your virtual developer that maintains context and learns over time while working independently, so you can focus on your biggest priorities. AWS Security Agent is your virtual security engineer that helps build secure applications by being a security consultant for app design, code reviews, and penetration testing. AWS DevOps Agent is your virtual operations team member that helps resolve and proactively prevent incidents, while continuously improving your applications’ reliability and performance. AI agents have transformed how development teams work, and as the technology evolves, teams are learning how to maximize agents’ value. To understand how to push agents further, we looked to our own development teams building services at Amazon scale and uncovered three critical insights to dramatically increase value. First, by learning what the agents were and weren’t good at, the team could switch from babysitting every small task to directing agents toward broad, goal-driven outcomes. Second, the velocity of our teams was tied to how many agentic tasks they could run simultaneously. Third, the longer the agents could operate on their own, the better. While these insights came from software development, the team quickly realized they needed the same capabilities across every aspect of the software development lifecycle—like security and operations—or risk creating new bottlenecks. These insights led AWS to frontier agents—a new, more sophisticated class of AI agents with three defining characteristics. First, they're autonomous. Direct them toward a goal, and the agents figure out how to achieve it. Second, they're scalable. They can perform multiple tasks at the same time and distribute work across multiple agents. Third, they work independently. They can operate for hours or days without requiring intervention. That’s why we are announcing three new frontier agents—Kiro autonomous agent, AWS Security Agent, and AWS DevOps Agent—focused on transforming the software development lifecycle. These agents represent a step-function change in what you can do with agents today, moving from assisting with individual tasks to completing complex projects autonomously like a member of your team. These agents take advantage of our decades of experience building software, industry-leading security practices, and extensive operational expertise to help you build faster, secure applications from the start, and operate with greater confidence. Clariant, Commonwealth Bank of Australia, SmugMug, Western Governors University, and Presidio are among the customers already using one or more of these new agents to dramatically accelerate the software development lifecycle. Kiro autonomous agent: The frontier agent for software development AI coding tools have accelerated individual tasks, but many of them have also introduced new friction. Using these tools, you can find yourself acting as the human "thread" that holds work together—rebuilding context when switching tasks, manually coordinating cross-repository changes, and restitching information scattered across tickets, pull requests, and chat threads. This slows them down and pulls focus away from real priorities. What would it take for a tool to cut this friction, so you can stay focused and ship code faster? The Kiro autonomous agent keeps work moving independently while you focus on priority tasks. You now get more uninterrupted time for high-priority work instead of juggling background busy work, shortening the path from idea to meaningful contributions. Kiro autonomous agent maintains persistent context across sessions and continuously learns your pull requests and feedback. It can handle a range of tasks—from triaging bugs to improving code coverage—with a single change spanning multiple repositories. You can ask it questions, describe a task, and assign tasks in your backlog directly from GitHub. The agent will then independently figure out how to get the work done, sharing changes as proposed edits and pull requests, so you stay in control of what gets incorporated. For teams, the Kiro autonomous agent is a shared resource that works alongside the entire team, building a collective understanding of your codebase, products, and standards. It connects to your team’s repos, pipelines, and tools, like Jira, GitHub, and Slack, to maintain context as work progresses, adapting to changes or updates. Every code review, ticket, and architectural decision informs the agent’s understanding, making it even more useful for the team over time. AWS Security Agent: The frontier agent for more secure apps Security teams face a dual challenge: they need to proactively identify risks throughout development, while also reacting quickly when issues emerge. Current tools often provide generic recommendations, and penetration testing takes so much time and resources that it can’t keep up with fast-moving development teams. What if security could deliver tailored guidance throughout the lifecycle and make comprehensive testing available on demand? AWS Security Agent helps you build applications that are secure from the start across AWS, multicloud, and hybrid environments. The agent embeds deep security expertise throughout the development lifecycle, proactively reviewing design documents and scanning pull requests against organizational security requirements and common vulnerabilities. You define your organization's security standards once, and AWS Security Agent automatically validates them across your applications during its review—helping teams address the risks that matter to their business, not generic checklists. The agent also transforms penetration testing from a slow, manual process into an on-demand capability, matching your team’s development velocity. Now you can expand penetration testing across your entire application portfolio. The agent returns validated findings with remediation code to fix the issues it finds, saving you invaluable time and resources. If you have multiple apps deploying at once, you can easily scale the number of AWS Security Agents to meet demand, so you never have to compromise between moving fast and maintaining security. By continually validating security from design to deployment, the agent helps prevent vulnerabilities early, so you can focus on what matters most. SmugMug is a Software-as-a-Service platform for photographers to store, host, and share their images and videos. The company added AWS Security Agent to its automated security portfolio to help transform its security testing approach, enabling penetration test assessments that complete in hours rather than days at a fraction of manual testing costs. "AWS Security Agent helped catch a business logic bug that no existing tools would have caught, exposing information improperly," said Andres Ruiz, staff software engineer at SmugMug. "To any other tool, this would have been invisible. But the ability for Security Agent to contextualize the information, parse the API response, and find the unexpected information there represents a leap forward in automated security testing. Existing tools today lack this capability, and likely only a human tester would have been able to catch this." AWS DevOps Agent: The frontier agent for operational excellence When an application goes down, everything stops. Customers lose access, teams lose time, and trust takes a hit. Modern distributed applications—with microservices, cloud dependencies, and telemetry spread across multiple tools—make it increasingly difficult to isolate issues and understand system behavior. Meanwhile, as services scale, operations can continue to eat up more of your time, reducing your ability to spend innovating and improving your application to provide the best experience for customers. What if operations could break this cycle and move from constant firefighting to continuous improvement? AWS DevOps Agent delivers fewer alerts and more sleep for your team through always-on incident triage, guided resolution, and recommendations for how to continuously improve the reliability and performance of your applications across AWS, multicloud, and hybrid environments. AWS DevOps Agent is on call when incidents happen, instantly responding to issues and using its knowledge of your application and the relationship between components to find the root cause of the problem. It learns your resources and their relationships spanning everything from observability tools, like Amazon CloudWatch, Dynatrace, Datadog, New Relic, and Splunk, to runbooks, code repositories, and continuous integration and continuous delivery (CI/CD) pipelines. It maps your application resources and correlates telemetry, code, and deployment data to precisely pinpoint root causes and reduce mean time to resolution. Within Amazon, AWS DevOps Agent has handled thousands of escalations, with an estimated root cause identification rate of over 86%. You can also move from reactive firefighting to proactive operational improvement by analyzing patterns across historical incidents with AWS DevOps Agent. It uses those learnings to provide targeted recommendations that strengthen four key areas: observability, infrastructure optimization, deployment pipeline enhancement, and application resilience. This approach accesses the untapped insights in your operational data and tools, helping teams improve recovery times and drive operational excellence across applications. Commonwealth Bank of Australia is one of Australia's leading providers of integrated financial services serving over 17 million customers. The bank's Cloud Foundations group manages over 1,700 AWS accounts and provides centralized cloud operation services for thousands of engineers. While prototyping their next-generation internal cloud platform, the team replicated a complex network and identity management issue to test AWS DevOps Agent. These types of issues can take a seasoned DevOps engineer hours to identify, and the agent found the root cause in under 15 minutes. "AWS DevOps Agent thinks and acts like a seasoned DevOps engineer, helping our engineers build a banking infrastructure that’s faster, more resilient, and designed to deliver better experiences for our customers," said Jason Sandery, head of cloud services at Commonwealth Bank of Australia. "This isn't just about faster resolution times—it's about maintaining the trust our customers put in us.” Driving toward an agentic future Together, Kiro autonomous agent, AWS Security Agent, and AWS DevOps Agent mark the beginning of a new era in software development. These frontier agents don't just make teams faster—they fundamentally redefine what's possible when AI works as an extension of your team, delivering outcomes autonomously across the software development lifecycle. All of these agents are available today in preview. For more details about these agents, visit the following product pages and blogs: Frontier agents product page The Kiro blog about the Kiro autonomous agent Kiro autonomous agent product page The AWS News blog on the AWS Security Agent AWS Security Agent product page The AWS News blog on the AWS DevOps Agent AWS DevOps Agent product page Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/amazon-ai-frontier-agents-autonomous-kiro</guid>
    </item>
    <item>
      <title>Amazon introduces new frontier Nova models, a pioneering Nova Forge service for organizations to build their own models, and Nova Act for building agents</title>
      <link>https://www.aboutamazon.com/news/aws/aws-agentic-ai-amazon-bedrock-nova-models</link>
      <description><![CDATA[Key takeaways Nova 2 models deliver industry-leading price-performance across reasoning, multimodal processing, conversational AI, code generation, and agentic tasks. Nova Forge enables companies to build their own optimized variants of Nova by infusing their proprietary data early in the training process through Forge’s unique "open training" approach. Nova Act achieves breakthrough 90% reliability for browser-based UI automation workflows built by early customers. Amazon announces a comprehensive expansion of its Nova portfolio with four new models, a pioneering "open training" service that empowers organizations to build their custom model variants with Nova , and a service for creating highly reliable AI agents. Tens of thousands of companies are using Nova for diverse applications, such as producing high-quality content, automating multi-step tasks, and accelerating development of AI agents. Amazon's new Nova 2 model family balances speed, cost, and intelligence across multiple AI domains: Nova 2 Lite Nova 2 Lite is a fast, cost-effective reasoning model for everyday workloads that can process text, images, and videos to generate text. Customers can adjust how much step-by-step "thinking" the model performs before responding, balancing intelligence depth with speed and cost—ideal for customer service chatbots, document processing, and business automation. Nova 2 Lite delivers industry-leading price performance in its intelligence class. It is equal or better on 13 out of 15 benchmarks compared to Claude Haiku 4.5, equal or better on 11 out of 17 benchmarks compared to GPT-5 Mini, and equal or better on 14 out of 18 benchmarks compared to Gemini Flash 2.5. Nova 2 Lite demonstrates standout capabilities in processing documents, extracting information from videos, generating code, providing accurate grounded answers, and automating multi-step agentic workflows. Nova 2 Pro Nova 2 Pro is Amazon's most intelligent reasoning model that can process text, images, video, and speech to generate text. It’s ideal for highly complex tasks like agentic coding, long-range planning, and sophisticated problem-solving—where the highest accuracy is essential. The model can also serve as a "teacher" for knowledge distillation—transferring its capabilities into smaller, more efficient "student" models for specific domains and use cases. Nova 2 Pro is equal or better on 10 out of 16 benchmarks compared to Claude Sonnet 4.5, equal or better on 8 out of 16 benchmarks compared to GPT-5.1, equal or better on 15 out of 19 benchmarks compared to Gemini 2.5 Pro, and equal or better on 8 out of 18 benchmarks compared to Gemini 3 Pro Preview. Nova 2 Pro demonstrates strengths in multi-document analysis, video reasoning, following complex instructions, solving advanced math, and executing agentic and software engineering tasks. Both Nova 2 Lite and Nova 2 Pro have built-in web grounding and code execution capabilities, meaning they can search the web for current information and run code directly—ensuring responses stay anchored in up-to-date facts rather than relying solely on training data. Nova 2 Sonic Nova 2 Sonic is Amazon's speech-to-speech model that unifies text and speech understanding and generation for real-time, human-like conversational AI. It features expanded multilingual support with expressive voices, higher accuracy, and a one-million token context window for sustained interactions, while enabling seamless switching between voice and text. The model handles tasks asynchronously, letting users continue natural conversations—even switching topics—while actions like booking flights complete in the background. It also seamlessly integrates with Amazon Connect, telephony providers (Vonage, Twilio, AudioCodes), and conversational AI frameworks (LiveKit, Pipecat), making it ideal for customer service applications, AI assistants, and interactive voice experiences. Nova 2 Sonic offers industry-leading price performance and quality compared to OpenAI’s gpt-realtime and Gemini 2.5 Flash models available through their realtime APIs. Nova 2 Omni Nova 2 Omni is a unified multimodal reasoning and generation model that can process text, images, video, and speech inputs while generating both text and images—an industry first. It handles up to 750,000 words, hours of audio, long videos, and hundred-page documents, simultaneously analyzing entire product catalogs, testimonials, brand guidelines, and video libraries at once. This eliminates the cost and complexity of connecting multiple specialized models. For example, marketing teams can analyze product details across all formats to instantly generate complete campaigns including headlines, copy, social posts, and visuals in one workflow. While there are no comparable models in the industry to Nova 2 Omni, it demonstrates strengths in public benchmarks of multimodal reasoning on documents, images, videos, and audio, and can generate high-quality images similar to other leading image-generation models. Organizations like Cisco, Siemens, Sumo Logic, and Trellix are using Nova 2 models for applications ranging from agentic threat detection to video understanding and voice AI assistants. Nova Forge: First-of-its-kind service for building your own frontier AI models Organizations embedding proprietary knowledge into AI applications currently face three compromises: customizing proprietary models in ways that only scratch the surface for integrating an organization’s expertise, continuing to train open-weights models without access to the original training data, which risks the model regressing on foundational capabilities like instruction following, or building from scratch at enormous expense. What organizations need is access to both frontier model capabilities and the ability to deeply integrate their expertise. Nova Forge empowers organizations to build their own optimized variants of Nova—we call them “Novellas”—by blending their proprietary data with Nova’s frontier capabilities. The service pioneers "open training"—giving exclusive access to pre-trained, mid-trained, and post-trained Nova model checkpoints so customers can mix their proprietary data with Amazon Nova-curated datasets at every stage of model training. The result is a customized model that combines Nova's full knowledge and reasoning power with deep understanding of each organization's specific business. Customers can start building their own Novellas with Nova 2 Lite today. In addition, Nova Forge customers get early access to Nova 2 Pro and Nova 2 Omni, which gives them a head start in building applications and their Novellas with even more capable Nova models. Beyond model checkpoints and data-mixing capabilities, Nova Forge offers three additional powerful capabilities: First, the ability to train AI using your own environments, which are referred to as reinforcement learning “gyms.” These gyms are synthetic environments where the models learn from simulated scenarios that reflect their real-world use cases. Second, option to create smaller, faster models that maintain their intelligence at a lower cost—trained on AI-generated examples from larger models through a process called synthetic data-based distillation. Third, access to a responsible AI toolkit that allows them to implement safety controls. Organizations like Booking.com, Cosine AI, Nimbus Therapeutics, Nomura Research Institute, OpenBabylon, Reddit, and Sony are building their own models with Nova Forge to better serve their unique requirements. “Working with Nova Forge is allowing us to improve content moderation on Reddit with a more unified system that's already delivering impressive results,” said Chris Slowe, CTO, Reddit. “We're replacing a number of different models with a single, more accurate solution that makes moderation more efficient. The ability to replace multiple specialized ML workflows with one cohesive approach marks a shift in how we implement and scale AI across Reddit. After seeing these early successes in our safety efforts, we're eager to explore how Nova Forge might help in other areas of our business.” Once customers create their own frontier model with Nova Forge, they can deploy it on Amazon Bedrock with the same enterprise-grade security, scalability, and data privacy as all other Bedrock models. This complete solution—from building their own frontier model to production deployment—ensures organizations achieve optimal AI performance tailored to their specific business needs, with exclusive use of their model securely hosted on AWS. Nova Act: New AWS service for building and managing reliable AI agents for UI-based workflows Nova Act is now available as a service on AWS for building and deploying highly reliable AI agents that can take actions in web browsers. Powered by a custom Nova 2 Lite model, Nova Act provides the fastest and easiest path to build and manage fleets of agents that automate browser-based tasks. Nova Act delivers 90% reliability on early customer workflows and outperforms competing models on relevant benchmarks. Nova Act achieves breakthrough reliability by training a custom Nova 2 Lite model through reinforcement learning, running thousands of tasks on hundreds of simulated web environments. This style of training allows Nova Act to excel on UI-based workflows like updating data in a customer relationship management (CRM) system, testing website functionality, or submitting health insurance claims. With Nova Act, developers can start prototyping an agent in minutes with a no-code playground using natural language prompts, refine that Nova Act agent in familiar IDEs like VS Code, and then deploy to AWS. What customers build and test locally scales in production, with comprehensive management tools and monitoring through the Nova Act AWS console. Organizations across sectors are already seeing results with Nova Act: Startup Sola Systems integrated Nova Act to automate hundreds of thousands of workflows per month for their clients across business-critical tasks like reconciling payments, coordinating shipments, and updating medical records. 1Password used Nova Act to enable users to access their logins with fewer manual steps, and works automatically with a single simple prompt that works across hundreds of different websites. Hertz accelerated its software delivery by 5x and eliminated its Quality Assurance (QA) bottleneck by using Nova Act to automate end-to-end testing across its rental platform—which processes millions in daily bookings—transforming what used to take weeks into hours. Amazon Leo eliminated its QA constraint ahead of its satellite internet launch by using Nova Act to write test scenarios in natural language that automatically execute and adapt across thousands of web and mobile test cases, reducing what previously took weeks of engineering effort to minutes while running three times faster with zero AI costs after initial runs. Getting started with Amazon Nova To learn more about Amazon Nova, visit aws.amazon.com/bedrock/nova . Start building for free at nova.amazon.com/dev . Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-agentic-ai-amazon-bedrock-nova-models</guid>
    </item>
    <item>
      <title>New AWS AI Factories transform customers’ existing infrastructure into high-performance AI environments</title>
      <link>https://www.aboutamazon.com/news/aws/aws-data-centers-ai-factories</link>
      <description><![CDATA[Key takeaways AWS AI Factories deliver dedicated infrastructure combining the latest NVIDIA accelerated computing platform, Trainium chips, AWS AI services, and AWS high-speed, low-latency networking. Customers can leverage their existing data center space, network connectivity, and power while AWS handles the complexity of deployment and management of the integrated infrastructure. AWS AI Factories help enterprises and public sector organizations meet their data sovereignty and regulatory requirements, with accelerated deployment timelines. As governments and large organizations seek to scale AI projects, some are turning to the concept of an “AI factory” to address their unique sovereignty and compliance needs. But building a high-performance AI factory requires a comprehensive set of management, database, storage, and security services—complexity that few customers want to take on themselves. To address this need, today we announced AWS AI Factories, a new offering that provides enterprises and governments with dedicated AWS AI infrastructure deployed in their own data centers. AWS AI Factories combine the latest AI accelerators, including cutting-edge NVIDIA AI computing and Trainium chips , AWS high-speed, low-latency networking, high-performance storage and databases, security, and energy-efficient infrastructure, together with comprehensive AI services like Amazon Bedrock and SageMaker AI so customers can rapidly develop and deploy AI applications at scale. Organizations in regulated industries and the public sector face a critical AI infrastructure challenge in getting their large-scale AI projects deployed. Building their own AI capabilities requires massive capital investments in GPUs, data centers , and power, plus navigating complex procurement cycles, selecting the right AI model for their use case, and licensing models from different AI providers. This creates multi-year timelines and operational complexity that diverts focus from their core business goals. AWS AI Factories address this challenge by deploying dedicated AWS AI infrastructure in customers’ own data centers, operated exclusively for them. AWS AI Factories operate like a private AWS Region that gives secure, low-latency access to compute, storage, database, and AI services. This approach lets you leverage existing data center space and power capacity you’ve already acquired and gives access to AWS AI infrastructure and services—from the latest AI chips for training and inference to tools for building, training, and deploying AI models. It also provides managed services that offer access to leading foundation models without having to negotiate separate contracts with model providers—all while helping you meet security, data sovereignty, and regulatory requirements for where data is processed and stored. Leveraging nearly two decades of cloud leadership and unmatched experience in architecting large-scale AI systems, we are able to deploy secure, reliable AI infrastructure faster than most organizations can on their own, saving years of buildout effort and managing operational complexity. AWS and NVIDIA expand collaboration to accelerate customer AI infrastructure deployments The relationship between AWS and NVIDIA goes back 15 years, to when we launched the world’s first GPU cloud instance, and today we offer the widest range of GPU solutions for customers. Building on our longstanding collaboration to deliver advanced AI infrastructure, AWS and NVIDIA make it possible for customers to build and run large language models faster, at scale, and more securely than anywhere else—now in your own data centers. With the NVIDIA-AWS AI Factories integration, AWS customers have seamless access to the NVIDIA accelerated computing platform, full-stack NVIDIA AI software, and thousands of GPU-accelerated applications to deliver high performance, efficiency, and scalability for building next-generation AI solutions. We continue to bring the best of our technologies together. The AWS Nitro System, Elastic Fabric Adapter (EFA) petabit-scale networking, and Amazon EC2 UltraClusters support the latest NVIDIA Grace Blackwell and the next-generation NVIDIA Vera Rubin platforms. In the future, AWS will support NVIDIA NVLink Fusion high-speed chip interconnect technology in next-generation Trainium4 and Graviton chips, and in the Nitro System. This integration makes it possible for customers to accelerate time to market and achieve better performance. “Large-scale AI requires a full-stack approach—from advanced GPUs and networking to software and services that optimize every layer of the data center. Together with AWS, we’re delivering all of this directly into customers’ environments,” said Ian Buck, vice president and general manager of Hyperscale and HPC at NVIDIA. “By combining NVIDIA’s latest Grace Blackwell and Vera Rubin architectures with AWS’s secure, high-performance infrastructure and AI software stack, AWS AI Factories allow organizations to stand up powerful AI capabilities in a fraction of the time and focus entirely on innovation instead of integration.” Helping the public sector accelerate AI adoption AWS AI Factories are built to meet AWS's rigorous security standards of providing governments with the confidence to run their most sensitive workloads across all classification levels: Unclassified, Sensitive, Secret, and Top Secret. AWS AI Factories will also provide governments around the world with the availability, reliability, security, and control they need to help their own economies advance and take advantage of the benefits of AI technologies. AWS and NVIDIA are collaborating on a strategic partnership with HUMAIN, the global company based in Saudi Arabia building full-stack AI capabilities, with AWS building a first-of-its-kind "AI Zone" in Saudi Arabia featuring up to 150,000 AI chips, including GB300 GPUs, dedicated AWS AI infrastructure, and AWS AI services, all within a HUMAIN purpose-built data center. “The AI factory AWS is building in our new AI Zone represents the beginning of a multi-gigawatt journey for HUMAIN and AWS. From inception, this infrastructure has been engineered to serve both the accelerating local and global demand for AI compute,” said Tareq Amin, CEO of HUMAIN. “What truly sets this partnership apart is the scale of our ambition and the innovation in how we work together. We chose AWS because of their experience building infrastructure at scale, enterprise-grade reliability, breadth of AI capabilities, and depth of commitment to the region. Through a shared commitment to global market expansion, we are creating an ecosystem that will shape the future of how AI ideas can be built, deployed, and scaled for the whole world.” For more details on AWS AI Factories, visit the product page . Get the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-data-centers-ai-factories</guid>
    </item>
    <item>
      <title>New agentic capabilities in AWS Transform enable rapid modernization of any code or application</title>
      <link>https://www.aboutamazon.com/news/aws/aws-transform-ai-agents-windows-modern</link>
      <description><![CDATA[Key takeaways AWS Transform custom capability makes rapid, large-scale modernizations possible for all legacy systems across any software, code, library, and framework. AWS Transform accelerates full-stack Windows modernization by up to 5x across all layers, eliminating up to 70% of customers’ maintenance and licensing costs. Air Canada, Experian, QAD, Teamfront, Thomson Reuters, and Verisk are using AWS Transform to help eliminate their tech debt. A typical organization spends 30% of its teams' time on manual modernization work, otherwise known as tech debt. This work is necessary, but takes valuable resources away from innovations that create new business value. AWS Transform , the first agentic AI service for transforming Windows .NET applications, VMware systems, and mainframes, has already helped customers modernize 4x faster with existing transformation capabilities. Customers have used AWS Transform to analyze an estimated 1.1 billion lines of code and save more than 810,000 hours of manual effort. However, customers told us they have even more systems they need to modernize, so today we’re announcing enhancements that broaden customers’ ability to rapidly modernize legacy applications and code at scale—to realize the full value of AI . AWS Transform custom capability modernizes any system, even custom to your organization We are introducing new agentic capabilities in AWS Transform to accelerate organization-wide code and application modernization across any code, API, framework, runtime, architecture, language, and even company-specific programming languages and frameworks. With pre-built transformations for common patterns (e.g., Java, Node.js, and Python upgrades) and custom transformations for organization-specific tasks, a specialized agent executes consistent, repeatable, and high-quality transformations. For a typical organization, AWS Transform custom can scale modernization across hundreds or thousands of applications, achieving transformation up to 5x faster than when done manually. The transformation agent automatically captures feedback and continues to improve over time, so each subsequent transformation becomes more reliable and efficient. Air Canada, the largest airline in Canada, needed to modernize outdated software that jeopardized the company’s rhythm of business. In only a few days, Air Canada was able to deploy AWS Transform to coordinate and execute the modernization across thousands of Lambda functions (i.e., small tasks in response to events or triggers), realizing an 80% reduction in expected time and cost for the project compared to performing the migration manually. QAD is a software company at the forefront of cloud-based solutions for global manufacturers. “For many of our customers, upgrading from older, highly customized versions to our modern cloud Adaptive ERP with Champion AI has been a real challenge. AWS Transform has completely changed that,” said Sanjay Brahmawar, chief executive officer of QAD|Redzone. “Modernizations that used to take two weeks now take just three days, driving 60%-70% productivity gains and saving more than 7,500 developer hours a year. We’ve already processed more than 180,000 lines of legacy code with exceptional accuracy—and the agent improves with each project. This means faster upgrades, fewer disruptions, and a dramatically easier path to the latest QAD Adaptive ERP platform. For our customers, this isn’t just modernization—it’s acceleration.” AWS Transform speeds up Windows modernization Customers need to modernize their complete Windows environments to reduce expensive licensing costs and improve security and performance. Starting today, AWS Transform provides an up to 5x acceleration of full-stack Windows modernization including .NET apps, SQL Server, user interface (UI) frameworks, and deployment layers into open source, cloud-native solutions. The AWS Transform agents start by analyzing the complete Windows stack and proposing coordinated modernization plans across all layers. Once approved, the agent transforms the application, UI framework, database, and operating system, while providing updates and comprehensive transformation summaries. The new capabilities enable the rapid modernization of full-stack Windows and SQL Server systems to open source alternatives, freeing customers from expensive licensing agreements and reducing operating costs by up to 70%. Teamfront is a strategic partner for market-leading software companies. "Our initial success with AWS Transform—modernizing 800,000 lines of code in just two weeks—demonstrated that we could transform massive codebases in weeks instead of months,” said Bobby Land, chief product and technology officer, Teamfront. “This breakthrough showed us a clear path to retiring technical debt and gave us the confidence to expand our modernization efforts. We're now moving from SQL Server to PostgreSQL while simultaneously transforming our applications, accelerating our modernization journey and enabling us to better serve our portfolio of field service software companies." Thomson Reuters, a global AI and technology leader powering legal, tax, government, risk, and compliance industries, used AWS Transform to move from Windows to open source alternatives to achieve better performance and lower costs. Using agentic AI-powered automation, they now boost velocity by migrating 1.5 million lines of code per month, achieving 30% lower costs, and reducing technical debt by 50%. Enhancements to AWS Transform for mainframe and VMware Drawing on nearly two decades of experience helping organizations modernize, we continue to enhance AWS Transform, today adding: New capabilities in AWS Transform for mainframe modernizationthat save time, reduce risk, and simplify migration. Three new agents build on the code analysis, business rule extraction, and technical documentation capabilities already available in AWS Transform. The agents help produce activity analysis to aid modernization and retirement decisions, blueprints for reimagining legacy code into clear business functions, capabilities, flows, and data usage, as well as simplified domain decomposition. Additionally, new task agents speed up test planning and validation by automatically generating test plans, test data collection scripts, and automation scripts, which traditionally take up to half of project timelines. New capabilities in AWS Transform for VMwarethat simplify and accelerate large-scale discovery, planning, and network migration. This includes an agentic experience for iteration and migration flexibility, which customizes and orchestrates the entire process from assessment to deployment, as well as a new on-premises discovery tool with support for security reviews and inventory discovery. A new migration planning agent applies business context using unstructured inputs (e.g., documents, files, chats, and business rules). Lastly, enhanced network migration agentic capabilities support advanced configurations and security technologies from Cisco ACI, Fortigate, and Palo Alto Networks. New AWS Transform composability initiativethat empowers our AWS Partners to integrate their proprietary tools, agents, and knowledge bases to build customized workflows for customers within the AWS Transform product experience. Accenture, Capgemini, and Pegasystems are the first AWS Partners to build new agents for AWS Transform that deliver more effective and contextually relevant transformations for customers in industries such as financial services and healthcare. For more details on AWS Transform, visit: AWS Transformproduct page AWS News Blog:Introducing AWS Transform custom: Crush tech debt with AI-powered code modernization AWS News Blog:AWS Transform announces full-stack Windows modernization capabilities AWS News Blog:AWS Transform for mainframe introduces reimagine capabilities and automated testing functionality What’s New at AWS:AWS Transform adds new agentic AI capabilities for enterprise VMware migrations See the latest news from AWS re:Invent , including all things agentic and generative AI, product and service announcements, and more.]]></description>
      <pubDate>Sun, 30 Nov 2025 00:00:00 GMT</pubDate>
      <guid isPermaLink="true">https://www.aboutamazon.com/news/aws/aws-transform-ai-agents-windows-modern</guid>
    </item>
  </channel>
</rss>